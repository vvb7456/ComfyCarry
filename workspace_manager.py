#!/usr/bin/env python3
"""
Workspace Manager v1.0 - ComfyUI RunPod/Vast éƒ¨ç½²ç®¡ç†å™¨
- ä»ªè¡¨ç›˜: ç³»ç»Ÿç›‘æ§, æœåŠ¡æ§åˆ¶
- æ¨¡å‹ç®¡ç†: æœ¬åœ°æ¨¡å‹æ‰«æ, CivitAI æŸ¥è¯¢, Enhanced-Civicomfy ä¸‹è½½
- æ—¥å¿—æŸ¥çœ‹: PM2 æ—¥å¿—å®æ—¶æŸ¥çœ‹

å¯åŠ¨: python workspace_manager.py [port]
"""

import json
import os
import sys
import subprocess
import hashlib
import threading
import time
import re
import secrets
from pathlib import Path
from datetime import datetime

import requests
from flask import Flask, jsonify, request, Response, send_file, redirect, session
from flask_cors import CORS

app = Flask(__name__)
CORS(app)

# Session secret key
app.secret_key = os.environ.get("SESSION_SECRET", secrets.token_hex(32))

# --- é…ç½® ---
COMFYUI_DIR = os.environ.get("COMFYUI_DIR", "/workspace/ComfyUI")
COMFYUI_URL = os.environ.get("COMFYUI_URL", "http://localhost:8188")
CONFIG_FILE = Path(__file__).parent / ".civitai_config.json"
MEILI_URL = 'https://search.civitai.com/multi-search'
MEILI_BEARER = '8c46eb2508e21db1e9828a97968d91ab1ca1caa5f70a00e88a2ba1e286603b61'
MANAGER_PORT = int(os.environ.get("MANAGER_PORT", 5000))
DASHBOARD_PASSWORD = os.environ.get("DASHBOARD_PASSWORD", "comfy2025")

# æ¨¡å‹ç›®å½•æ˜ å°„
MODEL_DIRS = {
    "checkpoints": "models/checkpoints",
    "loras": "models/loras",
    "controlnet": "models/controlnet",
    "vae": "models/vae",
    "upscale_models": "models/upscale_models",
    "embeddings": "models/embeddings",
    "clip": "models/clip",
    "unet": "models/unet",
    "clip_vision": "models/clip_vision",
}

MODEL_EXTENSIONS = {".safetensors", ".ckpt", ".pt", ".pth", ".bin"}

# --- Setup Wizard State ---
SETUP_STATE_FILE = Path("/workspace/.setup_state.json")

# é»˜è®¤æ’ä»¶åˆ—è¡¨ (ä¸åŸ deploy.sh å®Œå…¨ä¸€è‡´)
DEFAULT_PLUGINS = [
    {"url": "https://github.com/ltdrdata/ComfyUI-Manager", "name": "ComfyUI-Manager", "required": True},
    {"url": "https://github.com/Fannovel16/comfyui_controlnet_aux", "name": "ControlNet Aux"},
    {"url": "https://github.com/ltdrdata/ComfyUI-Impact-Pack", "name": "Impact Pack"},
    {"url": "https://github.com/yolain/ComfyUI-Easy-Use", "name": "Easy Use"},
    {"url": "https://github.com/crystian/ComfyUI-Crystools", "name": "Crystools"},
    {"url": "https://github.com/ssitu/ComfyUI_UltimateSDUpscale", "name": "Ultimate SD Upscale"},
    {"url": "https://github.com/adieyal/comfyui-dynamicprompts", "name": "Dynamic Prompts"},
    {"url": "https://github.com/weilin9999/WeiLin-Comfyui-Tools", "name": "WeiLin Tools"},
    {"url": "https://github.com/GreenLandisaLie/AuraSR-ComfyUI", "name": "AuraSR"},
    {"url": "https://github.com/ltdrdata/was-node-suite-comfyui", "name": "WAS Node Suite"},
    {"url": "https://github.com/kijai/ComfyUI-KJNodes", "name": "KJNodes"},
    {"url": "https://github.com/BenjaMITM/Enhanced-Civicomfy", "name": "Enhanced Civicomfy", "required": True},
    {"url": "https://github.com/pythongosssss/ComfyUI-WD14-Tagger", "name": "WD14 Tagger"},
    {"url": "https://github.com/rgthree/rgthree-comfy", "name": "rgthree"},
    {"url": "https://github.com/ltdrdata/ComfyUI-Inspire-Pack", "name": "Inspire Pack"},
]


def _load_setup_state():
    """åŠ è½½ Setup Wizard çŠ¶æ€"""
    defaults = {
        "completed": False,
        "current_step": 0,
        "image_type": "",         # "generic" or "prebuilt"
        "password": "",
        "cloudflared_token": "",
        "rclone_config_method": "",  # "url", "base64", "skip"
        "rclone_config_value": "",
        "civitai_token": "",
        "plugins": [p["url"] for p in DEFAULT_PLUGINS],
        "deploy_started": False,
        "deploy_completed": False,
        "deploy_log": [],
    }
    if SETUP_STATE_FILE.exists():
        try:
            state = json.loads(SETUP_STATE_FILE.read_text(encoding="utf-8"))
            for k, v in defaults.items():
                if k not in state:
                    state[k] = v
            return state
        except Exception:
            pass
    return defaults


def _save_setup_state(state):
    """ä¿å­˜ Setup Wizard çŠ¶æ€"""
    SETUP_STATE_FILE.write_text(json.dumps(state, indent=2, ensure_ascii=False), encoding="utf-8")


def _is_setup_complete():
    """æ£€æŸ¥éƒ¨ç½²æ˜¯å¦å·²å®Œæˆ"""
    if not SETUP_STATE_FILE.exists():
        # å¦‚æœ ComfyUI å·²å­˜åœ¨ä¸”æœ‰ main.pyï¼Œè§†ä¸ºå·²éƒ¨ç½² (å…¼å®¹æ—§è„šæœ¬)
        if Path("/workspace/ComfyUI/main.py").exists():
            return True
        return False
    state = _load_setup_state()
    return state.get("deploy_completed", False)


# --- é‰´æƒ ---


LOGIN_PAGE = """<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>Login - Workspace Manager</title>
<style>
*{box-sizing:border-box;margin:0;padding:0}
body{font-family:'Inter',sans-serif;background:#0a0a0f;color:#e8e8f0;min-height:100vh;display:flex;align-items:center;justify-content:center}
.card{background:#1a1a28;border:1px solid #2a2a3e;border-radius:12px;padding:32px;width:360px;max-width:92vw}
.card h2{text-align:center;margin-bottom:20px;background:linear-gradient(135deg,#7c5cfc,#e879f9);-webkit-background-clip:text;background-clip:text;-webkit-text-fill-color:transparent}
input{width:100%;padding:10px 14px;background:#0e0e18;color:#e8e8f0;border:1px solid #2a2a3e;border-radius:8px;font-size:.9rem;margin-bottom:14px}
input:focus{border-color:#7c5cfc;outline:none}
button{width:100%;padding:10px;background:#7c5cfc;color:#fff;border:none;border-radius:8px;font-size:.9rem;cursor:pointer;font-weight:600}
button:hover{background:#9078ff}
.err{color:#f87171;font-size:.82rem;text-align:center;margin-bottom:10px}
</style></head>
<body><div class="card"><h2>Workspace Manager</h2>
<form method="POST" action="/login">
<div class="err" id="err">__ERR__</div>
<input name="password" type="password" placeholder="è¾“å…¥è®¿é—®å¯†ç ..." autofocus>
<button type="submit">ç™»å½•</button>
</form></div></body></html>"""


@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "GET":
        return Response(LOGIN_PAGE.replace("__ERR__", ""), mimetype="text/html")
    pw = request.form.get("password", "")
    if pw == DASHBOARD_PASSWORD:
        session["authed"] = True
        return redirect("/")
    return Response(LOGIN_PAGE.replace("__ERR__", "å¯†ç é”™è¯¯"), mimetype="text/html")


@app.route("/logout")
def logout():
    session.clear()
    return redirect("/login")


@app.before_request
def check_auth():
    """å…¨å±€é‰´æƒä¸ Setup Wizard è·¯ç”±"""
    # Setup ç›¸å…³è·¯ç”±å§‹ç»ˆå…è®¸
    if request.path.startswith("/api/setup/") or request.path == "/setup":
        return
    if request.path in ("/login", "/favicon.ico", "/dashboard.js"):
        return
    # å¦‚æœå°šæœªå®Œæˆéƒ¨ç½²å‘å¯¼, é‡å®šå‘åˆ°å‘å¯¼é¡µ
    if not _is_setup_complete():
        if request.path.startswith("/api/"):
            return jsonify({"error": "Setup not complete", "setup_required": True}), 503
        if request.path != "/":
            return redirect("/")
        return  # è®© index() å¤„ç†å‘å¯¼é¡µæ¸²æŸ“
    # æ­£å¸¸é‰´æƒ
    if not DASHBOARD_PASSWORD:
        return
    if session.get("authed"):
        return
    if request.path.startswith("/api/"):
        return jsonify({"error": "Unauthorized"}), 401
    return redirect("/login")


# --- å·¥å…·å‡½æ•° ---
def _get_api_key():
    if CONFIG_FILE.exists():
        try:
            return json.loads(CONFIG_FILE.read_text()).get("api_key", "")
        except Exception:
            return ""
    return ""

def _run_cmd(cmd, timeout=10):
    """è¿è¡Œ shell å‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
    try:
        r = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)
        return r.stdout.strip()
    except Exception as e:
        return f"Error: {e}"

def _sha256_file(filepath):
    """è®¡ç®—æ–‡ä»¶å®Œæ•´ SHA256 (CivitAI éœ€è¦å®Œæ•´æ–‡ä»¶å“ˆå¸Œ)"""
    sha = hashlib.sha256()
    try:
        with open(filepath, "rb") as f:
            while True:
                chunk = f.read(65536)
                if not chunk:
                    break
                sha.update(chunk)
        return sha.hexdigest().upper()
    except Exception:
        return None


# ====================================================================
# ç³»ç»Ÿç›‘æ§ API
# ====================================================================
@app.route("/api/system")
def api_system():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    info = {"cpu": {}, "memory": {}, "disk": {}, "gpu": [], "network": {}, "uptime": ""}

    # CPU
    try:
        import psutil
        info["cpu"]["percent"] = psutil.cpu_percent(interval=0.5)
        info["cpu"]["cores"] = psutil.cpu_count()
        info["cpu"]["freq"] = psutil.cpu_freq()._asdict() if psutil.cpu_freq() else {}
        load = os.getloadavg()
        info["cpu"]["load"] = {"1m": load[0], "5m": load[1], "15m": load[2]}
    except Exception as e:
        info["cpu"]["error"] = str(e)

    # Memory
    try:
        import psutil
        mem = psutil.virtual_memory()
        info["memory"] = {
            "total": mem.total, "used": mem.used, "available": mem.available,
            "percent": mem.percent
        }
    except Exception as e:
        info["memory"]["error"] = str(e)

    # Disk
    try:
        import psutil
        disk = psutil.disk_usage("/workspace" if os.path.exists("/workspace") else "/")
        info["disk"] = {
            "total": disk.total, "used": disk.used, "free": disk.free,
            "percent": disk.percent, "path": "/workspace"
        }
    except Exception as e:
        info["disk"]["error"] = str(e)

    # GPU (nvidia-smi)
    try:
        gpu_out = _run_cmd(
            "nvidia-smi --query-gpu=index,name,memory.total,memory.used,memory.free,"
            "utilization.gpu,temperature.gpu,power.draw,power.limit "
            "--format=csv,nounits,noheader", timeout=5
        )
        for line in gpu_out.strip().split("\n"):
            if not line.strip():
                continue
            parts = [p.strip() for p in line.split(",")]
            if len(parts) >= 9:
                info["gpu"].append({
                    "index": int(parts[0]), "name": parts[1],
                    "mem_total": int(parts[2]), "mem_used": int(parts[3]),
                    "mem_free": int(parts[4]), "util": int(parts[5]),
                    "temp": int(parts[6]),
                    "power": float(parts[7]) if parts[7] != "[N/A]" else 0,
                    "power_limit": float(parts[8]) if parts[8] != "[N/A]" else 0,
                })
    except Exception:
        pass

    # Network
    try:
        import psutil
        net = psutil.net_io_counters()
        info["network"] = {
            "bytes_sent": net.bytes_sent, "bytes_recv": net.bytes_recv,
            "packets_sent": net.packets_sent, "packets_recv": net.packets_recv,
        }
    except Exception:
        pass

    # Uptime
    try:
        info["uptime"] = _run_cmd("uptime -p", timeout=3)
    except Exception:
        pass

    return jsonify(info)


# ====================================================================
# æœåŠ¡ç®¡ç† API (PM2)
# ====================================================================
@app.route("/api/services")
def api_services():
    """è·å– PM2 æœåŠ¡åˆ—è¡¨"""
    try:
        out = _run_cmd("pm2 jlist", timeout=5)
        if out and not out.startswith("Error"):
            services = json.loads(out)
            result = []
            for s in services:
                result.append({
                    "name": s.get("name"),
                    "pm_id": s.get("pm_id"),
                    "status": s.get("pm2_env", {}).get("status"),
                    "cpu": s.get("monit", {}).get("cpu", 0),
                    "memory": s.get("monit", {}).get("memory", 0),
                    "restarts": s.get("pm2_env", {}).get("restart_time", 0),
                    "uptime": s.get("pm2_env", {}).get("pm_uptime", 0),
                    "pid": s.get("pid"),
                })
            return jsonify({"services": result})
        return jsonify({"services": [], "error": out})
    except Exception as e:
        return jsonify({"services": [], "error": str(e)})


@app.route("/api/services/<name>/<action>", methods=["POST"])
def api_service_action(name, action):
    """æ§åˆ¶æœåŠ¡: restart, stop, start"""
    if action not in ("restart", "stop", "start"):
        return jsonify({"error": "Invalid action"}), 400
    if not re.match(r'^[\w\-]+$', name):
        return jsonify({"error": "Invalid service name"}), 400
    out = _run_cmd(f"pm2 {action} {name}", timeout=10)
    return jsonify({"ok": True, "output": out})


# ====================================================================
# æ—¥å¿— API
# ====================================================================
@app.route("/api/logs/<name>")
def api_logs(name):
    """è·å– PM2 æ—¥å¿—"""
    if not re.match(r'^[\w\-]+$', name):
        return jsonify({"logs": "", "error": "Invalid service name"}), 400
    try:
        lines = int(request.args.get("lines", "100"))
        lines = min(max(lines, 1), 1000)
    except (ValueError, TypeError):
        lines = 100
    try:
        out = _run_cmd(f"pm2 logs {name} --nostream --lines {lines}", timeout=5)
        return jsonify({"logs": out})
    except Exception as e:
        return jsonify({"logs": "", "error": str(e)})


# ====================================================================
# é…ç½® API (CivitAI Key)
# ====================================================================
@app.route("/api/config", methods=["GET"])
def get_config():
    key = _get_api_key()
    return jsonify({
        "api_key": key, "has_key": bool(key),
        "key_preview": f"{key[:8]}...{key[-4:]}" if len(key) > 12 else ("****" if key else ""),
        "comfyui_dir": COMFYUI_DIR, "comfyui_url": COMFYUI_URL,
    })

@app.route("/api/config", methods=["POST"])
def save_config():
    data = request.get_json()
    api_key = data.get("api_key", "").strip()
    CONFIG_FILE.write_text(json.dumps({"api_key": api_key}))
    return jsonify({"ok": True, "has_key": bool(api_key)})


# ====================================================================
# CivitAI æœç´¢ä»£ç† (Meilisearch CORS bypass)
# ====================================================================
@app.route("/api/search", methods=["POST"])
def proxy_search():
    try:
        data = request.get_json(force=True, silent=True)
        if not data:
            return jsonify({"error": "No JSON body"}), 400

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {MEILI_BEARER}",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }

        resp = requests.post(MEILI_URL, headers=headers, json=data, timeout=10)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ====================================================================
# æœ¬åœ°æ¨¡å‹ç®¡ç† API
# ====================================================================
@app.route("/api/local_models")
def api_local_models():
    """æ‰«ææœ¬åœ°æ¨¡å‹æ–‡ä»¶"""
    category = request.args.get("category", "all")
    results = []

    dirs_to_scan = MODEL_DIRS if category == "all" else {category: MODEL_DIRS.get(category, "")}

    for cat, rel_dir in dirs_to_scan.items():
        full_dir = os.path.join(COMFYUI_DIR, rel_dir)
        if not os.path.isdir(full_dir):
            continue
        for root, _, files in os.walk(full_dir):
            for fname in files:
                ext = os.path.splitext(fname)[1].lower()
                if ext not in MODEL_EXTENSIONS:
                    continue
                fpath = os.path.join(root, fname)
                rel_path = os.path.relpath(fpath, os.path.join(COMFYUI_DIR, rel_dir))
                stat = os.stat(fpath)

                # Check for metadata files
                base_no_ext = os.path.splitext(fpath)[0]
                info_path = f"{fpath}.weilin-info.json"
                info_data = None
                if os.path.exists(info_path):
                    try:
                        with open(info_path, "r", encoding="utf-8") as f:
                            info_data = json.load(f)
                    except Exception:
                        pass

                # Check for preview image
                preview = None
                for pext in [".jpg", ".png", ".jpeg", ".webp"]:
                    ppath = base_no_ext + pext
                    if os.path.exists(ppath):
                        preview = os.path.relpath(ppath, COMFYUI_DIR)
                        break

                entry = {
                    "filename": fname,
                    "rel_path": rel_path,
                    "category": cat,
                    "size_bytes": stat.st_size,
                    "modified": stat.st_mtime,
                    "abs_path": fpath,
                    "has_info": info_data is not None,
                    "has_preview": preview is not None,
                    "preview_path": preview,
                }

                if info_data:
                    entry["name"] = info_data.get("name", fname)
                    entry["base_model"] = info_data.get("baseModel", "")
                    entry["type"] = info_data.get("type", cat)
                    entry["trained_words"] = [
                        w.get("word", "") for w in info_data.get("trainedWords", [])
                    ]
                    entry["links"] = info_data.get("links", [])
                    # Images from info
                    imgs = info_data.get("images", [])
                    if imgs:
                        entry["civitai_image"] = imgs[0].get("url", "")
                else:
                    entry["name"] = fname
                    entry["base_model"] = ""
                    entry["type"] = cat
                    entry["trained_words"] = []

                results.append(entry)

    results.sort(key=lambda x: x["modified"], reverse=True)
    return jsonify({"models": results, "total": len(results)})


@app.route("/api/local_models/preview")
def api_model_preview():
    """è¿”å›æ¨¡å‹é¢„è§ˆå›¾"""
    rel = request.args.get("path", "")
    full = os.path.join(COMFYUI_DIR, rel)
    if os.path.isfile(full):
        return send_file(full)
    return "", 404


@app.route("/api/local_models/delete", methods=["POST"])
def api_delete_model():
    """åˆ é™¤æœ¬åœ°æ¨¡å‹åŠå…¶å…³è”æ–‡ä»¶"""
    data = request.get_json()
    abs_path = data.get("abs_path", "")

    # å®‰å…¨æ£€æŸ¥
    if not abs_path.startswith(COMFYUI_DIR):
        return jsonify({"error": "è·¯å¾„ä¸åœ¨ ComfyUI ç›®å½•å†…"}), 403

    if not os.path.isfile(abs_path):
        return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404

    deleted = [abs_path]
    os.remove(abs_path)

    # åˆ é™¤å…³è”æ–‡ä»¶
    base_no_ext = os.path.splitext(abs_path)[0]
    for suffix in [".weilin-info.json", ".jpg", ".png", ".jpeg", ".webp", ".civitai.info"]:
        companion = (abs_path + suffix) if suffix.startswith(".weilin") else (base_no_ext + suffix)
        if os.path.exists(companion):
            os.remove(companion)
            deleted.append(companion)

    return jsonify({"ok": True, "deleted": deleted})


@app.route("/api/local_models/fetch_info", methods=["POST"])
def api_fetch_model_info():
    """é€šè¿‡ SHA256 ä» CivitAI è·å–æ¨¡å‹å…ƒæ•°æ®å¹¶ä¿å­˜"""
    data = request.get_json()
    abs_path = data.get("abs_path", "")

    # å®‰å…¨æ£€æŸ¥
    if not abs_path.startswith(COMFYUI_DIR):
        return jsonify({"error": "è·¯å¾„ä¸åœ¨ ComfyUI ç›®å½•å†…"}), 403

    if not os.path.isfile(abs_path):
        return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404

    # è®¡ç®— SHA256
    file_hash = _sha256_file(abs_path)
    if not file_hash:
        return jsonify({"error": "æ— æ³•è®¡ç®—å“ˆå¸Œ"}), 500

    # è°ƒç”¨ CivitAI API
    api_key = _get_api_key()
    headers = {}
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"

    try:
        api_url = f"https://civitai.com/api/v1/model-versions/by-hash/{file_hash}"
        resp = requests.get(api_url, headers=headers, timeout=30)
        if resp.status_code == 404:
            return jsonify({"error": "CivitAI æœªæ‰¾åˆ°è¯¥æ¨¡å‹", "hash": file_hash}), 404
        resp.raise_for_status()
        civitai_data = resp.json()
    except Exception as e:
        return jsonify({"error": f"API è¯·æ±‚å¤±è´¥: {e}", "hash": file_hash}), 500

    # æ„å»º weilin-info.json
    info_data = {
        "file": os.path.basename(abs_path),
        "path": abs_path,
        "sha256": file_hash,
        "name": civitai_data.get("model", {}).get("name", ""),
        "type": civitai_data.get("model", {}).get("type", ""),
        "baseModel": civitai_data.get("baseModel", ""),
        "images": [],
        "trainedWords": [],
        "links": [],
        "raw": {"civitai": civitai_data},
    }

    # ç‰ˆæœ¬å
    ver_name = civitai_data.get("name", "")
    if ver_name:
        info_data["name"] += f" - {ver_name}"

    # è§¦å‘è¯
    trigger_words = civitai_data.get("trainedWords", [])
    for w in trigger_words:
        info_data["trainedWords"].append({"word": w, "civitai": True})

    # Links
    model_id = civitai_data.get("modelId")
    version_id = civitai_data.get("id")
    if model_id:
        link = f"https://civitai.com/models/{model_id}"
        if version_id:
            link += f"?modelVersionId={version_id}"
        info_data["links"].append(link)

    # å›¾ç‰‡
    for img in civitai_data.get("images", []):
        img_url = img.get("url", "")
        if img_url:
            img_entry = {
                "url": img_url,
                "type": img.get("type", "image"),
                "width": img.get("width"),
                "height": img.get("height"),
                "nsfwLevel": img.get("nsfwLevel"),
            }
            meta = img.get("meta") or {}
            if meta:
                img_entry["positive"] = meta.get("prompt", "")
                img_entry["negative"] = meta.get("negativePrompt", "")
                img_entry["seed"] = meta.get("seed")
                img_entry["sampler"] = meta.get("sampler")
                img_entry["cfg"] = meta.get("cfgScale")
                img_entry["steps"] = meta.get("steps")
                img_entry["model"] = meta.get("Model")
            info_data["images"].append(img_entry)

    # ä¿å­˜ info json
    info_path = f"{abs_path}.weilin-info.json"
    with open(info_path, "w", encoding="utf-8") as f:
        json.dump(info_data, f, sort_keys=False, indent=2, ensure_ascii=False)

    # ä¸‹è½½é¢„è§ˆå›¾
    base_no_ext = os.path.splitext(abs_path)[0]
    if info_data["images"]:
        first_img_url = info_data["images"][0].get("url", "")
        if first_img_url:
            try:
                img_resp = requests.get(first_img_url, timeout=15, stream=True)
                img_resp.raise_for_status()
                ct = img_resp.headers.get("Content-Type", "")
                ext = ".png"
                if "jpeg" in ct or "jpg" in ct:
                    ext = ".jpeg"
                elif "webp" in ct:
                    ext = ".webp"
                preview_path = base_no_ext + ext
                with open(preview_path, "wb") as pf:
                    for chunk in img_resp.iter_content(4096):
                        pf.write(chunk)
                info_data["_preview_saved"] = preview_path
            except Exception:
                pass

    return jsonify({"ok": True, "info": info_data, "hash": file_hash})


# ====================================================================
# Enhanced-Civicomfy ä¸‹è½½ä»£ç†
# ====================================================================
@app.route("/api/download", methods=["POST"])
def api_download_model():
    """ä»£ç†è¯·æ±‚åˆ° ComfyUI çš„ Enhanced-Civicomfy ä¸‹è½½æ¥å£"""
    data = request.get_json()
    api_key = data.get("api_key") or _get_api_key()

    payload = {
        "model_url_or_id": data.get("model_id", ""),
        "model_type": data.get("model_type", "checkpoint"),
        "api_key": api_key,
        "num_connections": data.get("num_connections", 4),
    }
    if data.get("version_id"):
        payload["model_version_id"] = int(data["version_id"])
    if data.get("custom_filename"):
        payload["custom_filename"] = data["custom_filename"]

    try:
        resp = requests.post(f"{COMFYUI_URL}/civitai/download", json=payload, timeout=30)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except requests.exceptions.ConnectionError:
        return jsonify({"error": "ComfyUI æœªè¿è¡Œï¼Œæ— æ³•ä¸‹è½½ã€‚è¯·å…ˆå¯åŠ¨ ComfyUI æœåŠ¡ã€‚"}), 503
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/download/status")
def api_download_status():
    """è·å– Civicomfy ä¸‹è½½çŠ¶æ€"""
    try:
        resp = requests.get(f"{COMFYUI_URL}/civitai/status", timeout=5)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception:
        return jsonify({"queue": [], "active": [], "history": []}), 200


@app.route("/api/download/cancel", methods=["POST"])
def api_download_cancel():
    """å–æ¶ˆæŒ‡å®šä¸‹è½½ä»»åŠ¡"""
    data = request.get_json()
    download_id = data.get("download_id", "")
    if not download_id:
        return jsonify({"error": "download_id required"}), 400
    try:
        resp = requests.post(f"{COMFYUI_URL}/civitai/cancel", json={"download_id": download_id}, timeout=10)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/download/retry", methods=["POST"])
def api_download_retry():
    """é‡è¯•å¤±è´¥/å–æ¶ˆçš„ä¸‹è½½"""
    data = request.get_json()
    download_id = data.get("download_id", "")
    if not download_id:
        return jsonify({"error": "download_id required"}), 400
    try:
        resp = requests.post(f"{COMFYUI_URL}/civitai/retry", json={"download_id": download_id}, timeout=10)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/download/clear_history", methods=["POST"])
def api_download_clear_history():
    """æ¸…é™¤ä¸‹è½½å†å²"""
    try:
        resp = requests.post(f"{COMFYUI_URL}/civitai/clear_history", json={}, timeout=10)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/tunnel_links")
def api_tunnel_links():
    """è·å– Cloudflare Tunnel ä»£ç†çš„æœåŠ¡é“¾æ¥"""
    links = []
    # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
    tunnel_url = os.environ.get("CF_TUNNEL_URL", os.environ.get("TUNNEL_URL", ""))
    if tunnel_url:
        links.append({"name": "ComfyUI", "url": tunnel_url.rstrip("/"), "icon": "ğŸ¨"})
    jupyter_url = os.environ.get("JUPYTER_URL", "")
    if jupyter_url:
        links.append({"name": "Jupyter", "url": jupyter_url, "icon": "ğŸ““"})

    if not links:
        links = _parse_tunnel_ingress()

    vast_proxy = os.environ.get("VAST_PROXY_URL", "")
    if vast_proxy:
        links.append({"name": "Vast.ai Proxy", "url": vast_proxy, "icon": "â˜ï¸"})

    return jsonify({"links": links})


def _parse_tunnel_ingress():
    """ä» PM2 tunnel æ—¥å¿—ä¸­è§£æ Cloudflare Tunnel ingress é…ç½®"""
    links = []
    try:
        r = subprocess.run(
            "pm2 logs tunnel --nostream --lines 300 2>/dev/null",
            shell=True, capture_output=True, text=True, timeout=5
        )
        log = r.stdout + r.stderr
        import re as _re

        # Strategy 1: Parse config="{...}" with escaped JSON (named tunnels)
        # The JSON value has escaped quotes, so we can't use simple (.*?) â€” match
        # everything between config=" and the closing " that is NOT preceded by \
        cfg_match = _re.search(r'config="((?:[^"\\]|\\.)*)"', log)
        if cfg_match:
            raw = cfg_match.group(1).replace('\\"', '"').replace('\\\\', '\\')
            try:
                cfg = json.loads(raw)
                ingress = cfg.get("ingress", [])
                _tunnel_ingress_to_links(ingress, links)
            except (json.JSONDecodeError, ValueError):
                pass

        # Strategy 2: Look for "ingress" JSON array directly in logs
        if not links:
            # Sometimes the config is logged as plain JSON
            ing_match = _re.search(r'"ingress"\s*:\s*\[', log)
            if ing_match:
                # Find the matching closing bracket
                start = ing_match.start()
                brace_start = log.index('[', start)
                depth = 0
                end = brace_start
                for i in range(brace_start, min(brace_start + 5000, len(log))):
                    if log[i] == '[': depth += 1
                    elif log[i] == ']': depth -= 1
                    if depth == 0:
                        end = i + 1
                        break
                try:
                    ingress = json.loads(log[brace_start:end])
                    _tunnel_ingress_to_links(ingress, links)
                except (json.JSONDecodeError, ValueError):
                    pass

        # Strategy 3: Find hostnameâ†’URL mappings from "Registered tunnel connection" lines
        if not links:
            # Look for registered hostnames like "Updated to ... hostname=xxx.com"
            hostnames = _re.findall(r'hostname[=:]\s*([a-zA-Z0-9][a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', log)
            for h in set(hostnames):
                if 'cloudflare' not in h:
                    links.append({"name": h.split(".")[0].replace("-", " ").title(),
                                  "url": f"https://{h}", "icon": "ğŸŒ"})

        # Strategy 4: Fallback â€” trycloudflare quick tunnel URLs
        if not links:
            urls = list(set(_re.findall(r'https://[a-z0-9-]+\.trycloudflare\.com', log)))
            for i, u in enumerate(urls):
                links.append({"name": f"Service #{i+1}", "url": u, "icon": "ğŸŒ"})
    except Exception:
        pass
    return links


def _tunnel_ingress_to_links(ingress, links):
    """å°† Cloudflare Tunnel ingress åˆ—è¡¨è½¬æ¢ä¸ºæœåŠ¡é“¾æ¥"""
    port_services = _detect_port_services()
    jupyter_token = _get_jupyter_token()
    for entry in ingress:
        hostname = entry.get("hostname", "")
        service = entry.get("service", "")
        if not hostname or "http_status:" in service:
            continue
        import re as _re
        port_match = _re.search(r':(\d+)', service)
        port = port_match.group(1) if port_match else ""
        proto = "ssh" if service.startswith("ssh://") else "http"
        if proto == "ssh":
            continue
        svc_name = port_services.get(port, "")
        if not svc_name:
            svc_name = hostname.split(".")[0].replace("-", " ").title()
        icon = {"comfyui": "ğŸ¨", "jupyter": "ğŸ““", "dashboard": "ğŸ“Š"}.get(svc_name.lower(), "ğŸŒ")
        url = f"https://{hostname}"
        # Append Jupyter token if applicable
        if svc_name.lower() == "jupyter" and jupyter_token:
            url += f"/?token={jupyter_token}"
        links.append({
            "name": svc_name, "url": url,
            "icon": icon, "port": port, "service": service
        })


def _get_jupyter_token():
    """ä» jupyter server list è·å–è¿è¡Œä¸­çš„ Jupyter token"""
    try:
        r = subprocess.run(
            "jupyter server list 2>&1",
            shell=True, capture_output=True, text=True, timeout=5
        )
        output = r.stdout + r.stderr
        import re as _re
        # Match: https://host:port/?token=TOKEN :: /path
        # or:   http://host:port/?token=TOKEN :: /path
        match = _re.search(r'https?://[^?]+\?token=([a-f0-9]+)', output)
        if match:
            return match.group(1)
    except Exception:
        pass
    return ""


def _detect_port_services():
    """æ£€æµ‹æœ¬æœºç«¯å£å¯¹åº”çš„æœåŠ¡åç§°"""
    mapping = {}
    # å°è¯•ç”¨ PM2 è·å–åŠ¨æ€ç«¯å£æ˜ å°„
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True, capture_output=True, text=True, timeout=5)
        if r.returncode == 0:
            procs = json.loads(r.stdout)
            for p in procs:
                name = p.get("name", "")
                args = p.get("pm2_env", {}).get("args", [])
                if isinstance(args, list):
                    for i, a in enumerate(args):
                        if a == "--port" and i + 1 < len(args):
                            mapping[str(args[i + 1])] = name.title()
    except Exception:
        pass
    # å·²çŸ¥ç«¯å£ï¼ˆè¦†ç›– PM2 è‡ªåŠ¨æ£€æµ‹ï¼Œç¡®ä¿åç§°å‡†ç¡®ï¼‰
    mapping["8188"] = "ComfyUI"
    mapping["5000"] = "Dashboard"
    mapping["8080"] = "Jupyter"
    mapping["8888"] = "Jupyter"
    return mapping


@app.route("/api/tunnel_status")
def api_tunnel_status():
    """è·å– Tunnel çŠ¶æ€å’Œæ—¥å¿—"""
    import re as _re
    # PM2 è¿›ç¨‹ä¿¡æ¯
    status = "unknown"
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True, capture_output=True, text=True, timeout=5)
        if r.returncode == 0:
            procs = json.loads(r.stdout)
            for p in procs:
                if p.get("name") == "tunnel":
                    status = p.get("pm2_env", {}).get("status", "unknown")
                    break
    except Exception:
        pass

    # æ—¥å¿— (strip ANSI codes and PM2 prefixes)
    try:
        r = subprocess.run(
            "pm2 logs tunnel --nostream --lines 100 2>/dev/null",
            shell=True, capture_output=True, text=True, timeout=5
        )
        raw_logs = r.stdout + r.stderr
        # Strip ANSI escape codes
        ansi_re = _re.compile(r'\x1b\[[0-9;]*m')
        logs = ansi_re.sub('', raw_logs)
        # Strip PM2 prefix like "1|tunnel   | "
        logs = _re.sub(r'^\d+\|[^|]+\|\s*', '', logs, flags=_re.MULTILINE)
        # Strip PM2 tailing header lines
        logs = '\n'.join(l for l in logs.split('\n')
                        if not l.startswith('[TAILING]') and 'last 100 lines' not in l and '/root/.pm2/logs/' not in l)
    except Exception:
        logs = ""

    # Ingress é“¾æ¥
    links = _parse_tunnel_ingress()

    return jsonify({"status": status, "logs": logs, "links": links})


# ====================================================================
# Setup Wizard API
# ====================================================================
_deploy_thread = None
_deploy_log_lines = []       # å®æ—¶æ—¥å¿—è¡Œç¼“å†², SSE æ¶ˆè´¹
_deploy_log_lock = threading.Lock()


@app.route("/api/setup/state")
def api_setup_state():
    """è·å–å‘å¯¼çŠ¶æ€"""
    state = _load_setup_state()
    # ä¸è¿”å›æ•æ„Ÿå€¼çš„å®Œæ•´å†…å®¹
    safe = {k: v for k, v in state.items() if k != "deploy_log"}
    safe["has_rclone_config"] = bool(state.get("rclone_config_value"))
    safe["rclone_config_value"] = ""   # ä¸æš´éœ²
    safe["plugins_available"] = DEFAULT_PLUGINS
    # GPU ä¿¡æ¯ (å¦‚æœ torch å¯ç”¨)
    safe["gpu_info"] = _detect_gpu_info()
    return jsonify(safe)


@app.route("/api/setup/save", methods=["POST"])
def api_setup_save():
    """ä¿å­˜å‘å¯¼æŸä¸€æ­¥çš„é…ç½®"""
    data = request.get_json(force=True)
    state = _load_setup_state()
    # åˆå¹¶å‰ç«¯æäº¤çš„å­—æ®µ
    allowed_keys = {
        "current_step", "image_type", "password",
        "cloudflared_token", "rclone_config_method", "rclone_config_value",
        "civitai_token", "plugins",
    }
    for k, v in data.items():
        if k in allowed_keys:
            state[k] = v
    _save_setup_state(state)
    return jsonify({"ok": True})


@app.route("/api/setup/plugins")
def api_setup_plugins():
    """è¿”å›é»˜è®¤æ’ä»¶åˆ—è¡¨"""
    return jsonify({"plugins": DEFAULT_PLUGINS})


@app.route("/api/setup/deploy", methods=["POST"])
def api_setup_deploy():
    """å¼€å§‹éƒ¨ç½² â€” åœ¨åå°çº¿ç¨‹æ‰§è¡Œå…¨éƒ¨å®‰è£…é€»è¾‘"""
    global _deploy_thread
    if _deploy_thread and _deploy_thread.is_alive():
        return jsonify({"error": "éƒ¨ç½²å·²åœ¨è¿›è¡Œä¸­"}), 409

    state = _load_setup_state()
    state["deploy_started"] = True
    state["deploy_completed"] = False
    _save_setup_state(state)

    with _deploy_log_lock:
        _deploy_log_lines.clear()

    _deploy_thread = threading.Thread(target=_run_deploy, args=(dict(state),), daemon=True)
    _deploy_thread.start()
    return jsonify({"ok": True, "message": "éƒ¨ç½²å·²å¯åŠ¨"})


@app.route("/api/setup/log_stream")
def api_setup_log_stream():
    """SSE å®æ—¶æ—¥å¿—æµ"""
    def generate():
        idx = 0
        while True:
            with _deploy_log_lock:
                new_lines = _deploy_log_lines[idx:]
                idx = len(_deploy_log_lines)
            for line in new_lines:
                yield f"data: {json.dumps(line, ensure_ascii=False)}\n\n"
            # æ£€æŸ¥æ˜¯å¦ç»“æŸ
            state = _load_setup_state()
            if state.get("deploy_completed") and idx >= len(_deploy_log_lines):
                yield f"data: {json.dumps({'type': 'done', 'success': True}, ensure_ascii=False)}\n\n"
                break
            if not _deploy_thread or not _deploy_thread.is_alive():
                if not state.get("deploy_completed"):
                    yield f"data: {json.dumps({'type': 'done', 'success': False, 'msg': 'éƒ¨ç½²è¿›ç¨‹å¼‚å¸¸ç»ˆæ­¢'}, ensure_ascii=False)}\n\n"
                break
            time.sleep(0.5)
    return Response(generate(), mimetype="text/event-stream",
                    headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"})


@app.route("/api/setup/reset", methods=["POST"])
def api_setup_reset():
    """é‡ç½®å‘å¯¼ (è°ƒè¯•ç”¨)"""
    if SETUP_STATE_FILE.exists():
        SETUP_STATE_FILE.unlink()
    return jsonify({"ok": True})


def _detect_gpu_info():
    """æ£€æµ‹ GPU ä¿¡æ¯"""
    info = {"name": "", "cuda_cap": "", "vram_gb": 0}
    try:
        r = subprocess.run(
            'python3.13 -c "import torch; d=torch.cuda.get_device_properties(0); '
            'print(f\\"{d.name}|{d.major}.{d.minor}|{d.total_mem / 1073741824:.1f}\\")"',
            shell=True, capture_output=True, text=True, timeout=15
        )
        if r.returncode == 0 and "|" in r.stdout:
            parts = r.stdout.strip().split("|")
            info["name"] = parts[0]
            info["cuda_cap"] = parts[1]
            info["vram_gb"] = float(parts[2])
    except Exception:
        pass
    return info


# â”€â”€ éƒ¨ç½²æ‰§è¡Œå¼•æ“ â”€â”€
def _deploy_log(msg, level="info"):
    """å‘ SSE æ¨é€ä¸€è¡Œæ—¥å¿—"""
    entry = {"type": "log", "level": level, "msg": msg, "time": datetime.now().strftime("%H:%M:%S")}
    with _deploy_log_lock:
        _deploy_log_lines.append(entry)


def _deploy_step(name):
    """æ ‡è®°ä¸€ä¸ªéƒ¨ç½²æ­¥éª¤å¼€å§‹"""
    entry = {"type": "step", "name": name, "time": datetime.now().strftime("%H:%M:%S")}
    with _deploy_log_lock:
        _deploy_log_lines.append(entry)


def _deploy_exec(cmd, timeout=600, label=""):
    """æ‰§è¡Œ shell å‘½ä»¤, å®æ—¶æ¨é€è¾“å‡º"""
    if label:
        _deploy_log(f"$ {label}")
    try:
        proc = subprocess.Popen(
            cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
            text=True, bufsize=1
        )
        for line in proc.stdout:
            line = line.rstrip()
            if line:
                _deploy_log(line, "output")
        proc.wait(timeout=timeout)
        if proc.returncode != 0:
            _deploy_log(f"å‘½ä»¤é€€å‡ºç : {proc.returncode}", "warn")
        return proc.returncode == 0
    except Exception as e:
        _deploy_log(f"æ‰§è¡Œå¤±è´¥: {e}", "error")
        return False


def _run_deploy(config):
    """ä¸»éƒ¨ç½²æµç¨‹ â€” åœ¨åå°çº¿ç¨‹è¿è¡Œ, å®Œæ•´å¤åˆ» deploy.sh / deploy-prebuilt.sh é€»è¾‘"""
    import base64 as _b64

    PY = "python3.13"
    PIP = f"{PY} -m pip"
    image_type = config.get("image_type", "generic")

    try:
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 1: ç³»ç»Ÿä¾èµ–
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("å®‰è£…ç³»ç»Ÿä¾èµ–")
        _deploy_log("æ­£åœ¨å®‰è£…ç³»ç»Ÿä¾èµ–åŒ…...")
        _deploy_exec(
            "apt-get update -qq && "
            "apt-get install -y --no-install-recommends "
            "git git-lfs aria2 rclone jq curl ffmpeg libgl1 "
            "libglib2.0-0 libsm6 libxext6 build-essential",
            timeout=300, label="apt-get install"
        )

        # å°†ç³»ç»Ÿ python æŒ‡å‘ 3.13 (ä¿æŒåŸ deploy.sh é€»è¾‘)
        py313 = subprocess.run("command -v python3.13", shell=True, capture_output=True, text=True).stdout.strip()
        if py313:
            _deploy_exec(f'ln -sf "{py313}" /usr/local/bin/python && ln -sf "{py313}" /usr/bin/python || true')
        _deploy_exec(f'{PIP} install --upgrade pip setuptools packaging ninja -q', label="pip upgrade")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 2: Cloudflare Tunnel
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        cf_token = config.get("cloudflared_token", "")
        if cf_token:
            _deploy_step("å¯åŠ¨ Cloudflare Tunnel")
            # cloudflared å·²åœ¨ bootstrap.sh ä¸­å®‰è£…
            _deploy_exec("pm2 delete tunnel 2>/dev/null || true")
            _deploy_exec(f'pm2 start cloudflared --name tunnel -- tunnel run --token "{cf_token}"')
            _deploy_log("Cloudflare Tunnel å·²å¯åŠ¨")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 3: Rclone é…ç½®
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        rclone_method = config.get("rclone_config_method", "skip")
        rclone_value = config.get("rclone_config_value", "")
        if rclone_method != "skip" and rclone_value:
            _deploy_step("é…ç½® Rclone")
            _deploy_exec("mkdir -p ~/.config/rclone")
            if rclone_method == "url":
                _deploy_log(f"ä» URL ä¸‹è½½ rclone.conf...")
                _deploy_exec(f'curl -fsSL "{rclone_value}" -o ~/.config/rclone/rclone.conf')
            elif rclone_method == "base64":
                _deploy_log("ä» Base64 è§£ç  rclone.conf...")
                try:
                    conf_text = _b64.b64decode(rclone_value).decode("utf-8")
                    Path.home().joinpath(".config/rclone/rclone.conf").write_text(conf_text, encoding="utf-8")
                except Exception as e:
                    _deploy_log(f"Base64 è§£ç å¤±è´¥: {e}", "error")
            _deploy_exec("chmod 600 ~/.config/rclone/rclone.conf")
            _deploy_exec("rclone listremotes", label="æ£€æµ‹ remotes")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 4: PyTorch
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if image_type == "generic":
            _deploy_step("å®‰è£… PyTorch")
            TORCH_INDEX = "https://download.pytorch.org/whl/cu128"
            _deploy_log("å®‰è£… torch 2.9.1 (CUDA 12.8)...")
            _deploy_exec(
                f'{PIP} install --no-cache-dir torch==2.9.1 --index-url "{TORCH_INDEX}"',
                timeout=600, label="pip install torch"
            )
            _deploy_exec(f'{PIP} install --no-cache-dir hf_transfer', label="hf_transfer")
        else:
            _deploy_step("æ£€æŸ¥é¢„è£… PyTorch")
            _deploy_log("é¢„æ„å»ºé•œåƒ â€” è·³è¿‡ torch å®‰è£…")
            _deploy_exec(f'{PY} -c "import torch; print(f\\"PyTorch {{torch.__version__}} CUDA {{torch.version.cuda}}\\")"')

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 5: ComfyUI
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("å®‰è£… ComfyUI")
        if image_type == "prebuilt":
            # é¢„æ„å»ºé•œåƒ: ä» /opt/ComfyUI å¤åˆ¶
            if not Path("/workspace/ComfyUI/main.py").exists():
                _deploy_log("ä»é•œåƒå¤åˆ¶ ComfyUI...")
                _deploy_exec("mkdir -p /workspace/ComfyUI && cp -r /opt/ComfyUI/* /workspace/ComfyUI/")
            else:
                _deploy_log("ComfyUI å·²å­˜åœ¨, è·³è¿‡å¤åˆ¶")
        else:
            # é€šç”¨é•œåƒ: git clone
            if Path("/workspace/ComfyUI").exists():
                _deploy_exec("rm -rf /workspace/ComfyUI")
            _deploy_log("å…‹éš† ComfyUI ä»“åº“...")
            _deploy_exec("cd /workspace && git clone https://github.com/comfyanonymous/ComfyUI.git", timeout=120)
            _deploy_log("å®‰è£… ComfyUI ä¾èµ–...")
            _deploy_exec(f"cd /workspace/ComfyUI && {PIP} install --no-cache-dir -r requirements.txt", timeout=300)

        # å¥åº·æ£€æŸ¥ (ä¸åŸ deploy.sh å®Œå…¨ä¸€è‡´)
        _deploy_step("ComfyUI å¥åº·æ£€æŸ¥")
        _deploy_log("å¯åŠ¨é¦–æ¬¡å¥åº·æ£€æŸ¥...")
        _deploy_exec(f'cd /workspace/ComfyUI && {PY} main.py --listen 127.0.0.1 --port 8188 > /tmp/comfy_boot.log 2>&1 &')
        boot_ok = False
        for i in range(30):
            time.sleep(2)
            try:
                log = Path("/tmp/comfy_boot.log").read_text(errors="ignore")
                if "To see the GUI go to" in log:
                    boot_ok = True
                    break
            except Exception:
                pass
            _deploy_log(f"ç­‰å¾… ComfyUI å¯åŠ¨... ({i+1}/30)")

        # æ¸…ç†å¥åº·æ£€æŸ¥è¿›ç¨‹
        _deploy_exec("pkill -f 'main.py --listen 127.0.0.1 --port 8188' 2>/dev/null; sleep 1", label="åœæ­¢æ£€æŸ¥è¿›ç¨‹")

        if boot_ok:
            _deploy_log("âœ… ComfyUI å¥åº·æ£€æŸ¥é€šè¿‡")
        else:
            _deploy_log("âŒ ComfyUI å¥åº·æ£€æŸ¥å¤±è´¥!", "error")
            try:
                err = Path("/tmp/comfy_boot.log").read_text(errors="ignore")[-500:]
                _deploy_log(f"æœ€åæ—¥å¿—: {err}", "error")
            except Exception:
                pass
            # ä¸ä¸­æ–­, ç»§ç»­åç»­æ­¥éª¤

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 6: åŠ é€Ÿç»„ä»¶ (FA3 / SA3)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if image_type == "generic":
            _deploy_step("å®‰è£…åŠ é€Ÿç»„ä»¶ (FA3/SA3)")
            _deploy_log("æ£€æµ‹ GPU æ¶æ„...")
            gpu_info = _detect_gpu_info()
            cuda_cap = gpu_info.get("cuda_cap", "0.0")
            cuda_major = int(cuda_cap.split(".")[0]) if cuda_cap else 0
            _deploy_log(f"GPU: {gpu_info.get('name', '?')} | CUDA Cap: {cuda_cap}")

            # Python ç‰ˆæœ¬ tag
            py_ver_tag = subprocess.run(
                f'{PY} -c "import sys; print(f\\"cp{{sys.version_info.major}}{{sys.version_info.minor}}\\")"',
                shell=True, capture_output=True, text=True, timeout=5
            ).stdout.strip()

            # ä¸‹è½½é¢„ç¼–è¯‘ wheels
            GH_WHEELS = "https://github.com/vvb7456/ComfyUI_RunPod_Sync/releases/download/v4.5-wheels"
            _deploy_exec("mkdir -p /workspace/prebuilt_wheels")
            _deploy_exec(
                f'wget -q -O /workspace/prebuilt_wheels/flash_attn_3-3.0.0b1-cp39-abi3-linux_x86_64.whl '
                f'"{GH_WHEELS}/flash_attn_3-3.0.0b1-cp39-abi3-linux_x86_64.whl" || true',
                label="ä¸‹è½½ FA3 wheel"
            )
            if py_ver_tag in ("cp313", "cp312"):
                _deploy_exec(
                    f'wget -q -O /workspace/prebuilt_wheels/sageattn3-1.0.0-{py_ver_tag}-{py_ver_tag}-linux_x86_64.whl '
                    f'"{GH_WHEELS}/sageattn3-1.0.0-{py_ver_tag}-{py_ver_tag}-linux_x86_64.whl" || true',
                    label=f"ä¸‹è½½ SA3 wheel ({py_ver_tag})"
                )

            # FlashAttention å®‰è£… (ä¿æŒåŸ deploy.sh é€»è¾‘)
            if cuda_major >= 9:
                fa_wheel = "/workspace/prebuilt_wheels/flash_attn_3-3.0.0b1-cp39-abi3-linux_x86_64.whl"
                if not _deploy_exec(f'[ -f "{fa_wheel}" ] && {PIP} install "{fa_wheel}"'):
                    _deploy_log("Wheel ä¸å¯ç”¨, æºç ç¼–è¯‘ FA3...", "warn")
                    _deploy_exec(
                        f'cd /workspace && git clone https://github.com/Dao-AILab/flash-attention.git && '
                        f'cd flash-attention/hopper && MAX_JOBS=8 {PY} setup.py install && '
                        f'cd /workspace && rm -rf flash-attention',
                        timeout=1200, label="ç¼–è¯‘ FA3"
                    )
            else:
                _deploy_exec(f'{PIP} install --no-cache-dir flash-attn --no-build-isolation',
                             timeout=600, label="å®‰è£… FA2")

            # SageAttention å®‰è£… (ä¿æŒåŸ deploy.sh é€»è¾‘)
            if cuda_major >= 10:
                sa_wheel = f"/workspace/prebuilt_wheels/sageattn3-1.0.0-{py_ver_tag}-{py_ver_tag}-linux_x86_64.whl"
                if not _deploy_exec(f'[ -f "{sa_wheel}" ] && {PIP} install "{sa_wheel}"'):
                    _deploy_log("Wheel ä¸å¯ç”¨, æºç ç¼–è¯‘ SA3...", "warn")
                    _deploy_exec(
                        f'cd /workspace && git clone https://github.com/thu-ml/SageAttention.git && '
                        f'cd SageAttention/sageattention3_blackwell && {PY} setup.py install && '
                        f'cd /workspace && rm -rf SageAttention',
                        timeout=1200, label="ç¼–è¯‘ SA3"
                    )
            else:
                _deploy_exec(
                    f'cd /workspace && git clone https://github.com/thu-ml/SageAttention.git && '
                    f'cd SageAttention && {PIP} install . --no-build-isolation && '
                    f'cd /workspace && rm -rf SageAttention',
                    timeout=600, label="å®‰è£… SA2"
                )

            _deploy_exec("rm -rf /workspace/prebuilt_wheels")
            _deploy_log("âœ… åŠ é€Ÿç»„ä»¶å®‰è£…å®Œæˆ")
        else:
            _deploy_step("æ£€æŸ¥åŠ é€Ÿç»„ä»¶")
            _deploy_log("é¢„æ„å»ºé•œåƒ â€” FA3/SA3 å·²é¢„è£…, è·³è¿‡")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 7: æ’ä»¶å®‰è£…
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("å®‰è£…æ’ä»¶")
        plugins = config.get("plugins", [])
        if image_type == "prebuilt":
            _deploy_log("é¢„æ„å»ºé•œåƒå·²å«æ’ä»¶, æ£€æŸ¥é¢å¤–æ’ä»¶...")
            # åªå®‰è£…ä¸åœ¨é•œåƒä¸­çš„æ–°æ’ä»¶
            for url in plugins:
                name = url.rstrip("/").split("/")[-1].replace(".git", "")
                if not Path(f"/workspace/ComfyUI/custom_nodes/{name}").exists():
                    _deploy_log(f"å®‰è£…æ–°æ’ä»¶: {name}")
                    _deploy_exec(f'cd /workspace/ComfyUI/custom_nodes && git clone "{url}" || true', timeout=60)
        else:
            _deploy_log(f"å®‰è£… {len(plugins)} ä¸ªæ’ä»¶...")
            _deploy_exec("mkdir -p /workspace/ComfyUI/custom_nodes")
            for url in plugins:
                name = url.rstrip("/").split("/")[-1].replace(".git", "")
                _deploy_log(f"  å…‹éš† {name}...")
                _deploy_exec(f'cd /workspace/ComfyUI/custom_nodes && git clone "{url}" || true', timeout=60)

        # æ‰¹é‡å®‰è£…æ’ä»¶ä¾èµ–
        _deploy_log("å®‰è£…æ’ä»¶ä¾èµ–...")
        _deploy_exec(
            f'find /workspace/ComfyUI/custom_nodes -name "requirements.txt" -type f '
            f'-exec {PIP} install --no-cache-dir -r {{}} \\; 2>&1 || true',
            timeout=600, label="pip install plugin deps"
        )

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 8: R2 èµ„äº§åŒæ­¥
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if rclone_method != "skip" and rclone_value:
            _deploy_step("åŒæ­¥äº‘ç«¯èµ„äº§")
            # æ£€æµ‹ R2 remote
            r2_name = subprocess.run(
                "grep -E '^\\[(r2|.*r2.*)\\]' ~/.config/rclone/rclone.conf 2>/dev/null | head -n1 | tr -d '[]'",
                shell=True, capture_output=True, text=True
            ).stdout.strip()

            if r2_name:
                prefs = _load_sync_prefs()
                r2p = prefs.get("r2", {})
                if r2p.get("sync_workflows", True):
                    _deploy_log("åŒæ­¥å·¥ä½œæµ...")
                    _deploy_exec(
                        f'rclone sync "{r2_name}:comfyui-assets/workflow" /workspace/ComfyUI/user/default/workflows/ -P',
                        timeout=300
                    )
                if r2p.get("sync_loras", True):
                    _deploy_log("åŒæ­¥ LoRA...")
                    _deploy_exec(
                        f'rclone sync "{r2_name}:comfyui-assets/loras" /workspace/ComfyUI/models/loras/ -P',
                        timeout=300
                    )
                if r2p.get("sync_wildcards", True):
                    _deploy_log("åŒæ­¥ Wildcards...")
                    _deploy_exec(
                        f'rclone sync "{r2_name}:comfyui-assets/wildcards" '
                        f'/workspace/ComfyUI/custom_nodes/comfyui-dynamicprompts/wildcards/ -P',
                        timeout=300
                    )
                _deploy_log("âœ… èµ„äº§åŒæ­¥å®Œæˆ")
            else:
                _deploy_log("æœªæ£€æµ‹åˆ° R2 remote, è·³è¿‡èµ„äº§åŒæ­¥")
        else:
            _deploy_log("æœªé…ç½® Rclone, è·³è¿‡èµ„äº§åŒæ­¥")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 9: å¯åŠ¨æœåŠ¡
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("å¯åŠ¨æœåŠ¡")

        # Output äº‘ç«¯åŒæ­¥ (OneDrive / Google Drive)
        if rclone_method != "skip" and rclone_value:
            prefs = _load_sync_prefs()
            od = prefs.get("onedrive", {}).get("enabled", False)
            gd = prefs.get("gdrive", {}).get("enabled", False)
            if od or gd:
                _deploy_log("ç”Ÿæˆ cloud_sync.sh...")
                remotes = {r["name"]: r for r in _parse_rclone_conf()}
                _regenerate_sync_script(remotes, prefs)
                _deploy_exec("pm2 delete sync 2>/dev/null || true")
                _deploy_exec("pm2 start /workspace/cloud_sync.sh --name sync --log /workspace/sync.log")
                _deploy_log("âœ… äº‘ç«¯åŒæ­¥æœåŠ¡å·²å¯åŠ¨")

        # CivitAI API Key
        civitai_token = config.get("civitai_token", "")
        if civitai_token:
            CONFIG_FILE.write_text(json.dumps({"api_key": civitai_token}))
            _deploy_log("CivitAI API Key å·²ä¿å­˜")

        # å¯åŠ¨ ComfyUI
        _deploy_log("å¯åŠ¨ ComfyUI ä¸»æœåŠ¡...")
        _deploy_exec("pm2 delete comfy 2>/dev/null || true")
        _deploy_exec(
            f'cd /workspace/ComfyUI && pm2 start {PY} --name comfy '
            f'--interpreter none --log /workspace/comfy.log --time '
            f'--restart-delay 3000 --max-restarts 10 '
            f'-- main.py --listen 0.0.0.0 --port 8188 '
            f'--use-pytorch-cross-attention --fast --disable-xformers'
        )

        # ä¿å­˜ PM2 é…ç½®
        _deploy_exec("pm2 save 2>/dev/null || true")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 10: åå°ä»»åŠ¡
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("åå°ä»»åŠ¡")

        # jtoken å¿«æ·å‘½ä»¤
        _deploy_log("å®‰è£… jtoken å‘½ä»¤...")
        jtoken_script = '''#!/bin/bash
echo 'ğŸ” æ­£åœ¨æŸ¥æ‰¾ Jupyter ä¿¡æ¯...'
JUPYTER_TOKEN=$(ps aux | grep '[j]upyter-lab' | grep -oP 'token=\\K[a-zA-Z0-9-]+' | head -1)
JUPYTER_PORT=$(ps aux | grep '[j]upyter-lab' | grep -oP -- '--port=\\K[0-9]+' | head -1)
if [ -z "$JUPYTER_TOKEN" ]; then echo 'âŒ Jupyter Lab æœªè¿è¡Œ'; exit 1; fi
echo "ğŸ“Š Jupyter Lab: ç«¯å£=${JUPYTER_PORT:-æœªçŸ¥} Token=$JUPYTER_TOKEN"
if command -v pm2 >/dev/null 2>&1; then
    JUPYTER_DOMAIN=$(pm2 logs tunnel --nostream --lines 100 2>/dev/null | grep -oP 'dest=https://jupyter[^/]+' | head -1 | sed 's/dest=https:\\/\\///')
    [ -n "$JUPYTER_DOMAIN" ] && echo "ğŸŒ https://$JUPYTER_DOMAIN/?token=$JUPYTER_TOKEN"
fi
echo "ğŸ”— http://localhost:${JUPYTER_PORT}/?token=$JUPYTER_TOKEN"
'''
        Path("/usr/local/bin/jtoken").write_text(jtoken_script)
        _deploy_exec("chmod +x /usr/local/bin/jtoken")

        # AuraSR ä¸‹è½½
        _deploy_log("åå°ä¸‹è½½ AuraSR V2...")
        _deploy_exec("mkdir -p /workspace/ComfyUI/models/Aura-SR")
        _deploy_exec(
            'aria2c -x 16 -s 16 --console-log-level=error '
            '-d "/workspace/ComfyUI/models/Aura-SR" -o "model.safetensors" '
            '"https://huggingface.co/fal/AuraSR-v2/resolve/main/model.safetensors?download=true" &',
            label="AuraSR model"
        )
        _deploy_exec(
            'aria2c -x 16 -s 16 --console-log-level=error '
            '-d "/workspace/ComfyUI/models/Aura-SR" -o "config.json" '
            '"https://huggingface.co/fal/AuraSR-v2/resolve/main/config.json?download=true" &',
            label="AuraSR config"
        )

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # å®Œæˆ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("éƒ¨ç½²å®Œæˆ")

        # æ›´æ–° Dashboard å¯†ç 
        new_pw = config.get("password", "")
        if new_pw:
            global DASHBOARD_PASSWORD
            DASHBOARD_PASSWORD = new_pw
            _deploy_log(f"Dashboard å¯†ç å·²æ›´æ–°")

        state = _load_setup_state()
        state["deploy_completed"] = True
        _save_setup_state(state)

        gpu_info = _detect_gpu_info()
        _deploy_log(f"ğŸš€ éƒ¨ç½²å®Œæˆ! GPU: {gpu_info.get('name', '?')} | CUDA: {gpu_info.get('cuda_cap', '?')}")
        _deploy_log("è¯·åˆ·æ–°é¡µé¢è¿›å…¥ Dashboard")

    except Exception as e:
        _deploy_log(f"âŒ éƒ¨ç½²å¤±è´¥: {e}", "error")
        import traceback
        _deploy_log(traceback.format_exc(), "error")


# ====================================================================
# Cloud Sync (Rclone) ç®¡ç†
# ====================================================================
RCLONE_CONF = Path.home() / ".config" / "rclone" / "rclone.conf"
CLOUD_SYNC_SCRIPT = Path("/workspace/cloud_sync.sh")
SYNC_PREFS_FILE = Path("/workspace/.sync_prefs.json")


def _load_sync_prefs():
    """åŠ è½½åŒæ­¥åå¥½è®¾ç½®"""
    defaults = {
        "r2": {"enabled": True, "sync_workflows": True, "sync_loras": True, "sync_wildcards": True},
        "onedrive": {"enabled": True, "destination": "ComfyUI_Transfer"},
        "gdrive": {"enabled": False, "destination": "ComfyUI_Transfer"},
    }
    if SYNC_PREFS_FILE.exists():
        try:
            prefs = json.loads(SYNC_PREFS_FILE.read_text(encoding="utf-8"))
            # Merge with defaults
            for k, v in defaults.items():
                if k not in prefs:
                    prefs[k] = v
                else:
                    for dk, dv in v.items():
                        if dk not in prefs[k]:
                            prefs[k][dk] = dv
            return prefs
        except Exception:
            pass
    return defaults


def _save_sync_prefs(prefs):
    """ä¿å­˜åŒæ­¥åå¥½è®¾ç½®"""
    SYNC_PREFS_FILE.write_text(json.dumps(prefs, indent=2, ensure_ascii=False), encoding="utf-8")

def _parse_rclone_conf():
    """è§£æ rclone.conf è¿”å› remote åˆ—è¡¨"""
    remotes = []
    if not RCLONE_CONF.exists():
        return remotes
    current = None
    for line in RCLONE_CONF.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        m = re.match(r'^\[(.+)\]$', line)
        if m:
            if current:
                remotes.append(current)
            current = {"name": m.group(1), "type": "", "params": {},
                        "_has_token": False, "_has_keys": False}
        elif current and '=' in line:
            k, v = line.split('=', 1)
            k, v = k.strip(), v.strip()
            if k == "type":
                current["type"] = v
            if k == "token" and v:
                current["_has_token"] = True
            if k == "access_key_id" and v:
                current["_has_keys"] = True
            # ä¸è¦æš´éœ²æ•æ„Ÿ token
            if k not in ("token", "access_key_id", "secret_access_key", "refresh_token"):
                current["params"][k] = v
    if current:
        remotes.append(current)
    return remotes


def _parse_sync_log_entries(raw_log, max_entries=100):
    """å°† rclone æ—¥å¿—è§£æä¸ºç»“æ„åŒ–æ¡ç›®ï¼Œå¹¶é™„ä¸­æ–‡ç¿»è¯‘"""
    entries = []
    for line in raw_log.split('\n'):
        line = line.strip()
        if not line:
            continue
        # rclone log: 2026/02/16 02:15:55 INFO  : file.png: Copied (new)
        m = re.match(r'(\d{4}/\d{2}/\d{2}\s+\d{2}:\d{2}:\d{2})\s+(\w+)\s*:\s*(.*)', line)
        if m:
            ts, level, msg = m.group(1), m.group(2), m.group(3)
            cn_msg = _translate_rclone_msg(msg)
            entries.append({"time": ts, "level": level, "raw": msg, "msg": cn_msg})
        else:
            # è‡ªå®šä¹‰è¡Œå¦‚ [HH:MM:SS] New files detected
            m2 = re.match(r'\[(\d{2}:\d{2}:\d{2})\]\s*(.*)', line)
            if m2:
                entries.append({"time": m2.group(1), "level": "INFO", "raw": m2.group(2),
                                "msg": _translate_sync_event(m2.group(2))})
            elif line.startswith("Transferred:") or line.startswith("Checks:") or \
                    line.startswith("Deleted:") or line.startswith("Renamed:") or \
                    line.startswith("Elapsed"):
                entries.append({"time": "", "level": "STAT", "raw": line,
                                "msg": _translate_rclone_stat(line)})
    return entries[-max_entries:]


def _translate_rclone_msg(msg):
    """ç¿»è¯‘ rclone æ“ä½œæ¶ˆæ¯ä¸ºä¸­æ–‡"""
    # file.png: Copied (new)
    m = re.match(r'(.+?):\s*Copied\s*\(new\)', msg)
    if m:
        return f"ğŸ“¤ ä¸Šä¼ æ–°æ–‡ä»¶: {m.group(1)}"
    m = re.match(r'(.+?):\s*Copied\s*\(replaced existing\)', msg)
    if m:
        return f"ğŸ”„ è¦†ç›–æ›´æ–°: {m.group(1)}"
    m = re.match(r'(.+?):\s*Deleted', msg)
    if m:
        return f"ğŸ—‘ï¸ å·²åˆ é™¤æœ¬åœ°: {m.group(1)}"
    m = re.match(r'(.+?):\s*Moved', msg)
    if m:
        return f"ğŸ“¦ å·²ç§»åŠ¨: {m.group(1)}"
    if "There was nothing to transfer" in msg:
        return "âœ… æ— éœ€åŒæ­¥ï¼Œå…¨éƒ¨æœ€æ–°"
    if "Renamed" in msg:
        return f"ğŸ“ é‡å‘½å: {msg}"
    return msg


def _translate_sync_event(msg):
    """ç¿»è¯‘è‡ªå®šä¹‰åŒæ­¥äº‹ä»¶"""
    if "New files detected" in msg:
        return "ğŸ” æ£€æµ‹åˆ°æ–°æ–‡ä»¶ï¼Œå¼€å§‹åŒæ­¥..."
    if "OneDrive sync completed" in msg:
        return "âœ… OneDrive åŒæ­¥å®Œæˆ"
    if "Google Drive sync completed" in msg:
        return "âœ… Google Drive åŒæ­¥å®Œæˆ"
    if "Sync Service Started" in msg:
        return "ğŸš€ åŒæ­¥æœåŠ¡å·²å¯åŠ¨"
    return msg


def _translate_rclone_stat(line):
    """ç¿»è¯‘ rclone ç»Ÿè®¡è¡Œ"""
    if line.startswith("Transferred:") and "/" in line:
        # Transferred: 281.952 KiB / 281.952 KiB, 100%, 94.052 KiB/s
        parts = line.split(",")
        size_part = parts[0].replace("Transferred:", "").strip()
        return f"ğŸ“Š å·²ä¼ è¾“: {size_part}" + (f" ({parts[1].strip()})" if len(parts) > 1 else "")
    if line.startswith("Deleted:"):
        return f"ğŸ—‘ï¸ {line}"
    if line.startswith("Elapsed"):
        return f"â±ï¸ {line}"
    if line.startswith("Checks:"):
        return f"ğŸ” {line}"
    return line


@app.route("/api/sync/status")
def api_sync_status():
    """è·å– Cloud Sync çŠ¶æ€ã€æ—¥å¿—å’Œé…ç½®"""
    # PM2 è¿›ç¨‹çŠ¶æ€
    status = "unknown"
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True, capture_output=True, text=True, timeout=5)
        if r.returncode == 0:
            for p in json.loads(r.stdout):
                if p.get("name") == "sync":
                    status = p.get("pm2_env", {}).get("status", "unknown")
                    break
    except Exception:
        pass

    # åŒæ­¥æ—¥å¿—
    try:
        r = subprocess.run(
            "pm2 logs sync --nostream --lines 150 2>/dev/null",
            shell=True, capture_output=True, text=True, timeout=5
        )
        raw = r.stdout + r.stderr
        # Strip ANSI and PM2 prefix
        raw = re.sub(r'\x1b\[[0-9;]*m', '', raw)
        raw = re.sub(r'^\d+\|[^|]+\|\s*', '', raw, flags=re.MULTILINE)
        raw = '\n'.join(l for l in raw.split('\n')
                       if not l.startswith('[TAILING]') and 'last 150 lines' not in l
                       and '/root/.pm2/logs/' not in l)
        entries = _parse_sync_log_entries(raw)
    except Exception:
        entries = []

    # å½“å‰åŒæ­¥åå¥½
    prefs = _load_sync_prefs()

    return jsonify({
        "status": status,
        "entries": entries,
        "prefs": prefs
    })


@app.route("/api/sync/remotes")
def api_sync_remotes():
    """åˆ—å‡º rclone é…ç½®çš„ remoteï¼ŒåŒ…å«åŒæ­¥åå¥½"""
    remotes = _parse_rclone_conf()
    prefs = _load_sync_prefs()
    for r in remotes:
        t = r["type"]
        if t == "s3":
            r["category"] = "r2"
            r["display_name"] = "Cloudflare R2"
            r["icon"] = "â˜ï¸"
            r["prefs"] = prefs.get("r2", {})
        elif "onedrive" in t:
            r["category"] = "onedrive"
            r["display_name"] = "OneDrive"
            r["icon"] = "ğŸ“"
            r["prefs"] = prefs.get("onedrive", {})
        elif t == "drive":
            r["category"] = "gdrive"
            r["display_name"] = "Google Drive"
            r["icon"] = "ğŸ“‚"
            r["prefs"] = prefs.get("gdrive", {})
        else:
            r["category"] = "other"
            r["display_name"] = r["name"]
            r["icon"] = "ğŸ’¾"
            r["prefs"] = {}
        # Auth status â€” check if token/keys exist
        r["has_auth"] = bool(r.get("_has_token") or r.get("_has_keys"))
    return jsonify({"remotes": remotes, "prefs": prefs})


@app.route("/api/sync/storage")
def api_sync_storage():
    """è·å–å„ remote çš„å®¹é‡ä¿¡æ¯"""
    remotes = _parse_rclone_conf()
    results = {}
    for r in remotes:
        name = r["name"]
        try:
            proc = subprocess.run(
                f"rclone about {name}: --json 2>/dev/null",
                shell=True, capture_output=True, text=True, timeout=30
            )
            if proc.returncode == 0:
                about = json.loads(proc.stdout)
                results[name] = {
                    "total": about.get("total"),
                    "used": about.get("used"),
                    "free": about.get("free"),
                    "trashed": about.get("trashed"),
                }
            else:
                results[name] = {"error": "ä¸æ”¯æŒå®¹é‡æŸ¥è¯¢"}
        except subprocess.TimeoutExpired:
            results[name] = {"error": "æŸ¥è¯¢è¶…æ—¶"}
        except Exception as e:
            results[name] = {"error": str(e)}
    return jsonify({"storage": results})


@app.route("/api/sync/toggle", methods=["POST"])
def api_sync_toggle():
    """æ›´æ–°åŒæ­¥åå¥½è®¾ç½®"""
    data = request.get_json(force=True)
    category = data.get("category", "")  # r2, onedrive, gdrive
    updates = data.get("updates", {})    # e.g. {"enabled": true, "sync_loras": false}

    prefs = _load_sync_prefs()
    if category not in prefs:
        prefs[category] = {}
    prefs[category].update(updates)
    _save_sync_prefs(prefs)

    # å¦‚æœæ˜¯ output sync ç›¸å…³çš„å˜æ›´ï¼Œé‡æ–°ç”Ÿæˆ cloud_sync.sh
    if category in ("onedrive", "gdrive") and "enabled" in updates:
        remotes = {r["name"]: r for r in _parse_rclone_conf()}
        _regenerate_sync_script(remotes, prefs)
        subprocess.run("pm2 restart sync 2>/dev/null", shell=True, timeout=10)

    return jsonify({"ok": True, "message": "è®¾ç½®å·²ä¿å­˜", "prefs": prefs})


def _regenerate_sync_script(remotes, prefs):
    """é‡æ–°ç”Ÿæˆ cloud_sync.shï¼Œæ ¹æ®åå¥½è®¾ç½®æ§åˆ¶å“ªäº› remote å‚ä¸è¾“å‡ºåŒæ­¥"""
    onedrive_enabled = prefs.get("onedrive", {}).get("enabled", False)
    gdrive_enabled = prefs.get("gdrive", {}).get("enabled", False)

    # æ‰¾åˆ°å®é™… remote åç§°
    onedrive_name = ""
    gdrive_name = ""
    for name, r in remotes.items():
        if r["type"] == "onedrive" or "onedrive" in name.lower():
            onedrive_name = name
        elif r["type"] == "drive" or "gdrive" in name.lower():
            gdrive_name = name

    od_dest = prefs.get("onedrive", {}).get("destination", "ComfyUI_Transfer")
    gd_dest = prefs.get("gdrive", {}).get("destination", "ComfyUI_Transfer")

    # æ„å»º sync å—
    sync_blocks = []
    if onedrive_enabled and onedrive_name:
        sync_blocks.append(f'''        # OneDrive åŒæ­¥
        rclone move "$SOURCE_DIR" "{onedrive_name}:{od_dest}" \\
            --min-age "30s" \\
            --filter "+ *.{{png,jpg,jpeg,webp,gif,mp4,mov,webm}}" \\
            --filter "- .*/**" \\
            --filter "- *" \\
            --transfers 4 -v && echo "[$TIME] OneDrive sync completed"''')

    if gdrive_enabled and gdrive_name:
        sync_blocks.append(f'''        # Google Drive åŒæ­¥
        rclone move "$SOURCE_DIR" "{gdrive_name}:{gd_dest}" \\
            --min-age "30s" \\
            --filter "+ *.{{png,jpg,jpeg,webp,gif,mp4,mov,webm}}" \\
            --filter "- .*/**" \\
            --filter "- *" \\
            --transfers 4 -v && echo "[$TIME] Google Drive sync completed"''')

    # ç”Ÿæˆå¯ç”¨ä¿¡æ¯
    info_lines = []
    if onedrive_name:
        info_lines.append(f'echo "  OneDrive: {onedrive_name} ({"å¯ç”¨" if onedrive_enabled else "ç¦ç”¨"})"')
    if gdrive_name:
        info_lines.append(f'echo "  Google Drive: {gdrive_name} ({"å¯ç”¨" if gdrive_enabled else "ç¦ç”¨"})"')

    script = f'''#!/bin/bash
SOURCE_DIR="/workspace/ComfyUI/output"

echo "--- Cloud Sync Service Started ---"
{chr(10).join(info_lines)}

while true; do
    FOUND_FILES=$(find "$SOURCE_DIR" -type f -mmin +0.5 \\( -iname "*.png" -o -iname "*.jpg" -o -iname "*.mp4" -o -iname "*.webp" \\) ! -path '*/.*' -print -quit)

    if [ -n "$FOUND_FILES" ]; then
        TIME=$(date '+%H:%M:%S')
        echo "[$TIME] New files detected. Syncing..."

{chr(10).join(sync_blocks) if sync_blocks else '        echo "[$TIME] No remotes enabled, skipping"'}

    fi
    sleep 10
done
'''
    CLOUD_SYNC_SCRIPT.write_text(script, encoding="utf-8")
    CLOUD_SYNC_SCRIPT.chmod(0o755)


@app.route("/api/sync/rclone_config", methods=["GET"])
def api_get_rclone_config():
    """è·å– rclone.conf å®Œæ•´å†…å®¹ï¼ˆDashboard å·²æœ‰å¯†ç ä¿æŠ¤ï¼‰"""
    if not RCLONE_CONF.exists():
        return jsonify({"config": "", "exists": False})
    raw = RCLONE_CONF.read_text(encoding="utf-8")
    return jsonify({"config": raw, "exists": True})


@app.route("/api/sync/rclone_config", methods=["POST"])
def api_save_rclone_config():
    """ä¿å­˜ rclone.conf"""
    data = request.get_json(force=True)
    config_text = data.get("config", "")

    if not config_text.strip():
        return jsonify({"error": "é…ç½®å†…å®¹ä¸èƒ½ä¸ºç©º"}), 400

    # åŸºæœ¬è¯­æ³•æ ¡éªŒï¼šè‡³å°‘æœ‰ä¸€ä¸ª [remote] æ®µ
    sections = re.findall(r'^\[.+\]', config_text, re.MULTILINE)
    if not sections:
        return jsonify({"error": "é…ç½®æ ¼å¼é”™è¯¯ï¼šè‡³å°‘éœ€è¦ä¸€ä¸ª [remote] æ®µ"}), 400

    # å¤‡ä»½æ—§é…ç½®
    if RCLONE_CONF.exists():
        backup = RCLONE_CONF.with_suffix('.conf.bak')
        backup.write_text(RCLONE_CONF.read_text(encoding="utf-8"), encoding="utf-8")

    # å†™å…¥æ–°é…ç½®
    RCLONE_CONF.parent.mkdir(parents=True, exist_ok=True)
    RCLONE_CONF.write_text(config_text, encoding="utf-8")
    RCLONE_CONF.chmod(0o600)

    # éªŒè¯é…ç½®æ˜¯å¦å¯ç”¨
    try:
        r = subprocess.run("rclone listremotes 2>&1", shell=True, capture_output=True, text=True, timeout=5)
        remotes = [l.strip().rstrip(':') for l in r.stdout.strip().split('\n') if l.strip()]
    except Exception:
        remotes = []

    return jsonify({"ok": True, "message": f"é…ç½®å·²ä¿å­˜ï¼Œæ£€æµ‹åˆ° {len(remotes)} ä¸ª remote: {', '.join(remotes)}"})


@app.route("/api/sync/import_config", methods=["POST"])
def api_import_config():
    """ä» URL æˆ– base64 å¯¼å…¥ rclone.conf"""
    import base64
    data = request.get_json(force=True)
    import_type = data.get("type", "")
    value = data.get("value", "")

    config_text = ""
    if import_type == "url" and value:
        try:
            resp = requests.get(value, timeout=15)
            resp.raise_for_status()
            config_text = resp.text
        except Exception as e:
            return jsonify({"error": f"ä¸‹è½½å¤±è´¥: {e}"}), 400
    elif import_type == "base64" and value:
        try:
            config_text = base64.b64decode(value).decode("utf-8")
        except Exception as e:
            return jsonify({"error": f"Base64 è§£ç å¤±è´¥: {e}"}), 400
    else:
        return jsonify({"error": "è¯·æä¾› type (url/base64) å’Œ value"}), 400

    # éªŒè¯
    sections = re.findall(r'^\[.+\]', config_text, re.MULTILINE)
    if not sections:
        return jsonify({"error": "å¯¼å…¥çš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„ rclone é…ç½®"}), 400

    # å¤‡ä»½ + å†™å…¥
    if RCLONE_CONF.exists():
        backup = RCLONE_CONF.with_suffix('.conf.bak')
        backup.write_text(RCLONE_CONF.read_text(encoding="utf-8"), encoding="utf-8")
    RCLONE_CONF.parent.mkdir(parents=True, exist_ok=True)
    RCLONE_CONF.write_text(config_text, encoding="utf-8")
    RCLONE_CONF.chmod(0o600)

    # åˆ—å‡º remotes
    try:
        r = subprocess.run("rclone listremotes 2>&1", shell=True, capture_output=True, text=True, timeout=5)
        remotes = [l.strip().rstrip(':') for l in r.stdout.strip().split('\n') if l.strip()]
    except Exception:
        remotes = []

    return jsonify({"ok": True, "message": f"å¯¼å…¥æˆåŠŸï¼Œæ£€æµ‹åˆ° {len(remotes)} ä¸ª remote: {', '.join(remotes)}"})


# ====================================================================
# å‰ç«¯é¡µé¢
# ====================================================================
@app.route("/")
def index():
    # å¦‚æœå‘å¯¼æœªå®Œæˆï¼Œæ˜¾ç¤ºå‘å¯¼é¡µé¢
    if not _is_setup_complete():
        wizard_path = Path(__file__).parent / "setup_wizard.html"
        if wizard_path.exists():
            return Response(wizard_path.read_text(encoding="utf-8"), mimetype="text/html")
        return Response("<h1>setup_wizard.html not found</h1>", mimetype="text/html", status=404)
    html_path = Path(__file__).parent / "dashboard.html"
    if html_path.exists():
        return Response(html_path.read_text(encoding="utf-8"), mimetype="text/html")
    return Response("<h1>dashboard.html not found</h1>", mimetype="text/html", status=404)


@app.route("/dashboard.js")
def serve_js():
    js_path = Path(__file__).parent / "dashboard.js"
    if js_path.exists():
        return Response(js_path.read_text(encoding="utf-8"), mimetype="application/javascript")
    return "", 404


@app.route("/static/<path:filename>")
def serve_static(filename):
    """é€šç”¨é™æ€æ–‡ä»¶æœåŠ¡"""
    base_dir = Path(__file__).parent.resolve()
    safe_path = (base_dir / filename).resolve()
    if not str(safe_path).startswith(str(base_dir)):
        return "", 403
    if safe_path.exists() and safe_path.is_file():
        return send_file(str(safe_path))
    return "", 404


# ====================================================================
# å¯åŠ¨
# ====================================================================
if __name__ == "__main__":
    port = int(sys.argv[1]) if len(sys.argv) > 1 else MANAGER_PORT

    # ä»ç¯å¢ƒå˜é‡å¯¼å…¥ API Key
    if os.environ.get("CIVITAI_TOKEN") and not _get_api_key():
        CONFIG_FILE.write_text(json.dumps({"api_key": os.environ["CIVITAI_TOKEN"]}))
        print(f"  ğŸ“ å·²ä»ç¯å¢ƒå˜é‡ CIVITAI_TOKEN å¯¼å…¥ API Key")

    print(f"\n{'='*50}")
    print(f"  ğŸ–¥ï¸  Workspace Manager v1.0")
    print(f"  è®¿é—®åœ°å€: http://localhost:{port}")
    print(f"  ComfyUI:  {COMFYUI_DIR}")
    print(f"{'='*50}\n")
    app.run(host="0.0.0.0", port=port, debug=False)
