#!/usr/bin/env python3
"""
Workspace Manager v1.0 - ComfyUI RunPod/Vast éƒ¨ç½²ç®¡ç†å™¨
- ä»ªè¡¨ç›˜: ç³»ç»Ÿç›‘æ§, æœåŠ¡æ§åˆ¶
- æ¨¡å‹ç®¡ç†: æœ¬åœ°æ¨¡å‹æ‰«æ, CivitAI æŸ¥è¯¢, Enhanced-Civicomfy ä¸‹è½½
- æ—¥å¿—æŸ¥çœ‹: PM2 æ—¥å¿—å®æ—¶æŸ¥çœ‹

å¯åŠ¨: python workspace_manager.py [port]
"""

import json
import os
import sys
import subprocess
import hashlib
import threading
import time
import re
import secrets
import shlex
import uuid
import queue
from pathlib import Path
from datetime import datetime

import requests
from flask import Flask, jsonify, request, Response, send_file, redirect, session
from flask_cors import CORS

app = Flask(__name__, static_folder=None)
CORS(app)

# --- é…ç½® ---
COMFYUI_DIR = os.environ.get("COMFYUI_DIR", "/workspace/ComfyUI")
COMFYUI_URL = os.environ.get("COMFYUI_URL", "http://localhost:8188")
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_FILE = Path(__file__).parent / ".civitai_config.json"
MEILI_URL = 'https://search.civitai.com/multi-search'
MEILI_BEARER = '8c46eb2508e21db1e9828a97968d91ab1ca1caa5f70a00e88a2ba1e286603b61'
MANAGER_PORT = int(os.environ.get("MANAGER_PORT", 5000))

# â”€â”€ æŒä¹…åŒ–é…ç½® (.dashboard_env) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# æ‰€æœ‰ç”¨æˆ·å¯ä¿®æ”¹çš„è¿è¡Œæ—¶é…ç½®ç»Ÿä¸€å­˜å‚¨åœ¨æ­¤æ–‡ä»¶
DASHBOARD_ENV_FILE = Path("/workspace/.dashboard_env")

def _load_config():
    """ä» .dashboard_env åŠ è½½å…¨éƒ¨é…ç½®"""
    if DASHBOARD_ENV_FILE.exists():
        try:
            return json.loads(DASHBOARD_ENV_FILE.read_text(encoding="utf-8"))
        except Exception:
            pass
    return {}

def _save_config(data):
    """å†™å…¥ .dashboard_env"""
    DASHBOARD_ENV_FILE.write_text(json.dumps(data, indent=2, ensure_ascii=False), encoding="utf-8")

def _get_config(key, default=""):
    """è¯»å–å•ä¸ªé…ç½®å€¼"""
    return _load_config().get(key, default)

_config_lock = threading.Lock()

def _set_config(key, value):
    """å†™å…¥å•ä¸ªé…ç½®å€¼ (çº¿ç¨‹å®‰å…¨)"""
    with _config_lock:
        data = _load_config()
        data[key] = value
        _save_config(data)

# â”€â”€ å¯†ç  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_dashboard_password():
    """ä¼˜å…ˆ .dashboard_env > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼"""
    pw = _get_config("password")
    if pw:
        return pw
    env_pw = os.environ.get("DASHBOARD_PASSWORD", "")
    if env_pw:
        return env_pw
    return "comfy2025"

def _save_dashboard_password(pw):
    _set_config("password", pw)

DASHBOARD_PASSWORD = _load_dashboard_password()

# â”€â”€ Session Secret (æŒä¹…åŒ– â†’ é‡å¯ä¸æ‰çº¿) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _load_session_secret():
    """ä» .dashboard_env è¯» session_secret, ä¸å­˜åœ¨åˆ™ç”Ÿæˆå¹¶ä¿å­˜"""
    existing = _get_config("session_secret")
    if existing:
        return existing
    new_secret = secrets.token_hex(32)
    _set_config("session_secret", new_secret)
    return new_secret

app.secret_key = _load_session_secret()

# æ¨¡å‹ç›®å½•æ˜ å°„
MODEL_DIRS = {
    "checkpoints": "models/checkpoints",
    "loras": "models/loras",
    "controlnet": "models/controlnet",
    "vae": "models/vae",
    "upscale_models": "models/upscale_models",
    "embeddings": "models/embeddings",
    "clip": "models/clip",
    "unet": "models/unet",
    "clip_vision": "models/clip_vision",
}

MODEL_EXTENSIONS = {".safetensors", ".ckpt", ".pt", ".pth", ".bin"}

# --- Setup Wizard State ---
SETUP_STATE_FILE = Path("/workspace/.setup_state.json")

# é»˜è®¤æ’ä»¶åˆ—è¡¨ (ä¸åŸ deploy.sh å®Œå…¨ä¸€è‡´)
DEFAULT_PLUGINS = [
    {"url": "https://github.com/ltdrdata/ComfyUI-Manager", "name": "ComfyUI-Manager", "required": True},
    {"url": "https://github.com/Fannovel16/comfyui_controlnet_aux", "name": "ControlNet Aux"},
    {"url": "https://github.com/ltdrdata/ComfyUI-Impact-Pack", "name": "Impact Pack"},
    {"url": "https://github.com/yolain/ComfyUI-Easy-Use", "name": "Easy Use"},
    {"url": "https://github.com/crystian/ComfyUI-Crystools", "name": "Crystools"},
    {"url": "https://github.com/ssitu/ComfyUI_UltimateSDUpscale", "name": "Ultimate SD Upscale"},
    {"url": "https://github.com/adieyal/comfyui-dynamicprompts", "name": "Dynamic Prompts"},
    {"url": "https://github.com/weilin9999/WeiLin-Comfyui-Tools", "name": "WeiLin Tools"},
    {"url": "https://github.com/GreenLandisaLie/AuraSR-ComfyUI", "name": "AuraSR"},
    {"url": "https://github.com/ltdrdata/was-node-suite-comfyui", "name": "WAS Node Suite"},
    {"url": "https://github.com/kijai/ComfyUI-KJNodes", "name": "KJNodes"},
    {"url": "https://github.com/BenjaMITM/Enhanced-Civicomfy", "name": "Enhanced Civicomfy", "required": True},
    {"url": "https://github.com/pythongosssss/ComfyUI-WD14-Tagger", "name": "WD14 Tagger"},
    {"url": "https://github.com/rgthree/rgthree-comfy", "name": "rgthree"},
    {"url": "https://github.com/ltdrdata/ComfyUI-Inspire-Pack", "name": "Inspire Pack"},
]


def _load_setup_state():
    """åŠ è½½ Setup Wizard çŠ¶æ€"""
    defaults = {
        "completed": False,
        "current_step": 0,
        "image_type": "",         # "generic" or "prebuilt"
        "password": "",
        "cloudflared_token": "",
        "rclone_config_method": "",  # "url", "base64", "skip"
        "rclone_config_value": "",
        "civitai_token": "",
        "plugins": [p["url"] for p in DEFAULT_PLUGINS],
        "deploy_started": False,
        "deploy_completed": False,
        "deploy_error": "",
        "deploy_steps_completed": [],
        "deploy_log": [],
    }
    if SETUP_STATE_FILE.exists():
        try:
            state = json.loads(SETUP_STATE_FILE.read_text(encoding="utf-8"))
            for k, v in defaults.items():
                if k not in state:
                    state[k] = v
            return state
        except Exception:
            pass
    return defaults


def _save_setup_state(state):
    """ä¿å­˜ Setup Wizard çŠ¶æ€"""
    SETUP_STATE_FILE.write_text(json.dumps(state, indent=2, ensure_ascii=False), encoding="utf-8")


def _is_setup_complete():
    """æ£€æŸ¥éƒ¨ç½²æ˜¯å¦å·²å®Œæˆ"""
    if not SETUP_STATE_FILE.exists():
        # å¦‚æœ ComfyUI å·²å­˜åœ¨ä¸”æœ‰ main.pyï¼Œè§†ä¸ºå·²éƒ¨ç½² (å…¼å®¹æ—§è„šæœ¬)
        if Path("/workspace/ComfyUI/main.py").exists():
            return True
        return False
    state = _load_setup_state()
    return state.get("deploy_completed", False)


# --- é‰´æƒ ---


LOGIN_PAGE = """<!DOCTYPE html>
<html lang="zh-CN">
<head>
<meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>Login - ComfyCarry</title>
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;500;600;700&family=IBM+Plex+Sans+SC:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
*{box-sizing:border-box;margin:0;padding:0}
body{font-family:'IBM Plex Sans','IBM Plex Sans SC',-apple-system,sans-serif;background:#0a0a0f;color:#e8e8f0;min-height:100vh;display:flex;align-items:center;justify-content:center;font-size:clamp(15px,1.1vw,21px)}
.card{background:#1a1a28;border:1px solid #2a2a3e;border-radius:14px;padding:clamp(32px,3vw,48px);width:clamp(360px,28vw,480px);max-width:92vw}
.card h2{text-align:center;margin-bottom:clamp(20px,2vw,32px);font-size:clamp(1.3rem,1.8vw,1.8rem);background:linear-gradient(135deg,#7c5cfc,#e879f9);-webkit-background-clip:text;background-clip:text;-webkit-text-fill-color:transparent}
input{width:100%;padding:clamp(10px,1.2vw,16px) clamp(14px,1.5vw,20px);background:#0e0e18;color:#e8e8f0;border:1px solid #2a2a3e;border-radius:10px;font-size:clamp(.9rem,1vw,1.1rem);margin-bottom:clamp(14px,1.2vw,20px)}
input:focus{border-color:#7c5cfc;outline:none}
button{width:100%;padding:clamp(10px,1.2vw,16px);background:#7c5cfc;color:#fff;border:none;border-radius:10px;font-size:clamp(.9rem,1vw,1.1rem);cursor:pointer;font-weight:600}
button:hover{background:#9078ff}
.err{color:#f87171;font-size:clamp(.82rem,.9vw,1rem);text-align:center;margin-bottom:10px}
</style></head>
<body><div class="card"><h2>ComfyCarry</h2>
<form method="POST" action="/login">
<div class="err" id="err">__ERR__</div>
<input name="password" type="password" placeholder="è¾“å…¥è®¿é—®å¯†ç ..." autofocus>
<button type="submit">ç™»å½•</button>
</form></div></body></html>"""


@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "GET":
        return Response(LOGIN_PAGE.replace("__ERR__", ""), mimetype="text/html")
    pw = request.form.get("password", "")
    if pw == DASHBOARD_PASSWORD:
        session["authed"] = True
        return redirect("/")
    return Response(LOGIN_PAGE.replace("__ERR__", "å¯†ç é”™è¯¯"), mimetype="text/html")


@app.route("/logout")
def logout():
    session.clear()
    return redirect("/login")


@app.before_request
def check_auth():
    """å…¨å±€é‰´æƒä¸ Setup Wizard è·¯ç”±"""
    # Setup ç›¸å…³è·¯ç”±å§‹ç»ˆå…è®¸
    if request.path.startswith("/api/setup/") or request.path == "/setup":
        return
    # é…ç½®å¯¼å…¥åœ¨ Setup é˜¶æ®µä¹Ÿéœ€è¦å¯ç”¨
    if request.path == "/api/settings/import-config":
        return
    if request.path in ("/login", "/favicon.ico", "/dashboard.js", "/api/version"):
        return
    if request.path.startswith("/static/"):
        return
    # å¦‚æœå°šæœªå®Œæˆéƒ¨ç½²å‘å¯¼, é‡å®šå‘åˆ°å‘å¯¼é¡µ
    if not _is_setup_complete():
        if request.path.startswith("/api/"):
            return jsonify({"error": "Setup not complete", "setup_required": True}), 503
        if request.path != "/":
            return redirect("/")
        return  # è®© index() å¤„ç†å‘å¯¼é¡µæ¸²æŸ“
    # æ­£å¸¸é‰´æƒ
    if not DASHBOARD_PASSWORD:
        return
    if session.get("authed"):
        return
    if request.path.startswith("/api/"):
        return jsonify({"error": "Unauthorized"}), 401
    return redirect("/login")


# --- å·¥å…·å‡½æ•° ---
def _get_api_key():
    if CONFIG_FILE.exists():
        try:
            return json.loads(CONFIG_FILE.read_text()).get("api_key", "")
        except Exception:
            return ""
    return ""

def _run_cmd(cmd, timeout=10):
    """è¿è¡Œ shell å‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
    try:
        r = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=timeout)
        return r.stdout.strip()
    except Exception as e:
        return f"Error: {e}"

def _sha256_file(filepath):
    """è®¡ç®—æ–‡ä»¶å®Œæ•´ SHA256 (CivitAI éœ€è¦å®Œæ•´æ–‡ä»¶å“ˆå¸Œ)"""
    sha = hashlib.sha256()
    try:
        with open(filepath, "rb") as f:
            while True:
                chunk = f.read(65536)
                if not chunk:
                    break
                sha.update(chunk)
        return sha.hexdigest().upper()
    except Exception:
        return None


# ====================================================================
# ç‰ˆæœ¬ä¿¡æ¯ API
# ====================================================================
@app.route("/api/version")
def api_version():
    """è¿”å›å½“å‰éƒ¨ç½²ç‰ˆæœ¬ä¿¡æ¯"""
    version_info = {"version": "v2.4", "branch": "main", "commit": ""}
    version_file = os.path.join(SCRIPT_DIR, ".version")
    try:
        if os.path.exists(version_file):
            with open(version_file, "r") as f:
                for line in f:
                    line = line.strip()
                    if "=" in line:
                        k, v = line.split("=", 1)
                        version_info[k.strip().lower()] = v.strip()
    except Exception:
        pass
    # Also try git if available (dev environment)
    if not version_info.get("commit"):
        try:
            import subprocess
            result = subprocess.run(
                ["git", "rev-parse", "HEAD"], capture_output=True, text=True,
                cwd=SCRIPT_DIR, timeout=3
            )
            if result.returncode == 0:
                version_info["commit"] = result.stdout.strip()
            result2 = subprocess.run(
                ["git", "rev-parse", "--abbrev-ref", "HEAD"], capture_output=True, text=True,
                cwd=SCRIPT_DIR, timeout=3
            )
            if result2.returncode == 0:
                version_info["branch"] = result2.stdout.strip()
        except Exception:
            pass
    return jsonify(version_info)


# ç³»ç»Ÿç›‘æ§ API
# ====================================================================
@app.route("/api/system")
def api_system():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    info = {"cpu": {}, "memory": {}, "disk": {}, "gpu": [], "network": {}, "uptime": ""}

    # CPU
    try:
        import psutil
        info["cpu"]["percent"] = psutil.cpu_percent(interval=0.5)
        info["cpu"]["cores"] = psutil.cpu_count()
        info["cpu"]["freq"] = psutil.cpu_freq()._asdict() if psutil.cpu_freq() else {}
        load = os.getloadavg()
        info["cpu"]["load"] = {"1m": load[0], "5m": load[1], "15m": load[2]}
    except Exception as e:
        info["cpu"]["error"] = str(e)

    # Memory
    try:
        import psutil
        mem = psutil.virtual_memory()
        info["memory"] = {
            "total": mem.total, "used": mem.used, "available": mem.available,
            "percent": mem.percent
        }
    except Exception as e:
        info["memory"]["error"] = str(e)

    # Disk
    try:
        import psutil
        disk = psutil.disk_usage("/workspace" if os.path.exists("/workspace") else "/")
        info["disk"] = {
            "total": disk.total, "used": disk.used, "free": disk.free,
            "percent": disk.percent, "path": "/workspace"
        }
    except Exception as e:
        info["disk"]["error"] = str(e)

    # GPU (nvidia-smi)
    try:
        gpu_out = _run_cmd(
            "nvidia-smi --query-gpu=index,name,memory.total,memory.used,memory.free,"
            "utilization.gpu,temperature.gpu,power.draw,power.limit "
            "--format=csv,nounits,noheader", timeout=5
        )
        for line in gpu_out.strip().split("\n"):
            if not line.strip():
                continue
            parts = [p.strip() for p in line.split(",")]
            if len(parts) >= 9:
                info["gpu"].append({
                    "index": int(parts[0]), "name": parts[1],
                    "mem_total": int(parts[2]), "mem_used": int(parts[3]),
                    "mem_free": int(parts[4]), "util": int(parts[5]),
                    "temp": int(parts[6]),
                    "power": float(parts[7]) if parts[7] != "[N/A]" else 0,
                    "power_limit": float(parts[8]) if parts[8] != "[N/A]" else 0,
                })
    except Exception:
        pass

    # Network
    try:
        import psutil
        net = psutil.net_io_counters()
        info["network"] = {
            "bytes_sent": net.bytes_sent, "bytes_recv": net.bytes_recv,
            "packets_sent": net.packets_sent, "packets_recv": net.packets_recv,
        }
    except Exception:
        pass

    # Uptime
    try:
        info["uptime"] = _run_cmd("uptime -p", timeout=3)
    except Exception:
        pass

    return jsonify(info)


# ====================================================================
# æœåŠ¡ç®¡ç† API (PM2)
# ====================================================================
@app.route("/api/services")
def api_services():
    """è·å– PM2 æœåŠ¡åˆ—è¡¨"""
    try:
        out = _run_cmd("pm2 jlist", timeout=5)
        if out and not out.startswith("Error"):
            services = json.loads(out)
            result = []
            for s in services:
                result.append({
                    "name": s.get("name"),
                    "pm_id": s.get("pm_id"),
                    "status": s.get("pm2_env", {}).get("status"),
                    "cpu": s.get("monit", {}).get("cpu", 0),
                    "memory": s.get("monit", {}).get("memory", 0),
                    "restarts": s.get("pm2_env", {}).get("restart_time", 0),
                    "uptime": s.get("pm2_env", {}).get("pm_uptime", 0),
                    "pid": s.get("pid"),
                })
            return jsonify({"services": result})
        return jsonify({"services": [], "error": out})
    except Exception as e:
        return jsonify({"services": [], "error": str(e)})


@app.route("/api/services/<name>/<action>", methods=["POST"])
def api_service_action(name, action):
    """æ§åˆ¶æœåŠ¡: restart, stop, start"""
    if action not in ("restart", "stop", "start"):
        return jsonify({"error": "Invalid action"}), 400
    if not re.match(r'^[\w\-]+$', name):
        return jsonify({"error": "Invalid service name"}), 400
    out = _run_cmd(f"pm2 {action} {name}", timeout=10)
    return jsonify({"ok": True, "output": out})


# ====================================================================
# æ—¥å¿— API
# ====================================================================
@app.route("/api/logs/<name>")
def api_logs(name):
    """è·å– PM2 æ—¥å¿—"""
    if not re.match(r'^[\w\-]+$', name):
        return jsonify({"logs": "", "error": "Invalid service name"}), 400
    try:
        lines = int(request.args.get("lines", "100"))
        lines = min(max(lines, 1), 1000)
    except (ValueError, TypeError):
        lines = 100
    try:
        out = _run_cmd(f"pm2 logs {name} --nostream --lines {lines}", timeout=5)
        return jsonify({"logs": out})
    except Exception as e:
        return jsonify({"logs": "", "error": str(e)})


# ====================================================================
# é…ç½® API (CivitAI Key)
# ====================================================================
@app.route("/api/config", methods=["GET"])
def get_config():
    key = _get_api_key()
    return jsonify({
        "api_key": key, "has_key": bool(key),
        "key_preview": f"{key[:8]}...{key[-4:]}" if len(key) > 12 else ("****" if key else ""),
        "comfyui_dir": COMFYUI_DIR, "comfyui_url": COMFYUI_URL,
    })

@app.route("/api/config", methods=["POST"])
def save_config():
    data = request.get_json(force=True) or {}
    api_key = data.get("api_key", "").strip()
    CONFIG_FILE.write_text(json.dumps({"api_key": api_key}))
    return jsonify({"ok": True, "has_key": bool(api_key)})


# ====================================================================
# CivitAI æœç´¢ä»£ç† (Meilisearch CORS bypass)
# ====================================================================
@app.route("/api/search", methods=["POST"])
def proxy_search():
    try:
        data = request.get_json(force=True, silent=True)
        if not data:
            return jsonify({"error": "No JSON body"}), 400

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {MEILI_BEARER}",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }

        resp = requests.post(MEILI_URL, headers=headers, json=data, timeout=10)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception as e:
        return jsonify({"error": str(e)}), 500


# ====================================================================
# æœ¬åœ°æ¨¡å‹ç®¡ç† API
# ====================================================================
@app.route("/api/local_models")
def api_local_models():
    """æ‰«ææœ¬åœ°æ¨¡å‹æ–‡ä»¶"""
    category = request.args.get("category", "all")
    results = []

    dirs_to_scan = MODEL_DIRS if category == "all" else {category: MODEL_DIRS.get(category, "")}

    for cat, rel_dir in dirs_to_scan.items():
        full_dir = os.path.join(COMFYUI_DIR, rel_dir)
        if not os.path.isdir(full_dir):
            continue
        for root, _, files in os.walk(full_dir):
            for fname in files:
                ext = os.path.splitext(fname)[1].lower()
                if ext not in MODEL_EXTENSIONS:
                    continue
                fpath = os.path.join(root, fname)
                rel_path = os.path.relpath(fpath, os.path.join(COMFYUI_DIR, rel_dir))
                stat = os.stat(fpath)

                # Check for metadata files
                base_no_ext = os.path.splitext(fpath)[0]
                info_path = f"{fpath}.weilin-info.json"
                info_data = None
                if os.path.exists(info_path):
                    try:
                        with open(info_path, "r", encoding="utf-8") as f:
                            info_data = json.load(f)
                    except Exception:
                        pass

                # Check for preview image
                preview = None
                for pext in [".jpg", ".png", ".jpeg", ".webp"]:
                    ppath = base_no_ext + pext
                    if os.path.exists(ppath):
                        preview = os.path.relpath(ppath, COMFYUI_DIR)
                        break

                entry = {
                    "filename": fname,
                    "rel_path": rel_path,
                    "category": cat,
                    "size_bytes": stat.st_size,
                    "modified": stat.st_mtime,
                    "abs_path": fpath,
                    "has_info": info_data is not None,
                    "has_preview": preview is not None,
                    "preview_path": preview,
                }

                if info_data:
                    entry["name"] = info_data.get("name", fname)
                    entry["base_model"] = info_data.get("baseModel", "")
                    entry["type"] = info_data.get("type", cat)
                    entry["trained_words"] = [
                        w.get("word", "") for w in info_data.get("trainedWords", [])
                    ]
                    entry["links"] = info_data.get("links", [])
                    # CivitAI IDs from raw data
                    raw_civitai = info_data.get("raw", {}).get("civitai", {})
                    entry["civitai_id"] = raw_civitai.get("modelId")
                    entry["civitai_version_id"] = raw_civitai.get("id")
                    entry["version_name"] = raw_civitai.get("name", "")
                    entry["sha256"] = info_data.get("sha256", "")
                    # Images from info (full array)
                    imgs = info_data.get("images", [])
                    entry["images"] = imgs
                    if imgs:
                        entry["civitai_image"] = imgs[0].get("url", "")
                else:
                    entry["name"] = fname
                    entry["base_model"] = ""
                    entry["type"] = cat
                    entry["trained_words"] = []

                results.append(entry)

    results.sort(key=lambda x: x["modified"], reverse=True)
    return jsonify({"models": results, "total": len(results)})


@app.route("/api/local_models/preview")
def api_model_preview():
    """è¿”å›æ¨¡å‹é¢„è§ˆå›¾"""
    rel = request.args.get("path", "")
    full = os.path.realpath(os.path.join(COMFYUI_DIR, rel))
    # è·¯å¾„å®‰å…¨æ£€æŸ¥: å¿…é¡»åœ¨ COMFYUI_DIR å†…
    if not full.startswith(os.path.realpath(COMFYUI_DIR) + os.sep):
        return jsonify({"error": "è·¯å¾„è¶Šç•Œ"}), 403
    if os.path.isfile(full):
        return send_file(full)
    return "", 404


@app.route("/api/local_models/delete", methods=["POST"])
def api_delete_model():
    """åˆ é™¤æœ¬åœ°æ¨¡å‹åŠå…¶å…³è”æ–‡ä»¶"""
    data = request.get_json(force=True) or {}
    abs_path = os.path.realpath(data.get("abs_path", ""))

    # å®‰å…¨æ£€æŸ¥: realpath + å‰ç¼€åŒ¹é…å« /
    if not abs_path.startswith(os.path.realpath(COMFYUI_DIR) + os.sep):
        return jsonify({"error": "è·¯å¾„ä¸åœ¨ ComfyUI ç›®å½•å†…"}), 403

    if not os.path.isfile(abs_path):
        return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404

    deleted = [abs_path]
    os.remove(abs_path)

    # åˆ é™¤å…³è”æ–‡ä»¶
    base_no_ext = os.path.splitext(abs_path)[0]
    for suffix in [".weilin-info.json", ".jpg", ".png", ".jpeg", ".webp", ".civitai.info"]:
        companion = (abs_path + suffix) if suffix.startswith(".weilin") else (base_no_ext + suffix)
        if os.path.exists(companion):
            os.remove(companion)
            deleted.append(companion)

    return jsonify({"ok": True, "deleted": deleted})


@app.route("/api/local_models/fetch_info", methods=["POST"])
def api_fetch_model_info():
    """é€šè¿‡ SHA256 ä» CivitAI è·å–æ¨¡å‹å…ƒæ•°æ®å¹¶ä¿å­˜"""
    data = request.get_json(force=True) or {}
    abs_path = os.path.realpath(data.get("abs_path", ""))

    # å®‰å…¨æ£€æŸ¥: realpath + å‰ç¼€åŒ¹é…å« /
    if not abs_path.startswith(os.path.realpath(COMFYUI_DIR) + os.sep):
        return jsonify({"error": "è·¯å¾„ä¸åœ¨ ComfyUI ç›®å½•å†…"}), 403

    if not os.path.isfile(abs_path):
        return jsonify({"error": "æ–‡ä»¶ä¸å­˜åœ¨"}), 404

    # è®¡ç®— SHA256
    file_hash = _sha256_file(abs_path)
    if not file_hash:
        return jsonify({"error": "æ— æ³•è®¡ç®—å“ˆå¸Œ"}), 500

    # è°ƒç”¨ CivitAI API
    api_key = _get_api_key()
    headers = {}
    if api_key:
        headers["Authorization"] = f"Bearer {api_key}"

    try:
        api_url = f"https://civitai.com/api/v1/model-versions/by-hash/{file_hash}"
        resp = requests.get(api_url, headers=headers, timeout=30)
        if resp.status_code == 404:
            return jsonify({"error": "CivitAI æœªæ‰¾åˆ°è¯¥æ¨¡å‹", "hash": file_hash}), 404
        resp.raise_for_status()
        civitai_data = resp.json()
    except Exception as e:
        return jsonify({"error": f"API è¯·æ±‚å¤±è´¥: {e}", "hash": file_hash}), 500

    # æ„å»º weilin-info.json
    info_data = {
        "file": os.path.basename(abs_path),
        "path": abs_path,
        "sha256": file_hash,
        "name": civitai_data.get("model", {}).get("name", ""),
        "type": civitai_data.get("model", {}).get("type", ""),
        "baseModel": civitai_data.get("baseModel", ""),
        "images": [],
        "trainedWords": [],
        "links": [],
        "raw": {"civitai": civitai_data},
    }

    # ç‰ˆæœ¬å
    ver_name = civitai_data.get("name", "")
    if ver_name:
        info_data["name"] += f" - {ver_name}"

    # è§¦å‘è¯
    trigger_words = civitai_data.get("trainedWords", [])
    for w in trigger_words:
        info_data["trainedWords"].append({"word": w, "civitai": True})

    # Links
    model_id = civitai_data.get("modelId")
    version_id = civitai_data.get("id")
    if model_id:
        link = f"https://civitai.com/models/{model_id}"
        if version_id:
            link += f"?modelVersionId={version_id}"
        info_data["links"].append(link)

    # å›¾ç‰‡
    for img in civitai_data.get("images", []):
        img_url = img.get("url", "")
        if img_url:
            img_entry = {
                "url": img_url,
                "type": img.get("type", "image"),
                "width": img.get("width"),
                "height": img.get("height"),
                "nsfwLevel": img.get("nsfwLevel"),
            }
            meta = img.get("meta") or {}
            if meta:
                img_entry["positive"] = meta.get("prompt", "")
                img_entry["negative"] = meta.get("negativePrompt", "")
                img_entry["seed"] = meta.get("seed")
                img_entry["sampler"] = meta.get("sampler")
                img_entry["cfg"] = meta.get("cfgScale")
                img_entry["steps"] = meta.get("steps")
                img_entry["model"] = meta.get("Model")
            info_data["images"].append(img_entry)

    # ä¿å­˜ info json
    info_path = f"{abs_path}.weilin-info.json"
    with open(info_path, "w", encoding="utf-8") as f:
        json.dump(info_data, f, sort_keys=False, indent=2, ensure_ascii=False)

    # ä¸‹è½½é¢„è§ˆå›¾
    base_no_ext = os.path.splitext(abs_path)[0]
    if info_data["images"]:
        first_img_url = info_data["images"][0].get("url", "")
        if first_img_url:
            try:
                with requests.get(first_img_url, timeout=15, stream=True) as img_resp:
                    img_resp.raise_for_status()
                    ct = img_resp.headers.get("Content-Type", "")
                    ext = ".png"
                    if "jpeg" in ct or "jpg" in ct:
                        ext = ".jpeg"
                    elif "webp" in ct:
                        ext = ".webp"
                    preview_path = base_no_ext + ext
                    with open(preview_path, "wb") as pf:
                        for chunk in img_resp.iter_content(4096):
                            pf.write(chunk)
                    info_data["_preview_saved"] = preview_path
            except Exception:
                pass

    return jsonify({"ok": True, "info": info_data, "hash": file_hash})


# ====================================================================
# Enhanced-Civicomfy ä¸‹è½½ä»£ç†
# ====================================================================
@app.route("/api/download", methods=["POST"])
def api_download_model():
    """ä»£ç†è¯·æ±‚åˆ° ComfyUI çš„ Enhanced-Civicomfy ä¸‹è½½æ¥å£"""
    data = request.get_json(force=True) or {}
    api_key = data.get("api_key") or _get_api_key()

    payload = {
        "model_url_or_id": data.get("model_id", ""),
        "model_type": data.get("model_type", "checkpoint"),
        "api_key": api_key,
        "num_connections": data.get("num_connections", 4),
    }
    if data.get("version_id"):
        payload["model_version_id"] = int(data["version_id"])
    if data.get("custom_filename"):
        payload["custom_filename"] = data["custom_filename"]

    try:
        resp = requests.post(f"{COMFYUI_URL}/civitai/download", json=payload, timeout=30)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except requests.exceptions.ConnectionError:
        return jsonify({"error": "ComfyUI æœªè¿è¡Œï¼Œæ— æ³•ä¸‹è½½ã€‚è¯·å…ˆå¯åŠ¨ ComfyUI æœåŠ¡ã€‚"}), 503
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/download/status")
def api_download_status():
    """è·å– Civicomfy ä¸‹è½½çŠ¶æ€"""
    try:
        resp = requests.get(f"{COMFYUI_URL}/civitai/status", timeout=5)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception:
        return jsonify({"queue": [], "active": [], "history": []}), 200


@app.route("/api/download/cancel", methods=["POST"])
def api_download_cancel():
    """å–æ¶ˆæŒ‡å®šä¸‹è½½ä»»åŠ¡"""
    data = request.get_json(force=True) or {}
    download_id = data.get("download_id", "")
    if not download_id:
        return jsonify({"error": "download_id required"}), 400
    try:
        resp = requests.post(f"{COMFYUI_URL}/civitai/cancel", json={"download_id": download_id}, timeout=10)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/download/retry", methods=["POST"])
def api_download_retry():
    """é‡è¯•å¤±è´¥/å–æ¶ˆçš„ä¸‹è½½"""
    data = request.get_json(force=True) or {}
    download_id = data.get("download_id", "")
    if not download_id:
        return jsonify({"error": "download_id required"}), 400
    try:
        resp = requests.post(f"{COMFYUI_URL}/civitai/retry", json={"download_id": download_id}, timeout=10)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/download/clear_history", methods=["POST"])
def api_download_clear_history():
    """æ¸…é™¤ä¸‹è½½å†å²"""
    try:
        resp = requests.post(f"{COMFYUI_URL}/civitai/clear_history", json={}, timeout=10)
        return Response(resp.content, status=resp.status_code, mimetype="application/json")
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/tunnel_links")
def api_tunnel_links():
    """è·å– Cloudflare Tunnel ä»£ç†çš„æœåŠ¡é“¾æ¥"""
    links = []
    # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
    tunnel_url = os.environ.get("CF_TUNNEL_URL", os.environ.get("TUNNEL_URL", ""))
    if tunnel_url:
        links.append({"name": "ComfyUI", "url": tunnel_url.rstrip("/"), "icon": "ğŸ¨"})
    jupyter_url = os.environ.get("JUPYTER_URL", "")
    if jupyter_url:
        links.append({"name": "Jupyter", "url": jupyter_url, "icon": "ğŸ““"})

    if not links:
        links = _parse_tunnel_ingress()

    vast_proxy = os.environ.get("VAST_PROXY_URL", "")
    if vast_proxy:
        links.append({"name": "Vast.ai Proxy", "url": vast_proxy, "icon": "â˜ï¸"})

    return jsonify({"links": links})


def _parse_tunnel_ingress():
    """ä» PM2 tunnel æ—¥å¿—ä¸­è§£æ Cloudflare Tunnel ingress é…ç½®"""
    links = []
    try:
        r = subprocess.run(
            "pm2 logs tunnel --nostream --lines 300 2>/dev/null",
            shell=True, capture_output=True, text=True, timeout=5
        )
        log = r.stdout + r.stderr

        # Strategy 1: Parse config="{...}" with escaped JSON (named tunnels)
        # The JSON value has escaped quotes, so we can't use simple (.*?) â€” match
        # everything between config=" and the closing " that is NOT preceded by \
        cfg_match = re.search(r'config="((?:[^"\\]|\\.)*)"', log)
        if cfg_match:
            raw = cfg_match.group(1).replace('\\"', '"').replace('\\\\', '\\')
            try:
                cfg = json.loads(raw)
                ingress = cfg.get("ingress", [])
                _tunnel_ingress_to_links(ingress, links)
            except (json.JSONDecodeError, ValueError):
                pass

        # Strategy 2: Look for "ingress" JSON array directly in logs
        if not links:
            # Sometimes the config is logged as plain JSON
            ing_match = re.search(r'"ingress"\s*:\s*\[', log)
            if ing_match:
                # Find the matching closing bracket
                start = ing_match.start()
                brace_start = log.index('[', start)
                depth = 0
                end = brace_start
                for i in range(brace_start, min(brace_start + 5000, len(log))):
                    if log[i] == '[': depth += 1
                    elif log[i] == ']': depth -= 1
                    if depth == 0:
                        end = i + 1
                        break
                try:
                    ingress = json.loads(log[brace_start:end])
                    _tunnel_ingress_to_links(ingress, links)
                except (json.JSONDecodeError, ValueError):
                    pass

        # Strategy 3: Find hostnameâ†’URL mappings from "Registered tunnel connection" lines
        if not links:
            # Look for registered hostnames like "Updated to ... hostname=xxx.com"
            hostnames = re.findall(r'hostname[=:]\s*([a-zA-Z0-9][a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', log)
            for h in set(hostnames):
                if 'cloudflare' not in h:
                    links.append({"name": h.split(".")[0].replace("-", " ").title(),
                                  "url": f"https://{h}", "icon": "ğŸŒ"})

        # Strategy 4: Fallback â€” trycloudflare quick tunnel URLs
        if not links:
            urls = list(set(re.findall(r'https://[a-z0-9-]+\.trycloudflare\.com', log)))
            for i, u in enumerate(urls):
                links.append({"name": f"Service #{i+1}", "url": u, "icon": "ğŸŒ"})
    except Exception:
        pass
    return links


def _tunnel_ingress_to_links(ingress, links):
    """å°† Cloudflare Tunnel ingress åˆ—è¡¨è½¬æ¢ä¸ºæœåŠ¡é“¾æ¥"""
    port_services = _detect_port_services()
    jupyter_token = _get_jupyter_token()
    for entry in ingress:
        hostname = entry.get("hostname", "")
        service = entry.get("service", "")
        if not hostname or "http_status:" in service:
            continue
        port_match = re.search(r':(\d+)', service)
        port = port_match.group(1) if port_match else ""
        proto = "ssh" if service.startswith("ssh://") else "http"
        if proto == "ssh":
            continue
        svc_name = port_services.get(port, "")
        if not svc_name:
            svc_name = hostname.split(".")[0].replace("-", " ").title()
        icon = {"comfyui": "ğŸ¨", "jupyter": "ğŸ““", "dashboard": "ğŸ“Š"}.get(svc_name.lower(), "ğŸŒ")
        url = f"https://{hostname}"
        # Append Jupyter token if applicable
        if svc_name.lower() == "jupyter" and jupyter_token:
            url += f"/?token={jupyter_token}"
        links.append({
            "name": svc_name, "url": url,
            "icon": icon, "port": port, "service": service
        })


def _get_jupyter_token():
    """ä» jupyter server list è·å–è¿è¡Œä¸­çš„ Jupyter token"""
    try:
        r = subprocess.run(
            "jupyter server list 2>&1",
            shell=True, capture_output=True, text=True, timeout=5
        )
        output = r.stdout + r.stderr
        # Match: https://host:port/?token=TOKEN :: /path
        # or:   http://host:port/?token=TOKEN :: /path
        match = re.search(r'https?://[^?]+\?token=([a-f0-9]+)', output)
        if match:
            return match.group(1)
    except Exception:
        pass
    return ""


def _detect_port_services():
    """æ£€æµ‹æœ¬æœºç«¯å£å¯¹åº”çš„æœåŠ¡åç§°"""
    mapping = {}
    # å°è¯•ç”¨ PM2 è·å–åŠ¨æ€ç«¯å£æ˜ å°„
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True, capture_output=True, text=True, timeout=5)
        if r.returncode == 0:
            procs = json.loads(r.stdout)
            for p in procs:
                name = p.get("name", "")
                args = p.get("pm2_env", {}).get("args", [])
                if isinstance(args, list):
                    for i, a in enumerate(args):
                        if a == "--port" and i + 1 < len(args):
                            mapping[str(args[i + 1])] = name.title()
    except Exception:
        pass
    # å·²çŸ¥ç«¯å£ï¼ˆè¦†ç›– PM2 è‡ªåŠ¨æ£€æµ‹ï¼Œç¡®ä¿åç§°å‡†ç¡®ï¼‰
    mapping["8188"] = "ComfyUI"
    mapping["5000"] = "Dashboard"
    mapping["8080"] = "Jupyter"
    mapping["8888"] = "Jupyter"
    return mapping


@app.route("/api/tunnel_status")
def api_tunnel_status():
    """è·å– Tunnel çŠ¶æ€å’Œæ—¥å¿—"""
    # PM2 è¿›ç¨‹ä¿¡æ¯
    status = "unknown"
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True, capture_output=True, text=True, timeout=5)
        if r.returncode == 0:
            procs = json.loads(r.stdout)
            for p in procs:
                if p.get("name") == "tunnel":
                    status = p.get("pm2_env", {}).get("status", "unknown")
                    break
    except Exception:
        pass

    # æ—¥å¿— (strip ANSI codes and PM2 prefixes)
    try:
        r = subprocess.run(
            "pm2 logs tunnel --nostream --lines 100 2>/dev/null",
            shell=True, capture_output=True, text=True, timeout=5
        )
        raw_logs = r.stdout + r.stderr
        # Strip ANSI escape codes
        ansi_re = re.compile(r'\x1b\[[0-9;]*m')
        logs = ansi_re.sub('', raw_logs)
        # Strip PM2 prefix like "1|tunnel   | "
        logs = re.sub(r'^\d+\|[^|]+\|\s*', '', logs, flags=re.MULTILINE)
        # Strip PM2 tailing header lines
        logs = '\n'.join(l for l in logs.split('\n')
                        if not l.startswith('[TAILING]') and 'last 100 lines' not in l and '/root/.pm2/logs/' not in l)
    except Exception:
        logs = ""

    # Ingress é“¾æ¥
    links = _parse_tunnel_ingress()

    return jsonify({"status": status, "logs": logs, "links": links})


# ====================================================================
# Plugin Management API (ä»£ç† ComfyUI-Manager ç«¯ç‚¹)
# ====================================================================

def _cm_get(path, params=None, timeout=30):
    """å‘ ComfyUI-Manager å‘é€ GET è¯·æ±‚"""
    try:
        r = requests.get(f"{COMFYUI_URL}{path}", params=params, timeout=timeout)
        return r
    except requests.exceptions.ConnectionError:
        return None
    except Exception:
        return None


def _cm_post(path, json_data=None, text_data=None, timeout=30):
    """å‘ ComfyUI-Manager å‘é€ POST è¯·æ±‚"""
    try:
        if text_data is not None:
            r = requests.post(f"{COMFYUI_URL}{path}", data=text_data,
                              headers={"Content-Type": "text/plain"}, timeout=timeout)
        else:
            r = requests.post(f"{COMFYUI_URL}{path}", json=json_data, timeout=timeout)
        return r
    except requests.exceptions.ConnectionError:
        return None
    except Exception:
        return None


# ====================================================================
# ComfyUI ç®¡ç† API
# ====================================================================

# ---------- å¯åŠ¨å‚æ•°å®šä¹‰ ----------
COMFYUI_PARAM_GROUPS = {
    "vram": {
        "label": "VRAM ç®¡ç†",
        "type": "select",
        "help": "æ§åˆ¶æ¨¡å‹æ˜¾å­˜åˆ†é…ç­–ç•¥ã€‚é»˜è®¤è‡ªåŠ¨æ£€æµ‹ï¼ŒHigh VRAM é€‚åˆå¤§æ˜¾å­˜GPUä¸å¸è½½æ¨¡å‹ï¼ŒLow VRAM é€‚åˆå°æ˜¾å­˜æ‹†åˆ†æ¨ç†",
        "options": [
            ("default", "é»˜è®¤ (è‡ªåŠ¨)"),
            ("gpu-only", "GPU Only (å…¨éƒ¨ä¿ç•™åœ¨GPU)"),
            ("highvram", "High VRAM (æ¨¡å‹ä¸å¸è½½)"),
            ("normalvram", "Normal VRAM (å¼ºåˆ¶æ­£å¸¸æ¨¡å¼)"),
            ("lowvram", "Low VRAM (æ‹†åˆ† UNet)"),
            ("novram", "No VRAM (æé™ä½æ˜¾å­˜)"),
        ],
        "flag_map": {
            "gpu-only": "--gpu-only", "highvram": "--highvram",
            "normalvram": "--normalvram", "lowvram": "--lowvram",
            "novram": "--novram",
        },
    },
    "attention": {
        "label": "Attention æ–¹æ¡ˆ",
        "type": "select",
        "help": "PyTorch SDPA æ¨èï¼Œè‡ªåŠ¨è°ƒç”¨æœ€ä¼˜å†…æ ¸(å«FlashAttention)ã€‚FlashAttention/SageAttention éœ€è¦é¢å¤–å®‰è£…å¯¹åº”åŒ…",
        "options": [
            ("default", "é»˜è®¤ (è‡ªåŠ¨é€‰æ‹©)"),
            ("pytorch-cross", "PyTorch SDPA (æ¨èâœ“)"),
            ("split-cross", "Split Cross Attention (çœVRAM)"),
            ("quad-cross", "Sub-Quadratic"),
            ("flash", "FlashAttention (éœ€flash-attnåŒ…)"),
            ("sage", "SageAttention (éœ€sageattentionåŒ…)"),
        ],
        "flag_map": {
            "pytorch-cross": "--use-pytorch-cross-attention",
            "split-cross": "--use-split-cross-attention",
            "quad-cross": "--use-quad-cross-attention",
            "flash": "--use-flash-attention",
            "sage": "--use-sage-attention",
        },
    },
    "disable_xformers": {
        "label": "ç¦ç”¨ xFormers",
        "type": "bool",
        "help": "xFormers åœ¨æ–°ç‰ˆ PyTorch ä¸‹å·²ä¸æ¨èï¼Œå»ºè®®ç¦ç”¨å¹¶ä½¿ç”¨ PyTorch SDPA",
        "flag": "--disable-xformers",
    },
    "unet_precision": {
        "label": "UNet ç²¾åº¦",
        "type": "select",
        "help": "æ§åˆ¶ UNet æ¨ç†ç²¾åº¦ã€‚FP8 å¯å¤§å¹…å‡å°‘æ˜¾å­˜å ç”¨ï¼Œé€‚åˆå¤§æ¨¡å‹ï¼›BF16 æ˜¯ Ampere+ æ¨èç²¾åº¦",
        "options": [
            ("default", "é»˜è®¤ (è‡ªåŠ¨)"),
            ("fp32", "FP32"), ("fp16", "FP16"), ("bf16", "BF16"),
            ("fp8_e4m3fn", "FP8 (e4m3fn)"), ("fp8_e5m2", "FP8 (e5m2)"),
        ],
        "flag_map": {
            "fp32": "--fp32-unet", "fp16": "--fp16-unet", "bf16": "--bf16-unet",
            "fp8_e4m3fn": "--fp8_e4m3fn-unet", "fp8_e5m2": "--fp8_e5m2-unet",
        },
    },
    "vae_precision": {
        "label": "VAE ç²¾åº¦",
        "type": "select",
        "help": "VAE è§£ç ç²¾åº¦ã€‚FP32 æœ€ç¨³å®šï¼ŒFP16/BF16 æ›´å¿«ã€‚é»‘å›¾æ—¶å¯å°è¯• FP32",
        "options": [
            ("default", "é»˜è®¤ (è‡ªåŠ¨)"),
            ("fp32", "FP32"), ("fp16", "FP16"), ("bf16", "BF16"),
            ("cpu", "CPU (åœ¨CPUä¸Šè¿è¡Œ)"),
        ],
        "flag_map": {
            "fp32": "--fp32-vae", "fp16": "--fp16-vae",
            "bf16": "--bf16-vae", "cpu": "--cpu-vae",
        },
    },
    "text_enc_precision": {
        "label": "Text Encoder ç²¾åº¦",
        "type": "select",
        "help": "æ–‡æœ¬ç¼–ç å™¨ç²¾åº¦ã€‚é€šå¸¸é»˜è®¤å³å¯ï¼ŒFP8 å¯èŠ‚çœæ˜¾å­˜",
        "options": [
            ("default", "é»˜è®¤ (è‡ªåŠ¨)"),
            ("fp32", "FP32"), ("fp16", "FP16"), ("bf16", "BF16"),
            ("fp8_e4m3fn", "FP8 (e4m3fn)"), ("fp8_e5m2", "FP8 (e5m2)"),
        ],
        "flag_map": {
            "fp32": "--fp32-text-enc", "fp16": "--fp16-text-enc",
            "bf16": "--bf16-text-enc",
            "fp8_e4m3fn": "--fp8_e4m3fn-text-enc", "fp8_e5m2": "--fp8_e5m2-text-enc",
        },
    },
    "fast": {
        "label": "å®éªŒæ€§ä¼˜åŒ– (--fast)",
        "type": "bool",
        "help": "å¯ç”¨ ComfyUI å®éªŒæ€§åŠ é€Ÿï¼Œå¯èƒ½æå‡æ¨ç†é€Ÿåº¦ 10-20%ï¼Œæå°‘æ•°å·¥ä½œæµå¯èƒ½ä¸å…¼å®¹",
        "flag": "--fast",
    },
    "preview_method": {
        "label": "é¢„è§ˆæ–¹å¼",
        "type": "select",
        "help": "ç”Ÿæˆè¿‡ç¨‹ä¸­çš„å®æ—¶é¢„è§ˆæ–¹å¼ã€‚TAESD æ•ˆæœæœ€å¥½ä½†ç¨æ…¢ï¼ŒLatent2RGB æœ€å¿«ä½†æ¨¡ç³Š",
        "options": [
            ("auto", "è‡ªåŠ¨"), ("none", "æ— "),
            ("latent2rgb", "Latent2RGB"), ("taesd", "TAESD"),
        ],
        "flag_prefix": "--preview-method",
    },
    "cache": {
        "label": "ç¼“å­˜ç­–ç•¥",
        "type": "select",
        "help": "æ§åˆ¶èŠ‚ç‚¹è¾“å‡ºç¼“å­˜ã€‚LRU ç²¾ç»†æ§åˆ¶ç¼“å­˜å¤§å°ï¼Œç»å…¸æ¨¡å¼æ¿€è¿›ç¼“å­˜æ›´å¿«ä½†å æ›´å¤šå†…å­˜",
        "options": [
            ("default", "é»˜è®¤"), ("classic", "ç»å…¸ (Aggressive)"),
            ("lru", "LRU"), ("none", "ç¦ç”¨"),
        ],
        "flag_map": {
            "classic": "--cache-classic", "none": "--cache-none",
        },
    },
    "cache_lru_size": {
        "label": "LRU ç¼“å­˜å¤§å°",
        "type": "number",
        "help": "LRU ç¼“å­˜æœ€å¤§æ¡ç›®æ•°ï¼Œ0 = æ— é™åˆ¶ã€‚å»ºè®®æ ¹æ®å¯ç”¨å†…å­˜è®¾ç½®",
        "flag_prefix": "--cache-lru",
        "depends_on": {"cache": "lru"},
    },
}

# Reverse lookup: flag -> (group_key, value)
_FLAG_TO_PARAM = {}
for _gk, _gv in COMFYUI_PARAM_GROUPS.items():
    if _gv["type"] == "bool":
        _FLAG_TO_PARAM[_gv["flag"]] = (_gk, True)
    elif "flag_map" in _gv:
        for _val, _flag in _gv["flag_map"].items():
            _FLAG_TO_PARAM[_flag] = (_gk, _val)


def _parse_comfyui_args(args):
    """ä»å‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨è§£æä¸ºç»“æ„åŒ–å‚æ•°å­—å…¸"""
    params = {k: (False if v["type"] == "bool" else 0 if v["type"] == "number" else "default")
              for k, v in COMFYUI_PARAM_GROUPS.items()}
    params["listen"] = "0.0.0.0"
    params["port"] = 8188

    i = 0
    while i < len(args):
        a = args[i]
        if a == "--listen" and i + 1 < len(args):
            params["listen"] = args[i + 1]; i += 2; continue
        elif a == "--port" and i + 1 < len(args):
            params["port"] = int(args[i + 1]); i += 2; continue
        elif a == "--preview-method" and i + 1 < len(args):
            params["preview_method"] = args[i + 1]; i += 2; continue
        elif a == "--cache-lru" and i + 1 < len(args):
            params["cache"] = "lru"
            params["cache_lru_size"] = int(args[i + 1]); i += 2; continue
        elif a in _FLAG_TO_PARAM:
            gk, val = _FLAG_TO_PARAM[a]
            params[gk] = val
        i += 1
    return params


def _build_comfyui_args(params):
    """ä»ç»“æ„åŒ–å‚æ•°å­—å…¸æ„å»ºå‘½ä»¤è¡Œå‚æ•°å­—ç¬¦ä¸²"""
    args = ["--listen", params.get("listen", "0.0.0.0"),
            "--port", str(params.get("port", 8188))]

    for gk, gv in COMFYUI_PARAM_GROUPS.items():
        val = params.get(gk)
        if val is None or val == "default" or val is False:
            continue
        if gv["type"] == "bool" and val:
            args.append(gv["flag"])
        elif gv["type"] == "select" and "flag_map" in gv and val in gv["flag_map"]:
            args.append(gv["flag_map"][val])
        elif gv["type"] == "select" and "flag_prefix" in gv and val != "default":
            args.extend([gv["flag_prefix"], str(val)])
        elif gv["type"] == "number" and "flag_prefix" in gv and val is not None:
            # val=0 å¯¹ --cache-lru ä»æœ‰æ„ä¹‰ (æ— é™åˆ¶)ï¼Œåªè·³è¿‡åˆå§‹é»˜è®¤å€¼ 0
            if gk == "cache_lru_size" and params.get("cache") != "lru":
                continue  # cache ä¸æ˜¯ LRU æ¨¡å¼æ—¶ä¸è¾“å‡º
            args.extend([gv["flag_prefix"], str(int(val))])

    return " ".join(args)


@app.route("/api/comfyui/status")
def api_comfyui_status():
    """è·å– ComfyUI ç³»ç»ŸçŠ¶æ€ + å½“å‰å¯åŠ¨å‚æ•°"""
    result = {"online": False, "system": {}, "devices": [], "params": {}, "args": []}
    # ç³»ç»ŸçŠ¶æ€ from ComfyUI
    try:
        resp = requests.get(f"{COMFYUI_URL}/system_stats", timeout=5)
        data = resp.json()
        result["online"] = True
        result["system"] = data.get("system", {})
        result["devices"] = data.get("devices", [])
    except Exception:
        pass
    # å½“å‰å¯åŠ¨å‚æ•° from PM2
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True,
                           capture_output=True, text=True, timeout=5)
        procs = json.loads(r.stdout or "[]")
        comfy = next((p for p in procs if p.get("name") == "comfy"), None)
        if comfy:
            pm2_env = comfy.get("pm2_env", {})
            raw_args = pm2_env.get("args", [])
            if isinstance(raw_args, str):
                raw_args = raw_args.split()
            result["args"] = raw_args
            result["params"] = _parse_comfyui_args(raw_args)
            result["pm2_status"] = pm2_env.get("status", "unknown")
            result["pm2_restarts"] = pm2_env.get("restart_time", 0)
            result["pm2_uptime"] = pm2_env.get("pm_uptime", 0)
    except Exception:
        pass
    return jsonify(result)


@app.route("/api/comfyui/params", methods=["GET"])
def api_comfyui_params_get():
    """è·å–å‚æ•°å®šä¹‰ + å½“å‰å€¼"""
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True,
                           capture_output=True, text=True, timeout=5)
        procs = json.loads(r.stdout or "[]")
        comfy = next((p for p in procs if p.get("name") == "comfy"), None)
        raw_args = []
        if comfy:
            raw_args = comfy.get("pm2_env", {}).get("args", [])
            if isinstance(raw_args, str):
                raw_args = raw_args.split()
        current = _parse_comfyui_args(raw_args)
        # Build schema for frontend
        schema = {}
        for gk, gv in COMFYUI_PARAM_GROUPS.items():
            schema[gk] = {
                "label": gv["label"], "type": gv["type"],
                "value": current.get(gk),
            }
            if "options" in gv:
                schema[gk]["options"] = gv["options"]
            if "depends_on" in gv:
                schema[gk]["depends_on"] = gv["depends_on"]
            if "help" in gv:
                schema[gk]["help"] = gv["help"]
            if "flag" in gv:
                schema[gk]["flag"] = gv["flag"]
            if "flag_map" in gv:
                schema[gk]["flag_map"] = gv["flag_map"]
            if "flag_prefix" in gv:
                schema[gk]["flag_prefix"] = gv["flag_prefix"]
        return jsonify({"schema": schema, "current": current, "raw_args": raw_args})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/comfyui/params", methods=["POST"])
def api_comfyui_params_update():
    """æ›´æ–° ComfyUI å¯åŠ¨å‚æ•°å¹¶é‡å¯"""
    data = request.get_json()
    params = data.get("params", {})
    extra_args = data.get("extra_args", "").strip()
    args_str = _build_comfyui_args(params)
    if extra_args:
        args_str = args_str + " " + extra_args

    # æŸ¥æ‰¾ Python è·¯å¾„
    py = "/usr/bin/python3.13"
    for candidate in ["/usr/bin/python3.13", "/usr/bin/python3.12",
                      "/usr/bin/python3.11", "/usr/bin/python3"]:
        if os.path.isfile(candidate):
            py = candidate
            break

    try:
        subprocess.run("pm2 delete comfy 2>/dev/null || true",
                       shell=True, timeout=10)
        cmd = (
            f'cd /workspace/ComfyUI && pm2 start {py} --name comfy '
            f'--interpreter none --log /workspace/comfy.log --time '
            f'--restart-delay 3000 --max-restarts 10 '
            f'-- main.py {args_str}'
        )
        subprocess.run(cmd, shell=True, timeout=30, check=True)
        subprocess.run("pm2 save 2>/dev/null || true", shell=True, timeout=5)
        return jsonify({"ok": True, "args": args_str})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/comfyui/queue")
def api_comfyui_queue():
    """è·å– ComfyUI ä»»åŠ¡é˜Ÿåˆ—"""
    try:
        resp = requests.get(f"{COMFYUI_URL}/queue", timeout=5)
        return jsonify(resp.json())
    except Exception:
        return jsonify({"queue_running": [], "queue_pending": [], "error": "ComfyUI æ— æ³•è¿æ¥"})


@app.route("/api/comfyui/interrupt", methods=["POST"])
def api_comfyui_interrupt():
    """ä¸­æ–­å½“å‰æ‰§è¡Œ"""
    try:
        requests.post(f"{COMFYUI_URL}/interrupt", timeout=5)
        return jsonify({"ok": True})
    except Exception:
        return jsonify({"error": "ComfyUI æ— æ³•è¿æ¥"}), 503


@app.route("/api/comfyui/free", methods=["POST"])
def api_comfyui_free():
    """é‡Šæ”¾ VRAM / å¸è½½æ¨¡å‹"""
    try:
        requests.post(f"{COMFYUI_URL}/free",
                      json={"unload_models": True, "free_memory": True}, timeout=10)
        return jsonify({"ok": True})
    except Exception:
        return jsonify({"error": "ComfyUI æ— æ³•è¿æ¥"}), 503


@app.route("/api/comfyui/history")
def api_comfyui_history():
    """è·å–æœ€è¿‘ç”Ÿæˆè®°å½•"""
    max_items = request.args.get("max_items", 5, type=int)
    try:
        resp = requests.get(f"{COMFYUI_URL}/history",
                            params={"max_items": max_items}, timeout=10)
        raw = resp.json()
        # Convert from dict {prompt_id: {outputs, status}} to sorted list
        items = []
        for pid, entry in raw.items():
            status = entry.get("status", {})
            outputs = entry.get("outputs", {})
            # Find output images
            images = []
            for node_id, node_out in outputs.items():
                for img in node_out.get("images", []):
                    images.append({
                        "filename": img.get("filename", ""),
                        "subfolder": img.get("subfolder", ""),
                        "type": img.get("type", "output"),
                    })
            items.append({
                "prompt_id": pid,
                "completed": status.get("completed", False),
                "images": images,
                "timestamp": status.get("status_str_start_time", ""),
            })
        # Sort by timestamp desc
        items.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
        return jsonify({"history": items[:max_items]})
    except Exception:
        return jsonify({"history": [], "error": "ComfyUI æ— æ³•è¿æ¥"})


@app.route("/api/comfyui/view")
def api_comfyui_view():
    """ä»£ç† ComfyUI å›¾ç‰‡æŸ¥çœ‹ (ç”¨äºç¼©ç•¥å›¾)"""
    filename = request.args.get("filename", "")
    subfolder = request.args.get("subfolder", "")
    img_type = request.args.get("type", "output")
    preview = request.args.get("preview", "")
    if not filename:
        return "", 400
    try:
        params = {"filename": filename, "type": img_type}
        if subfolder:
            params["subfolder"] = subfolder
        if preview:
            params["preview"] = preview
        resp = requests.get(f"{COMFYUI_URL}/view", params=params,
                            timeout=10, stream=True)
        return resp.content, resp.status_code, {
            "Content-Type": resp.headers.get("Content-Type", "image/png")
        }
    except Exception:
        return "", 503


# ====================================================================
#   ComfyUI WebSocket â†’ SSE å®æ—¶äº‹ä»¶æ¨é€
# ====================================================================

import websocket  # websocket-client

class ComfyWSBridge:
    """Maintains a WebSocket connection to ComfyUI and broadcasts events via SSE."""

    def __init__(self, comfyui_url):
        self._ws_url = comfyui_url.replace("http://", "ws://").replace("https://", "wss://")
        self._client_id = str(uuid.uuid4())
        self._subscribers = {}   # id -> queue.Queue
        self._lock = threading.Lock()
        self._ws = None
        self._running = False
        self._thread = None
        # Latest state cache for new subscribers
        self._last_status = None
        self._last_progress = None
        self._exec_info = {}     # Current execution info

    def start(self):
        if self._running:
            return
        self._running = True
        self._thread = threading.Thread(target=self._run_loop, daemon=True)
        self._thread.start()

    def _run_loop(self):
        """Reconnect loop â€” keeps trying to connect to ComfyUI WS."""
        while self._running:
            try:
                url = f"{self._ws_url}/ws?clientId={self._client_id}"
                self._ws = websocket.WebSocketApp(
                    url,
                    on_message=self._on_message,
                    on_error=self._on_error,
                    on_close=self._on_close,
                    on_open=self._on_open,
                )
                self._ws.run_forever(ping_interval=30, ping_timeout=10)
            except Exception:
                pass
            if self._running:
                time.sleep(3)  # Wait before reconnect

    def _on_open(self, ws):
        self._broadcast({"type": "ws_connected"})

    def _on_error(self, ws, error):
        pass  # Will reconnect in _run_loop

    def _on_close(self, ws, close_status_code=None, close_msg=None):
        self._broadcast({"type": "ws_disconnected"})

    def _on_message(self, ws, message):
        if isinstance(message, bytes):
            # Binary = preview image, skip for SSE (too large)
            return
        try:
            data = json.loads(message)
            msg_type = data.get("type", "")
            msg_data = data.get("data", {})

            if msg_type == "status":
                q_info = msg_data.get("status", {}).get("exec_info", {})
                q_remaining = q_info.get("queue_remaining", 0)
                old_remaining = (self._last_status or {}).get("status", {}).get(
                    "exec_info", {}).get("queue_remaining", 0)

                # Detect execution start/end from queue transitions
                if old_remaining == 0 and q_remaining > 0 and not self._exec_info:
                    self._exec_info = {"start_time": time.time()}
                    self._broadcast({"type": "execution_start", "data": {
                        "start_time": self._exec_info["start_time"]
                    }})
                elif q_remaining == 0 and self._exec_info:
                    elapsed = time.time() - self._exec_info.get("start_time", time.time())
                    self._broadcast({"type": "execution_done", "data": {
                        "elapsed": round(elapsed, 1)
                    }})
                    self._exec_info = {}
                    self._last_progress = None

                self._last_status = msg_data
                self._broadcast({"type": "status", "data": msg_data})

            elif msg_type == "crystools.monitor":
                # Real-time GPU/CPU/RAM stats from Crystools plugin
                self._broadcast({"type": "monitor", "data": msg_data})

            elif msg_type in ("execution_start", "executing", "progress",
                              "executed", "execution_error", "execution_cached",
                              "execution_success"):
                # These are normally only sent to the prompt submitter,
                # but forward them if we somehow receive them
                if msg_type == "progress":
                    val = msg_data.get("value", 0)
                    mx = msg_data.get("max", 1)
                    self._last_progress = {"value": val, "max": mx,
                                           "percent": round(val / mx * 100) if mx > 0 else 0}
                    self._broadcast({"type": "progress", "data": self._last_progress})
                elif msg_type == "execution_error":
                    self._broadcast({"type": "execution_error", "data": msg_data})
                    self._exec_info = {}
                    self._last_progress = None
                else:
                    self._broadcast({"type": msg_type, "data": msg_data})

        except Exception:
            pass

    def subscribe(self):
        """Add a new SSE subscriber and return (sub_id, queue)."""
        sub_id = str(uuid.uuid4())
        q = queue.Queue(maxsize=200)
        with self._lock:
            self._subscribers[sub_id] = q
        # Send cached state to new subscriber
        if self._last_status:
            q.put({"type": "status", "data": self._last_status})
        if self._exec_info:
            q.put({"type": "executing", "data": self._exec_info})
        if self._last_progress:
            q.put({"type": "progress", "data": self._last_progress})
        return sub_id, q

    def unsubscribe(self, sub_id):
        with self._lock:
            self._subscribers.pop(sub_id, None)

    def _broadcast(self, event):
        with self._lock:
            dead = []
            for sid, q in self._subscribers.items():
                try:
                    q.put_nowait(event)
                except queue.Full:
                    dead.append(sid)
            for sid in dead:
                self._subscribers.pop(sid, None)


# Global WebSocket bridge instance
_comfy_ws_bridge = ComfyWSBridge(COMFYUI_URL)
_comfy_ws_bridge.start()


@app.route("/api/comfyui/events")
def api_comfyui_events():
    """SSE endpoint â€” streams real-time ComfyUI events to the frontend."""
    sub_id, q = _comfy_ws_bridge.subscribe()

    def generate():
        try:
            while True:
                try:
                    event = q.get(timeout=30)
                    yield f"data: {json.dumps(event, ensure_ascii=False)}\n\n"
                except queue.Empty:
                    # Send keepalive
                    yield ": keepalive\n\n"
        except GeneratorExit:
            pass
        finally:
            _comfy_ws_bridge.unsubscribe(sub_id)

    return Response(generate(), mimetype="text/event-stream",
                    headers={"Cache-Control": "no-cache",
                             "X-Accel-Buffering": "no"})


@app.route("/api/comfyui/logs/stream")
def api_comfyui_logs_stream():
    """SSE endpoint â€” streams pm2 log lines for comfy in real-time."""
    def generate():
        proc = None
        try:
            # Use pm2 logs --raw --lines 0 to get only new lines
            proc = subprocess.Popen(
                ["pm2", "logs", "comfy", "--raw", "--lines", "50"],
                stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
                text=True, bufsize=1
            )
            for line in iter(proc.stdout.readline, ''):
                if not line:
                    break
                line = line.rstrip('\n')
                if not line:
                    continue
                # Classify log level
                lvl = "info"
                if re.search(r'error|exception|traceback', line, re.I):
                    lvl = "error"
                elif re.search(r'warn', line, re.I):
                    lvl = "warn"
                yield f"data: {json.dumps({'line': line, 'level': lvl}, ensure_ascii=False)}\n\n"
        except GeneratorExit:
            pass
        finally:
            if proc:
                try:
                    proc.kill()
                    proc.stdout.close()
                    proc.wait(timeout=5)
                except Exception:
                    pass

    return Response(generate(), mimetype="text/event-stream",
                    headers={"Cache-Control": "no-cache",
                             "X-Accel-Buffering": "no"})


@app.route("/api/plugins/installed")
def api_plugins_installed():
    """è·å–å·²å®‰è£…æ’ä»¶åˆ—è¡¨"""
    r = _cm_get("/customnode/installed", params={"mode": "default"})
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUIï¼Œè¯·ç¡®è®¤ ComfyUI æ­£åœ¨è¿è¡Œ"}), 502
    if r.status_code != 200:
        return jsonify({"error": f"ComfyUI-Manager è¿”å› {r.status_code}"}), r.status_code
    try:
        return jsonify(r.json())
    except Exception:
        return jsonify({"error": "è§£æå“åº”å¤±è´¥"}), 500


@app.route("/api/plugins/available")
def api_plugins_available():
    """è·å–æ‰€æœ‰å¯ç”¨æ’ä»¶åˆ—è¡¨(å«å®‰è£…çŠ¶æ€)"""
    r = _cm_get("/customnode/getlist", params={"mode": "remote", "skip_update": "true"}, timeout=60)
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUIï¼Œè¯·ç¡®è®¤ ComfyUI æ­£åœ¨è¿è¡Œ"}), 502
    if r.status_code != 200:
        return jsonify({"error": f"ComfyUI-Manager è¿”å› {r.status_code}"}), r.status_code
    try:
        return jsonify(r.json())
    except Exception:
        return jsonify({"error": "è§£æå“åº”å¤±è´¥"}), 500


@app.route("/api/plugins/versions/<path:node_name>")
def api_plugins_versions(node_name):
    """è·å–æŸæ’ä»¶æ‰€æœ‰å¯ç”¨ç‰ˆæœ¬"""
    r = _cm_get(f"/customnode/versions/{node_name}")
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    if r.status_code != 200:
        return jsonify({"error": f"è¿”å› {r.status_code}"}), r.status_code
    try:
        return jsonify(r.json())
    except Exception:
        return jsonify({"error": "è§£æå“åº”å¤±è´¥"}), 500


@app.route("/api/plugins/fetch_updates")
def api_plugins_fetch_updates():
    """æ‹‰å–æ›´æ–°ä¿¡æ¯ (git fetch)"""
    r = _cm_get("/customnode/fetch_updates", params={"mode": "remote"}, timeout=120)
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    # 200=æ— æ›´æ–°, 201=æœ‰æ›´æ–°å¯ç”¨
    return jsonify({"has_updates": r.status_code == 201, "status_code": r.status_code})


@app.route("/api/plugins/install", methods=["POST"])
def api_plugins_install():
    """å®‰è£…æ’ä»¶ (æ’å…¥é˜Ÿåˆ—)"""
    data = request.get_json(force=True) or {}
    payload = {
        "id": data.get("id", ""),
        "version": data.get("version", "unknown"),
        "selected_version": data.get("selected_version", "latest"),
        "channel": "default",
        "mode": "remote",
        "ui_id": f"dash-{int(time.time())}",
        "skip_post_install": False,
    }
    if data.get("repository"):
        payload["repository"] = data["repository"]
    if data.get("files"):
        payload["files"] = data["files"]
    r = _cm_post("/manager/queue/install", json_data=payload)
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    if r.status_code not in (200, 201):
        return jsonify({"error": f"å®‰è£…è¯·æ±‚å¤±è´¥: {r.status_code}"}), r.status_code
    # è‡ªåŠ¨å¯åŠ¨é˜Ÿåˆ—å¤„ç†
    _cm_get("/manager/queue/start")
    return jsonify({"ok": True, "message": "å·²åŠ å…¥å®‰è£…é˜Ÿåˆ—"})


@app.route("/api/plugins/uninstall", methods=["POST"])
def api_plugins_uninstall():
    """å¸è½½æ’ä»¶"""
    data = request.get_json(force=True) or {}
    payload = {
        "id": data.get("id", ""),
        "version": data.get("version", "unknown"),
        "ui_id": f"dash-{int(time.time())}",
    }
    if data.get("files"):
        payload["files"] = data["files"]
    r = _cm_post("/manager/queue/uninstall", json_data=payload)
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    if r.status_code not in (200, 201):
        return jsonify({"error": f"å¸è½½è¯·æ±‚å¤±è´¥: {r.status_code}"}), r.status_code
    _cm_get("/manager/queue/start")
    return jsonify({"ok": True, "message": "å·²åŠ å…¥å¸è½½é˜Ÿåˆ—"})


@app.route("/api/plugins/update", methods=["POST"])
def api_plugins_update():
    """æ›´æ–°æ’ä»¶"""
    data = request.get_json(force=True) or {}
    payload = {
        "id": data.get("id", ""),
        "version": data.get("version", "unknown"),
        "ui_id": f"dash-{int(time.time())}",
    }
    r = _cm_post("/manager/queue/update", json_data=payload)
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    if r.status_code not in (200, 201):
        return jsonify({"error": f"æ›´æ–°è¯·æ±‚å¤±è´¥: {r.status_code}"}), r.status_code
    _cm_get("/manager/queue/start")
    return jsonify({"ok": True, "message": "å·²åŠ å…¥æ›´æ–°é˜Ÿåˆ—"})


@app.route("/api/plugins/update_all", methods=["POST"])
def api_plugins_update_all():
    """ä¸€é”®æ›´æ–°æ‰€æœ‰æ’ä»¶"""
    r = _cm_get("/manager/queue/update_all", params={"mode": "remote"}, timeout=120)
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    _cm_get("/manager/queue/start")
    return jsonify({"ok": True, "message": "æ‰€æœ‰æ’ä»¶å·²åŠ å…¥æ›´æ–°é˜Ÿåˆ—"})


@app.route("/api/plugins/disable", methods=["POST"])
def api_plugins_disable():
    """ç¦ç”¨/å¯ç”¨æ’ä»¶"""
    data = request.get_json(force=True) or {}
    payload = {
        "id": data.get("id", ""),
        "version": data.get("version", "unknown"),
        "ui_id": f"dash-{int(time.time())}",
    }
    r = _cm_post("/manager/queue/disable", json_data=payload)
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    if r.status_code not in (200, 201):
        return jsonify({"error": f"æ“ä½œå¤±è´¥: {r.status_code}"}), r.status_code
    _cm_get("/manager/queue/start")
    return jsonify({"ok": True, "message": "æ“ä½œå·²æäº¤"})


@app.route("/api/plugins/install_git", methods=["POST"])
def api_plugins_install_git():
    """é€šè¿‡ Git URL ç›´æ¥å®‰è£…"""
    data = request.get_json(force=True) or {}
    url = data.get("url", "").strip()
    if not url:
        return jsonify({"error": "URL ä¸èƒ½ä¸ºç©º"}), 400
    r = _cm_post("/customnode/install/git_url", text_data=url, timeout=120)
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    if r.status_code not in (200, 201):
        return jsonify({"error": f"å®‰è£…å¤±è´¥: {r.status_code}"}), r.status_code
    return jsonify({"ok": True, "message": "Git URL å®‰è£…å®Œæˆ"})


@app.route("/api/plugins/queue_status")
def api_plugins_queue_status():
    """æŸ¥è¯¢é˜Ÿåˆ—çŠ¶æ€"""
    r = _cm_get("/manager/queue/status")
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    try:
        return jsonify(r.json())
    except Exception:
        return jsonify({"total_count": 0, "done_count": 0, "in_progress_count": 0, "is_processing": False})


@app.route("/api/plugins/manager_version")
def api_plugins_manager_version():
    """è·å– ComfyUI-Manager ç‰ˆæœ¬"""
    r = _cm_get("/manager/version")
    if r is None:
        return jsonify({"error": "æ— æ³•è¿æ¥ ComfyUI"}), 502
    return jsonify({"version": r.text.strip()})


# ====================================================================
# Settings API (å¯†ç  / é…ç½®ç®¡ç†)
# ====================================================================

@app.route("/api/settings", methods=["GET"])
def api_settings_get():
    """è¿”å›å½“å‰è®¾ç½®æ¦‚è§ˆ"""
    api_key = _get_api_key()
    return jsonify({
        "password_set": bool(DASHBOARD_PASSWORD),
        "password_masked": DASHBOARD_PASSWORD[:2] + "***" if DASHBOARD_PASSWORD and len(DASHBOARD_PASSWORD) > 2 else "***",
        "civitai_key_set": bool(api_key),
        "civitai_key_masked": api_key[:6] + "..." if api_key and len(api_key) > 6 else ("å·²è®¾ç½®" if api_key else ""),
    })


@app.route("/api/settings/password", methods=["POST"])
def api_settings_password():
    """ä¿®æ”¹ Dashboard å¯†ç """
    global DASHBOARD_PASSWORD
    data = request.get_json(force=True) or {}
    current = data.get("current", "")
    new_pw = data.get("new", "").strip()

    if not new_pw:
        return jsonify({"error": "æ–°å¯†ç ä¸èƒ½ä¸ºç©º"}), 400
    if len(new_pw) < 4:
        return jsonify({"error": "å¯†ç è‡³å°‘ 4 ä¸ªå­—ç¬¦"}), 400
    if current != DASHBOARD_PASSWORD:
        return jsonify({"error": "å½“å‰å¯†ç é”™è¯¯"}), 403

    DASHBOARD_PASSWORD = new_pw
    _save_dashboard_password(new_pw)
    return jsonify({"ok": True, "message": "å¯†ç å·²æ›´æ–°å¹¶æŒä¹…åŒ–ä¿å­˜"})


@app.route("/api/settings/restart", methods=["POST"])
def api_settings_restart():
    """é‡å¯ Dashboard (pm2 restart dashboardï¼Œå»¶è¿Ÿæ‰§è¡Œ)"""
    import threading
    def _do_restart():
        import time; time.sleep(1)
        subprocess.run("pm2 restart dashboard", shell=True, timeout=15)
    threading.Thread(target=_do_restart, daemon=True).start()
    return jsonify({"ok": True, "message": "Dashboard æ­£åœ¨é‡å¯..."})


@app.route("/api/settings/debug", methods=["GET"])
def api_settings_debug_get():
    """è·å– debug æ¨¡å¼çŠ¶æ€"""
    return jsonify({"debug": _get_config("debug", False)})


@app.route("/api/settings/debug", methods=["POST"])
def api_settings_debug_set():
    """åˆ‡æ¢ debug æ¨¡å¼"""
    data = request.get_json(force=True) or {}
    enabled = bool(data.get("enabled", False))
    _set_config("debug", enabled)
    return jsonify({"ok": True, "debug": enabled})


@app.route("/api/settings/export-config")
def api_settings_export_config():
    """å¯¼å‡ºæ‰€æœ‰é…ç½®ä¸º JSON æ–‡ä»¶"""
    import base64 as _b64
    config = {"_version": 1, "_exported_at": datetime.now().isoformat()}

    # 1. Dashboard å¯†ç 
    config["password"] = DASHBOARD_PASSWORD

    # 2. CivitAI API Key
    try:
        if CONFIG_FILE.exists():
            config["civitai_token"] = json.loads(CONFIG_FILE.read_text()).get("api_key", "")
    except Exception:
        pass

    # 3. éƒ¨ç½²æ¨¡å¼
    state = _load_setup_state()
    config["image_type"] = state.get("image_type", "")

    # 4. Cloudflare Tunnel Token
    config["cloudflared_token"] = state.get("cloudflared_token", "")

    # 5. Rclone é…ç½® (Base64 ç¼–ç )
    rclone_conf = Path.home() / ".config" / "rclone" / "rclone.conf"
    if rclone_conf.exists():
        try:
            config["rclone_config_base64"] = _b64.b64encode(
                rclone_conf.read_bytes()
            ).decode("ascii")
        except Exception:
            pass

    # 6. æ’ä»¶åˆ—è¡¨ â€” åˆ†ç¦»: é»˜è®¤æ’ä»¶ + é¢å¤–æ’ä»¶
    default_urls = {p["url"] for p in DEFAULT_PLUGINS}
    all_plugins = state.get("plugins", [])
    config["extra_plugins"] = [u for u in all_plugins if u not in default_urls]
    # ä¹Ÿä¿å­˜ç”¨æˆ·å¯¹é»˜è®¤æ’ä»¶çš„å–æ¶ˆé€‰æ‹© (å¦‚æœæœ‰)
    config["disabled_default_plugins"] = [u for u in default_urls if u not in all_plugins]

    # 7. åŒæ­¥è§„åˆ™ (v2) + æ—§ç‰ˆåŒæ­¥åå¥½ (å‘åå…¼å®¹)
    if SYNC_RULES_FILE.exists():
        try:
            config["sync_rules"] = json.loads(SYNC_RULES_FILE.read_text(encoding="utf-8"))
        except Exception:
            pass
    sync_prefs_file = Path("/workspace/.sync_prefs.json")
    if sync_prefs_file.exists():
        try:
            config["sync_prefs"] = json.loads(sync_prefs_file.read_text(encoding="utf-8"))
        except Exception:
            pass

    # 8. ComfyUI å¯åŠ¨å‚æ•°
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True,
                           capture_output=True, text=True, timeout=5)
        procs = json.loads(r.stdout or "[]")
        comfy = next((p for p in procs if p.get("name") == "comfy"), None)
        if comfy:
            raw_args = comfy.get("pm2_env", {}).get("args", [])
            if isinstance(raw_args, str):
                raw_args = raw_args.split()
            config["comfyui_params"] = _parse_comfyui_args(raw_args)
    except Exception:
        pass

    # 9. Debug æ¨¡å¼
    config["debug"] = _get_config("debug", False)

    return Response(
        json.dumps(config, indent=2, ensure_ascii=False),
        mimetype="application/json",
        headers={
            "Content-Disposition": "attachment; filename=comfyui-config.json",
            "Cache-Control": "no-cache"
        }
    )


@app.route("/api/settings/import-config", methods=["POST"])
def api_settings_import_config():
    """å¯¼å…¥é…ç½® JSON â€” åˆå¹¶è¦†ç›–ç°æœ‰è®¾ç½®"""
    import base64 as _b64

    data = request.get_json(force=True) or {}
    if not data:
        return jsonify({"error": "æ— æ•ˆçš„é…ç½®æ–‡ä»¶"}), 400

    applied = []
    errors = []

    # 1. å¯†ç 
    if data.get("password"):
        try:
            global DASHBOARD_PASSWORD
            DASHBOARD_PASSWORD = data["password"]
            _save_dashboard_password(data["password"])
            applied.append("Dashboard å¯†ç ")
        except Exception as e:
            errors.append(f"å¯†ç : {e}")

    # 2. CivitAI API Key
    if data.get("civitai_token"):
        try:
            CONFIG_FILE.write_text(json.dumps({"api_key": data["civitai_token"]}))
            applied.append("CivitAI API Key")
        except Exception as e:
            errors.append(f"CivitAI: {e}")

    # 3. Rclone é…ç½®
    if data.get("rclone_config_base64"):
        try:
            rclone_dir = Path.home() / ".config" / "rclone"
            rclone_dir.mkdir(parents=True, exist_ok=True)
            conf_text = _b64.b64decode(data["rclone_config_base64"]).decode("utf-8")
            (rclone_dir / "rclone.conf").write_text(conf_text, encoding="utf-8")
            subprocess.run("chmod 600 ~/.config/rclone/rclone.conf", shell=True)
            applied.append("Rclone é…ç½®")
        except Exception as e:
            errors.append(f"Rclone: {e}")

    # 4. åŒæ­¥è§„åˆ™ (v2) / æ—§ç‰ˆåŒæ­¥åå¥½
    if data.get("sync_rules"):
        try:
            SYNC_RULES_FILE.write_text(
                json.dumps(data["sync_rules"], indent=2, ensure_ascii=False), encoding="utf-8"
            )
            applied.append("åŒæ­¥è§„åˆ™")
        except Exception as e:
            errors.append(f"åŒæ­¥è§„åˆ™: {e}")
    if data.get("sync_prefs"):
        try:
            Path("/workspace/.sync_prefs.json").write_text(
                json.dumps(data["sync_prefs"], indent=2, ensure_ascii=False), encoding="utf-8"
            )
            applied.append("åŒæ­¥åå¥½ (æ—§ç‰ˆ)")
        except Exception as e:
            errors.append(f"åŒæ­¥åå¥½: {e}")

    # 5. Debug æ¨¡å¼
    if "debug" in data:
        _set_config("debug", bool(data["debug"]))
        applied.append("Debug æ¨¡å¼")

    # 6. Setup Wizard çŠ¶æ€ (image_type, plugins, tunnel token)
    try:
        state = _load_setup_state()
        if data.get("image_type"):
            state["image_type"] = data["image_type"]
            applied.append("éƒ¨ç½²æ¨¡å¼")
        if data.get("cloudflared_token"):
            state["cloudflared_token"] = data["cloudflared_token"]
            applied.append("Tunnel Token")
        if data.get("civitai_token"):
            state["civitai_token"] = data["civitai_token"]
        # åˆå¹¶æ’ä»¶åˆ—è¡¨
        if "extra_plugins" in data or "disabled_default_plugins" in data:
            default_urls = [p["url"] for p in DEFAULT_PLUGINS]
            disabled = set(data.get("disabled_default_plugins", []))
            plugins = [u for u in default_urls if u not in disabled]
            plugins.extend(data.get("extra_plugins", []))
            state["plugins"] = plugins
            applied.append("æ’ä»¶åˆ—è¡¨")
        if data.get("rclone_config_base64"):
            state["rclone_config_method"] = "base64"
            state["rclone_config_value"] = data["rclone_config_base64"]
        if data.get("password"):
            state["password"] = data["password"]
        _save_setup_state(state)
    except Exception as e:
        errors.append(f"å‘å¯¼çŠ¶æ€: {e}")

    # 7. ComfyUI å¯åŠ¨å‚æ•° (åªåœ¨ ComfyUI è¿è¡Œä¸­æ—¶ç”Ÿæ•ˆ)
    if data.get("comfyui_params"):
        try:
            # å‚æ•°å°†åœ¨ä¸‹æ¬¡å¯åŠ¨/é‡å¯æ—¶é€šè¿‡ API åº”ç”¨
            applied.append("ComfyUI å¯åŠ¨å‚æ•° (éœ€é‡å¯ ComfyUI ç”Ÿæ•ˆ)")
        except Exception as e:
            errors.append(f"ComfyUI å‚æ•°: {e}")

    return jsonify({
        "ok": True,
        "applied": applied,
        "errors": errors,
        "message": f"å·²å¯¼å…¥ {len(applied)} é¡¹é…ç½®" + (f", {len(errors)} é¡¹å¤±è´¥" if errors else "")
    })


@app.route("/api/settings/reinitialize", methods=["POST"])
def api_settings_reinitialize():
    """é‡æ–°åˆå§‹åŒ– â€” åœæ­¢æœåŠ¡, æ¸…ç† ComfyUI, é‡ç½®å‘å¯¼çŠ¶æ€, è¿›å…¥ Setup Wizard

    ä¿ç•™: apt/pip å·²å®‰è£…çš„åŒ… (system_deps, pytorch), Tunnel (å¦‚æ— å˜æ›´)
    åˆ é™¤: ComfyUI ç›®å½• (å¯é€‰ä¿ç•™ models), è‡ªå®šä¹‰èŠ‚ç‚¹, éƒ¨ç½²çŠ¶æ€
    """
    data = request.get_json(force=True) or {}
    keep_models = bool(data.get("keep_models", False))

    errors = []

    # 1. åœæ­¢ ComfyUI å’Œ sync æœåŠ¡
    try:
        _stop_sync_worker()
        subprocess.run("pm2 delete comfy 2>/dev/null || true", shell=True, timeout=15)
        subprocess.run("pm2 delete sync 2>/dev/null || true", shell=True, timeout=15)
    except Exception as e:
        errors.append(f"åœæ­¢æœåŠ¡å¤±è´¥: {e}")

    # 2. æ¸…ç† ComfyUI ç›®å½•
    comfy_dir = Path(COMFYUI_DIR)
    if comfy_dir.exists():
        try:
            if keep_models:
                # ä¿ç•™ models ç›®å½•, åˆ é™¤å…¶ä»–
                models_tmp = Path("/workspace/.models_backup")
                models_src = comfy_dir / "models"
                if models_src.exists():
                    subprocess.run(f'mv "{models_src}" "{models_tmp}"', shell=True, timeout=60)
                subprocess.run(f'rm -rf "{comfy_dir}"', shell=True, timeout=120)
                if models_tmp.exists():
                    comfy_dir.mkdir(parents=True, exist_ok=True)
                    subprocess.run(f'mv "{models_tmp}" "{models_src}"', shell=True, timeout=60)
            else:
                subprocess.run(f'rm -rf "{comfy_dir}"', shell=True, timeout=120)
        except Exception as e:
            errors.append(f"æ¸…ç† ComfyUI ç›®å½•å¤±è´¥: {e}")

    # 3. æ¸…ç†ç”Ÿæˆçš„è„šæœ¬å’ŒåŒæ­¥é…ç½®
    for f in [Path("/workspace/cloud_sync.sh"), Path("/workspace/.sync_prefs.json"), Path("/workspace/.sync_rules.json")]:
        try:
            if f.exists():
                f.unlink()
        except Exception:
            pass

    # 4. é‡ç½® Setup Wizard çŠ¶æ€ â€” ä¿ç•™ system_deps å’Œ pytorch æ­¥éª¤æ ‡è®°
    try:
        preserved_steps = []
        if SETUP_STATE_FILE.exists():
            old_state = _load_setup_state()
            for step_key in ("system_deps", "pytorch"):
                if step_key in old_state.get("deploy_steps_completed", []):
                    preserved_steps.append(step_key)
        # åˆ é™¤æ—§çŠ¶æ€æ–‡ä»¶, å†™å…¥ä»…å«ä¿ç•™æ­¥éª¤çš„å¹²å‡€çŠ¶æ€
        if SETUP_STATE_FILE.exists():
            SETUP_STATE_FILE.unlink()
        if preserved_steps:
            new_state = _load_setup_state()  # è·å–é»˜è®¤å€¼
            new_state["deploy_steps_completed"] = preserved_steps
            _save_setup_state(new_state)
    except Exception as e:
        errors.append(f"é‡ç½®çŠ¶æ€å¤±è´¥: {e}")

    # 5. ä¿å­˜ PM2 é…ç½®
    subprocess.run("pm2 save 2>/dev/null || true", shell=True, timeout=15)

    if errors:
        return jsonify({"ok": False, "errors": errors}), 500
    return jsonify({"ok": True, "message": "å·²é‡ç½®, è¯·åˆ·æ–°é¡µé¢è¿›å…¥ Setup Wizard"})


# ====================================================================
# Setup Wizard API
# ====================================================================
_deploy_thread = None
_deploy_log_lines = []       # å®æ—¶æ—¥å¿—è¡Œç¼“å†², SSE æ¶ˆè´¹
_deploy_log_lock = threading.Lock()


def _detect_image_type():
    """æ£€æµ‹å½“å‰ç¯å¢ƒæ˜¯ prebuilt è¿˜æ˜¯ generic é•œåƒ
    é¢„æ„å»ºé•œåƒåœ¨ /opt/ComfyUI/ ä¿å­˜äº† ComfyUI å‰¯æœ¬,
    éƒ¨ç½²æ—¶å¤åˆ¶åˆ° /workspace/ComfyUI/"""
    opt_comfyui = Path("/opt/ComfyUI/main.py")
    if opt_comfyui.exists():
        return "prebuilt"
    return "generic"


@app.route("/api/setup/state")
def api_setup_state():
    """è·å–å‘å¯¼çŠ¶æ€"""
    state = _load_setup_state()
    # ä¸è¿”å›æ•æ„Ÿå€¼çš„å®Œæ•´å†…å®¹
    safe = {k: v for k, v in state.items() if k != "deploy_log"}
    safe["has_rclone_config"] = bool(state.get("rclone_config_value"))
    safe["rclone_config_value"] = ""   # ä¸æš´éœ²
    safe["plugins_available"] = DEFAULT_PLUGINS
    # GPU ä¿¡æ¯ (å¦‚æœ torch å¯ç”¨)
    safe["gpu_info"] = _detect_gpu_info()
    # é•œåƒç±»å‹è‡ªåŠ¨æ£€æµ‹
    safe["detected_image_type"] = _detect_image_type()
    # ç¯å¢ƒå˜é‡é¢„å¡«å…… â€” è®©å‘å¯¼è‡ªåŠ¨æ£€æµ‹å·²è®¾ç½®çš„å€¼
    env_vars = {}
    if os.environ.get("DASHBOARD_PASSWORD"):
        env_vars["password"] = os.environ["DASHBOARD_PASSWORD"]
    if os.environ.get("CF_TUNNEL_TOKEN"):
        env_vars["cloudflared_token"] = os.environ["CF_TUNNEL_TOKEN"]
    if os.environ.get("CIVITAI_TOKEN"):
        env_vars["civitai_token"] = os.environ["CIVITAI_TOKEN"]
    if os.environ.get("RCLONE_CONF_BASE64"):
        env_vars["rclone_config_method"] = "base64"
        env_vars["rclone_has_env"] = True  # ä¸æš´éœ²å®Œæ•´å€¼
    safe["env_vars"] = env_vars
    return jsonify(safe)


@app.route("/api/setup/save", methods=["POST"])
def api_setup_save():
    """ä¿å­˜å‘å¯¼æŸä¸€æ­¥çš„é…ç½®"""
    data = request.get_json(force=True)
    state = _load_setup_state()
    # åˆå¹¶å‰ç«¯æäº¤çš„å­—æ®µ
    allowed_keys = {
        "current_step", "image_type", "password",
        "cloudflared_token", "rclone_config_method", "rclone_config_value",
        "civitai_token", "plugins", "sync_options",
    }
    for k, v in data.items():
        if k in allowed_keys:
            state[k] = v
    _save_setup_state(state)
    return jsonify({"ok": True})


@app.route("/api/setup/plugins")
def api_setup_plugins():
    """è¿”å›é»˜è®¤æ’ä»¶åˆ—è¡¨"""
    return jsonify({"plugins": DEFAULT_PLUGINS})


_deploy_lock = threading.Lock()


@app.route("/api/setup/deploy", methods=["POST"])
def api_setup_deploy():
    """å¼€å§‹éƒ¨ç½² â€” åœ¨åå°çº¿ç¨‹æ‰§è¡Œå…¨éƒ¨å®‰è£…é€»è¾‘"""
    global _deploy_thread
    with _deploy_lock:
        if _deploy_thread and _deploy_thread.is_alive():
            return jsonify({"error": "éƒ¨ç½²å·²åœ¨è¿›è¡Œä¸­"}), 409

        state = _load_setup_state()
        state["deploy_started"] = True
        state["deploy_completed"] = False
        state["deploy_error"] = ""
        # ä¿ç•™ deploy_steps_completed ä»¥æ”¯æŒæ™ºèƒ½é‡è¯•
        _save_setup_state(state)

        with _deploy_log_lock:
            _deploy_log_lines.clear()

        _deploy_thread = threading.Thread(target=_run_deploy, args=(dict(state),), daemon=True)
        _deploy_thread.start()
    return jsonify({"ok": True, "message": "éƒ¨ç½²å·²å¯åŠ¨"})


@app.route("/api/setup/log_stream")
def api_setup_log_stream():
    """SSE å®æ—¶æ—¥å¿—æµ"""
    def generate():
        idx = 0
        while True:
            with _deploy_log_lock:
                new_lines = _deploy_log_lines[idx:]
                idx = len(_deploy_log_lines)
            for line in new_lines:
                yield f"data: {json.dumps(line, ensure_ascii=False)}\n\n"
            # æ£€æŸ¥æ˜¯å¦ç»“æŸ
            state = _load_setup_state()
            if state.get("deploy_completed") and idx >= len(_deploy_log_lines):
                yield f"data: {json.dumps({'type': 'done', 'success': True}, ensure_ascii=False)}\n\n"
                break
            if not _deploy_thread or not _deploy_thread.is_alive():
                if not state.get("deploy_completed"):
                    error_msg = state.get("deploy_error") or "éƒ¨ç½²è¿›ç¨‹å¼‚å¸¸ç»ˆæ­¢"
                    yield f"data: {json.dumps({'type': 'done', 'success': False, 'msg': error_msg}, ensure_ascii=False)}\n\n"
                break
            time.sleep(0.5)
    return Response(generate(), mimetype="text/event-stream",
                    headers={"Cache-Control": "no-cache", "X-Accel-Buffering": "no"})


@app.route("/api/setup/reset", methods=["POST"])
def api_setup_reset():
    """é‡ç½®å‘å¯¼ (è°ƒè¯•ç”¨)"""
    if SETUP_STATE_FILE.exists():
        SETUP_STATE_FILE.unlink()
    return jsonify({"ok": True})


def _detect_gpu_info():
    """æ£€æµ‹ GPU ä¿¡æ¯"""
    info = {"name": "", "cuda_cap": "", "vram_gb": 0}
    try:
        r = subprocess.run(
            'python3.13 -c "import torch; d=torch.cuda.get_device_properties(0); '
            'print(f\\"{d.name}|{d.major}.{d.minor}|{d.total_mem / 1073741824:.1f}\\")"',
            shell=True, capture_output=True, text=True, timeout=15
        )
        if r.returncode == 0 and "|" in r.stdout:
            parts = r.stdout.strip().split("|")
            info["name"] = parts[0]
            info["cuda_cap"] = parts[1]
            info["vram_gb"] = float(parts[2])
    except Exception:
        pass
    return info


# â”€â”€ éƒ¨ç½²æ‰§è¡Œå¼•æ“ â”€â”€
def _deploy_log(msg, level="info"):
    """å‘ SSE æ¨é€ä¸€è¡Œæ—¥å¿—"""
    entry = {"type": "log", "level": level, "msg": msg, "time": datetime.now().strftime("%H:%M:%S")}
    with _deploy_log_lock:
        _deploy_log_lines.append(entry)


def _deploy_step(name):
    """æ ‡è®°ä¸€ä¸ªéƒ¨ç½²æ­¥éª¤å¼€å§‹"""
    entry = {"type": "step", "name": name, "time": datetime.now().strftime("%H:%M:%S")}
    with _deploy_log_lock:
        _deploy_log_lines.append(entry)


def _deploy_exec(cmd, timeout=600, label=""):
    """æ‰§è¡Œ shell å‘½ä»¤, å®æ—¶æ¨é€è¾“å‡º"""
    if label:
        _deploy_log(f"$ {label}")
    try:
        proc = subprocess.Popen(
            cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT,
            text=True, bufsize=1
        )
        for line in proc.stdout:
            line = line.rstrip()
            if line:
                _deploy_log(line, "output")
        proc.wait(timeout=timeout)
        if proc.returncode != 0:
            _deploy_log(f"å‘½ä»¤é€€å‡ºç : {proc.returncode}", "warn")
        return proc.returncode == 0
    except Exception as e:
        _deploy_log(f"æ‰§è¡Œå¤±è´¥: {e}", "error")
        if proc:
            try:
                proc.kill()
                proc.stdout.close()
                proc.wait(timeout=5)
            except Exception:
                pass
        return False


def _step_done(step_key):
    """æ£€æŸ¥æŸä¸ªéƒ¨ç½²æ­¥éª¤æ˜¯å¦åœ¨ä¸Šæ¬¡å°è¯•ä¸­å·²å®Œæˆ (ç”¨äºæ™ºèƒ½é‡è¯•)"""
    state = _load_setup_state()
    return step_key in state.get("deploy_steps_completed", [])


def _mark_step_done(step_key):
    """æ ‡è®°æ­¥éª¤å®Œæˆå¹¶æŒä¹…åŒ–"""
    state = _load_setup_state()
    completed = state.get("deploy_steps_completed", [])
    if step_key not in completed:
        completed.append(step_key)
    state["deploy_steps_completed"] = completed
    _save_setup_state(state)


def _run_deploy(config):
    """ä¸»éƒ¨ç½²æµç¨‹ â€” åœ¨åå°çº¿ç¨‹è¿è¡Œ, å®Œæ•´å¤åˆ» deploy.sh / deploy-prebuilt.sh é€»è¾‘"""
    import base64 as _b64

    PY = "python3.13"
    PIP = f"{PY} -m pip"
    image_type = config.get("image_type", "generic")

    try:
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 1: ç³»ç»Ÿä¾èµ–
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if _step_done("system_deps"):
            _deploy_step("å®‰è£…ç³»ç»Ÿä¾èµ– âœ… (å·²å®Œæˆ, è·³è¿‡)")
        else:
            _deploy_step("å®‰è£…ç³»ç»Ÿä¾èµ–")
            _deploy_log("æ­£åœ¨å®‰è£…ç³»ç»Ÿä¾èµ–åŒ…...")
            _deploy_exec(
                "apt-get update -qq && "
                "apt-get install -y --no-install-recommends "
                "git git-lfs aria2 rclone jq curl ffmpeg libgl1 "
                "libglib2.0-0 libsm6 libxext6 build-essential",
                timeout=300, label="apt-get install"
            )

            # å°†ç³»ç»Ÿ python æŒ‡å‘ 3.13 (ä¿æŒåŸ deploy.sh é€»è¾‘)
            py313 = subprocess.run("command -v python3.13", shell=True, capture_output=True, text=True).stdout.strip()
            if py313:
                _deploy_exec(f'ln -sf "{py313}" /usr/local/bin/python && ln -sf "{py313}" /usr/bin/python || true')
            _deploy_exec(f'{PIP} install --upgrade pip setuptools packaging ninja -q', label="pip upgrade")
            _mark_step_done("system_deps")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 2: Cloudflare Tunnel
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        cf_token = config.get("cloudflared_token", "")
        if cf_token:
            # æ£€æŸ¥ tunnel æ˜¯å¦å·²åœ¨è¿è¡Œ (bootstrap å¯èƒ½å·²å¯åŠ¨)
            tunnel_pid = subprocess.run(
                "pm2 pid tunnel 2>/dev/null", shell=True, capture_output=True, text=True
            ).stdout.strip()
            tunnel_running = tunnel_pid and tunnel_pid != "0" and tunnel_pid.isdigit()

            if tunnel_running:
                _deploy_step("Cloudflare Tunnel (å·²åœ¨è¿è¡Œ)")
                _deploy_log("Tunnel å·²ç”± bootstrap å¯åŠ¨ï¼Œè·³è¿‡é‡å¯ä»¥ä¿æŒè¿æ¥ç¨³å®š")
            else:
                _deploy_step("å¯åŠ¨ Cloudflare Tunnel")
                # cloudflared å·²åœ¨ bootstrap.sh ä¸­å®‰è£…
                _deploy_exec("pm2 delete tunnel 2>/dev/null || true")
                _deploy_exec(f'pm2 start cloudflared --name tunnel -- tunnel run --token "{cf_token}"')
                _deploy_log("Cloudflare Tunnel å·²å¯åŠ¨")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 3: Rclone é…ç½®
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        rclone_method = config.get("rclone_config_method", "skip")
        rclone_value = config.get("rclone_config_value", "")
        # æ”¯æŒ base64_env: ä»ç¯å¢ƒå˜é‡ RCLONE_CONF_BASE64 è¯»å–
        if rclone_method == "base64_env":
            rclone_method = "base64"
            rclone_value = os.environ.get("RCLONE_CONF_BASE64", "")
        if rclone_method != "skip" and rclone_value:
            _deploy_step("é…ç½® Rclone")
            _deploy_exec("mkdir -p ~/.config/rclone")
            if rclone_method == "url":
                _deploy_log(f"ä» URL ä¸‹è½½ rclone.conf...")
                _deploy_exec(f'curl -fsSL "{rclone_value}" -o ~/.config/rclone/rclone.conf')
            elif rclone_method == "base64":
                _deploy_log("ä» Base64 è§£ç  rclone.conf...")
                try:
                    conf_text = _b64.b64decode(rclone_value).decode("utf-8")
                    Path.home().joinpath(".config/rclone/rclone.conf").write_text(conf_text, encoding="utf-8")
                except Exception as e:
                    _deploy_log(f"Base64 è§£ç å¤±è´¥: {e}", "error")
            _deploy_exec("chmod 600 ~/.config/rclone/rclone.conf")
            _deploy_exec("rclone listremotes", label="æ£€æµ‹ remotes")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 4: PyTorch
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if image_type == "generic":
            if _step_done("pytorch"):
                _deploy_step("å®‰è£… PyTorch âœ… (å·²å®Œæˆ, è·³è¿‡)")
            else:
                _deploy_step("å®‰è£… PyTorch")
                TORCH_INDEX = "https://download.pytorch.org/whl/cu128"
                _deploy_log("å®‰è£… torch 2.9.1 (CUDA 12.8)...")
                _deploy_exec(
                    f'{PIP} install --no-cache-dir torch==2.9.1 --index-url "{TORCH_INDEX}"',
                    timeout=600, label="pip install torch"
                )
                _deploy_exec(f'{PIP} install --no-cache-dir hf_transfer', label="hf_transfer")
                _mark_step_done("pytorch")
        else:
            _deploy_step("æ£€æŸ¥é¢„è£… PyTorch")
            _deploy_log("é¢„æ„å»ºé•œåƒ â€” è·³è¿‡ torch å®‰è£…")
            _deploy_exec(f'{PY} -c "import torch; print(f\\"PyTorch {{torch.__version__}} CUDA {{torch.version.cuda}}\\")"')

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 5: ComfyUI
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if _step_done("comfyui_install"):
            _deploy_step("å®‰è£… ComfyUI âœ… (å·²å®Œæˆ, è·³è¿‡)")
            _deploy_step("ComfyUI å¥åº·æ£€æŸ¥ âœ… (å·²å®Œæˆ, è·³è¿‡)")
        else:
            _deploy_step("å®‰è£… ComfyUI")
            if image_type == "prebuilt":
                # é¢„æ„å»ºé•œåƒ: ä» /opt/ComfyUI å¤åˆ¶
                if not Path("/workspace/ComfyUI/main.py").exists():
                    _deploy_log("ä»é•œåƒå¤åˆ¶ ComfyUI...")
                    _deploy_exec("mkdir -p /workspace/ComfyUI && cp -r /opt/ComfyUI/* /workspace/ComfyUI/")
                else:
                    _deploy_log("ComfyUI å·²å­˜åœ¨, è·³è¿‡å¤åˆ¶")
            else:
                # é€šç”¨é•œåƒ: git clone
                if Path("/workspace/ComfyUI").exists():
                    _deploy_exec("rm -rf /workspace/ComfyUI")
                _deploy_log("å…‹éš† ComfyUI ä»“åº“...")
                _deploy_exec("cd /workspace && git clone https://github.com/comfyanonymous/ComfyUI.git", timeout=120)
                _deploy_log("å®‰è£… ComfyUI ä¾èµ–...")
                _deploy_exec(f"cd /workspace/ComfyUI && {PIP} install --no-cache-dir -r requirements.txt", timeout=300)

            # å¥åº·æ£€æŸ¥ (ä¸åŠ è½½æ’ä»¶, ä»…éªŒè¯ ComfyUI æ ¸å¿ƒèƒ½å¯åŠ¨)
            _deploy_step("ComfyUI å¥åº·æ£€æŸ¥")
            _deploy_log("å¯åŠ¨é¦–æ¬¡å¥åº·æ£€æŸ¥ (è·³è¿‡æ’ä»¶åŠ è½½)...")
            _deploy_exec(f'cd /workspace/ComfyUI && {PY} main.py --listen 127.0.0.1 --port 8188 --disable-all-custom-nodes > /tmp/comfy_boot.log 2>&1 &')
            boot_ok = False
            for i in range(30):
                time.sleep(2)
                try:
                    log = Path("/tmp/comfy_boot.log").read_text(errors="ignore")
                    if "To see the GUI go to" in log:
                        boot_ok = True
                        break
                except Exception:
                    pass
                _deploy_log(f"ç­‰å¾… ComfyUI å¯åŠ¨... ({i+1}/30)")

            # æ¸…ç†å¥åº·æ£€æŸ¥è¿›ç¨‹
            _deploy_exec("pkill -f 'main.py --listen 127.0.0.1 --port 8188 --disable-all-custom-nodes' 2>/dev/null; sleep 1", label="åœæ­¢æ£€æŸ¥è¿›ç¨‹")

            if boot_ok:
                _deploy_log("âœ… ComfyUI å¥åº·æ£€æŸ¥é€šè¿‡")
            else:
                _deploy_log("âŒ ComfyUI å¥åº·æ£€æŸ¥å¤±è´¥!", "error")
                try:
                    err = Path("/tmp/comfy_boot.log").read_text(errors="ignore")[-500:]
                    _deploy_log(f"æœ€åæ—¥å¿—: {err}", "error")
                except Exception:
                    pass
                # ä¸ä¸­æ–­, ç»§ç»­åç»­æ­¥éª¤

            _mark_step_done("comfyui_install")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 6: åŠ é€Ÿç»„ä»¶ (FA3 / SA3)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if image_type == "generic":
            if _step_done("accelerators"):
                _deploy_step("å®‰è£…åŠ é€Ÿç»„ä»¶ âœ… (å·²å®Œæˆ, è·³è¿‡)")
            else:
                _deploy_step("å®‰è£…åŠ é€Ÿç»„ä»¶ (FA3/SA3)")
                _deploy_log("æ£€æµ‹ GPU æ¶æ„...")
                gpu_info = _detect_gpu_info()
                cuda_cap = gpu_info.get("cuda_cap", "0.0")
                cuda_major = int(cuda_cap.split(".")[0]) if cuda_cap else 0
                _deploy_log(f"GPU: {gpu_info.get('name', '?')} | CUDA Cap: {cuda_cap}")

                # Python ç‰ˆæœ¬ tag
                py_ver_tag = subprocess.run(
                    f'{PY} -c "import sys; print(f\\"cp{{sys.version_info.major}}{{sys.version_info.minor}}\\")"',
                    shell=True, capture_output=True, text=True, timeout=5
                ).stdout.strip()

                # ä¸‹è½½é¢„ç¼–è¯‘ wheels
                GH_WHEELS = "https://github.com/vvb7456/ComfyCarry/releases/download/v4.5-wheels"
                _deploy_exec("mkdir -p /workspace/prebuilt_wheels")
                _deploy_exec(
                    f'wget -q -O /workspace/prebuilt_wheels/flash_attn_3-3.0.0b1-cp39-abi3-linux_x86_64.whl '
                    f'"{GH_WHEELS}/flash_attn_3-3.0.0b1-cp39-abi3-linux_x86_64.whl" || true',
                    label="ä¸‹è½½ FA3 wheel"
                )
                if py_ver_tag in ("cp313", "cp312"):
                    _deploy_exec(
                        f'wget -q -O /workspace/prebuilt_wheels/sageattn3-1.0.0-{py_ver_tag}-{py_ver_tag}-linux_x86_64.whl '
                        f'"{GH_WHEELS}/sageattn3-1.0.0-{py_ver_tag}-{py_ver_tag}-linux_x86_64.whl" || true',
                        label=f"ä¸‹è½½ SA3 wheel ({py_ver_tag})"
                    )

                # FlashAttention å®‰è£… (ä¿æŒåŸ deploy.sh é€»è¾‘)
                if cuda_major >= 9:
                    fa_wheel = "/workspace/prebuilt_wheels/flash_attn_3-3.0.0b1-cp39-abi3-linux_x86_64.whl"
                    if not _deploy_exec(f'[ -f "{fa_wheel}" ] && {PIP} install "{fa_wheel}"'):
                        _deploy_log("Wheel ä¸å¯ç”¨, æºç ç¼–è¯‘ FA3...", "warn")
                        _deploy_exec(
                            f'cd /workspace && git clone https://github.com/Dao-AILab/flash-attention.git && '
                            f'cd flash-attention/hopper && MAX_JOBS=8 {PY} setup.py install && '
                            f'cd /workspace && rm -rf flash-attention',
                            timeout=1200, label="ç¼–è¯‘ FA3"
                        )
                else:
                    _deploy_exec(f'{PIP} install --no-cache-dir flash-attn --no-build-isolation',
                                 timeout=600, label="å®‰è£… FA2")

                # SageAttention å®‰è£… (ä¿æŒåŸ deploy.sh é€»è¾‘)
                if cuda_major >= 10:
                    sa_wheel = f"/workspace/prebuilt_wheels/sageattn3-1.0.0-{py_ver_tag}-{py_ver_tag}-linux_x86_64.whl"
                    if not _deploy_exec(f'[ -f "{sa_wheel}" ] && {PIP} install "{sa_wheel}"'):
                        _deploy_log("Wheel ä¸å¯ç”¨, æºç ç¼–è¯‘ SA3...", "warn")
                        _deploy_exec(
                            f'cd /workspace && git clone https://github.com/thu-ml/SageAttention.git && '
                            f'cd SageAttention/sageattention3_blackwell && {PY} setup.py install && '
                            f'cd /workspace && rm -rf SageAttention',
                            timeout=1200, label="ç¼–è¯‘ SA3"
                        )
                else:
                    _deploy_exec(
                        f'cd /workspace && git clone https://github.com/thu-ml/SageAttention.git && '
                        f'cd SageAttention && {PIP} install . --no-build-isolation && '
                        f'cd /workspace && rm -rf SageAttention',
                        timeout=600, label="å®‰è£… SA2"
                    )

                _deploy_exec("rm -rf /workspace/prebuilt_wheels")
                _deploy_log("âœ… åŠ é€Ÿç»„ä»¶å®‰è£…å®Œæˆ")
                _mark_step_done("accelerators")
        else:
            _deploy_step("æ£€æŸ¥åŠ é€Ÿç»„ä»¶")
            _deploy_log("é¢„æ„å»ºé•œåƒ â€” FA3/SA3 å·²é¢„è£…, è·³è¿‡")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 7: æ’ä»¶å®‰è£…
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("å®‰è£…æ’ä»¶")
        plugins = config.get("plugins", [])
        if image_type == "prebuilt":
            _deploy_log("é¢„æ„å»ºé•œåƒå·²å«æ’ä»¶, æ£€æŸ¥é¢å¤–æ’ä»¶...")
            # åªå®‰è£…ä¸åœ¨é•œåƒä¸­çš„æ–°æ’ä»¶
            for url in plugins:
                name = url.rstrip("/").split("/")[-1].replace(".git", "")
                if not Path(f"/workspace/ComfyUI/custom_nodes/{name}").exists():
                    _deploy_log(f"å®‰è£…æ–°æ’ä»¶: {name}")
                    _deploy_exec(f'cd /workspace/ComfyUI/custom_nodes && git clone "{url}" || true', timeout=60)
        else:
            _deploy_log(f"å®‰è£… {len(plugins)} ä¸ªæ’ä»¶...")
            _deploy_exec("mkdir -p /workspace/ComfyUI/custom_nodes")
            for url in plugins:
                name = url.rstrip("/").split("/")[-1].replace(".git", "")
                _deploy_log(f"  å…‹éš† {name}...")
                _deploy_exec(f'cd /workspace/ComfyUI/custom_nodes && git clone "{url}" || true', timeout=60)

        # æ‰¹é‡å®‰è£…æ’ä»¶ä¾èµ–
        _deploy_log("å®‰è£…æ’ä»¶ä¾èµ–...")
        _deploy_exec(
            f'find /workspace/ComfyUI/custom_nodes -name "requirements.txt" -type f '
            f'-exec {PIP} install --no-cache-dir -r {{}} \\; 2>&1 || true',
            timeout=600, label="pip install plugin deps"
        )

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 8: æ‰§è¡Œ deploy åŒæ­¥è§„åˆ™
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if rclone_method != "skip" and rclone_value:
            _deploy_step("åŒæ­¥äº‘ç«¯èµ„äº§")
            # è¿ç§»æ—§é…ç½®æˆ–åŠ è½½è§„åˆ™
            _migrate_old_sync_prefs()
            rules = _load_sync_rules()
            deploy_rules = [r for r in rules if r.get("trigger") == "deploy" and r.get("enabled", True)]
            if deploy_rules:
                for rule in deploy_rules:
                    name = rule.get("name", rule.get("id", "?"))
                    _deploy_log(f"æ‰§è¡Œ: {name}...")
                    ok = _run_sync_rule(rule)
                    if not ok:
                        _deploy_log(f"âš ï¸ {name} æœªå®Œå…¨æˆåŠŸ, ç»§ç»­", "warning")
                _deploy_log("âœ… èµ„äº§åŒæ­¥å®Œæˆ")
            else:
                _deploy_log("æ²¡æœ‰ deploy åŒæ­¥è§„åˆ™, è·³è¿‡")
        else:
            _deploy_log("æœªé…ç½® Rclone, è·³è¿‡èµ„äº§åŒæ­¥")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 9: å¯åŠ¨æœåŠ¡
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("å¯åŠ¨æœåŠ¡")

        # å¯åŠ¨ Sync Worker (å¦‚æœ‰ watch è§„åˆ™)
        if rclone_method != "skip" and rclone_value:
            rules = _load_sync_rules()
            watch_rules = [r for r in rules if r.get("trigger") == "watch" and r.get("enabled", True)]
            if watch_rules:
                _start_sync_worker()
                _deploy_log(f"âœ… Sync Worker å·²å¯åŠ¨ ({len(watch_rules)} æ¡ç›‘æ§è§„åˆ™)")

        # CivitAI API Key
        civitai_token = config.get("civitai_token", "")
        if civitai_token:
            CONFIG_FILE.write_text(json.dumps({"api_key": civitai_token}))
            _deploy_log("CivitAI API Key å·²ä¿å­˜")

        # å¯åŠ¨ ComfyUI
        _deploy_log("å¯åŠ¨ ComfyUI ä¸»æœåŠ¡...")
        _deploy_exec("pm2 delete comfy 2>/dev/null || true")
        _deploy_exec(
            f'cd /workspace/ComfyUI && pm2 start {PY} --name comfy '
            f'--interpreter none --log /workspace/comfy.log --time '
            f'--restart-delay 3000 --max-restarts 10 '
            f'-- main.py --listen 0.0.0.0 --port 8188 '
            f'--use-pytorch-cross-attention --fast --disable-xformers'
        )

        # ä¿å­˜ PM2 é…ç½®
        _deploy_exec("pm2 save 2>/dev/null || true")

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # STEP 10: åå°ä»»åŠ¡
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("åå°ä»»åŠ¡")

        # jtoken å¿«æ·å‘½ä»¤
        _deploy_log("å®‰è£… jtoken å‘½ä»¤...")
        jtoken_script = '''#!/bin/bash
echo 'ğŸ” æ­£åœ¨æŸ¥æ‰¾ Jupyter ä¿¡æ¯...'
JUPYTER_TOKEN=$(ps aux | grep '[j]upyter-lab' | grep -oP 'token=\\K[a-zA-Z0-9-]+' | head -1)
JUPYTER_PORT=$(ps aux | grep '[j]upyter-lab' | grep -oP -- '--port=\\K[0-9]+' | head -1)
if [ -z "$JUPYTER_TOKEN" ]; then echo 'âŒ Jupyter Lab æœªè¿è¡Œ'; exit 1; fi
echo "ğŸ“Š Jupyter Lab: ç«¯å£=${JUPYTER_PORT:-æœªçŸ¥} Token=$JUPYTER_TOKEN"
if command -v pm2 >/dev/null 2>&1; then
    JUPYTER_DOMAIN=$(pm2 logs tunnel --nostream --lines 100 2>/dev/null | grep -oP 'dest=https://jupyter[^/]+' | head -1 | sed 's/dest=https:\\/\\///')
    [ -n "$JUPYTER_DOMAIN" ] && echo "ğŸŒ https://$JUPYTER_DOMAIN/?token=$JUPYTER_TOKEN"
fi
echo "ğŸ”— http://localhost:${JUPYTER_PORT}/?token=$JUPYTER_TOKEN"
'''
        Path("/usr/local/bin/jtoken").write_text(jtoken_script)
        _deploy_exec("chmod +x /usr/local/bin/jtoken")

        # AuraSR ä¸‹è½½ (å‰å°, æ˜¾ç¤ºè¿›åº¦)
        _deploy_log("ä¸‹è½½ AuraSR V2...")
        _deploy_exec("mkdir -p /workspace/ComfyUI/models/Aura-SR")
        _deploy_exec(
            'aria2c -x 16 -s 16 '
            '-d "/workspace/ComfyUI/models/Aura-SR" -o "model.safetensors" '
            '"https://huggingface.co/fal/AuraSR-v2/resolve/main/model.safetensors?download=true"',
            timeout=300, label="AuraSR model.safetensors"
        )
        _deploy_exec(
            'aria2c -x 16 -s 16 '
            '-d "/workspace/ComfyUI/models/Aura-SR" -o "config.json" '
            '"https://huggingface.co/fal/AuraSR-v2/resolve/main/config.json?download=true"',
            timeout=60, label="AuraSR config.json"
        )

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # å®Œæˆ
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        _deploy_step("éƒ¨ç½²å®Œæˆ")

        # æ›´æ–° Dashboard å¯†ç  (æŒä¹…åŒ–)
        new_pw = config.get("password", "")
        if new_pw:
            global DASHBOARD_PASSWORD
            DASHBOARD_PASSWORD = new_pw
            _save_dashboard_password(new_pw)
            _deploy_log(f"Dashboard å¯†ç å·²æ›´æ–°å¹¶ä¿å­˜")

        state = _load_setup_state()
        state["deploy_completed"] = True
        state["deploy_error"] = ""
        state["deploy_steps_completed"] = []  # æ¸…ç†: æˆåŠŸåæ— éœ€ä¿ç•™
        _save_setup_state(state)

        gpu_info = _detect_gpu_info()
        _deploy_log(f"ğŸš€ éƒ¨ç½²å®Œæˆ! GPU: {gpu_info.get('name', '?')} | CUDA: {gpu_info.get('cuda_cap', '?')}")
        _deploy_log("è¯·åˆ·æ–°é¡µé¢è¿›å…¥ Dashboard")

    except Exception as e:
        _deploy_log(f"âŒ éƒ¨ç½²å¤±è´¥: {e}", "error")
        import traceback
        _deploy_log(traceback.format_exc(), "error")
        # ä¿å­˜é”™è¯¯çŠ¶æ€, å…è®¸é‡è¯• (deploy_steps_completed å·²é€æ­¥ä¿å­˜)
        try:
            state = _load_setup_state()
            state["deploy_error"] = str(e)
            state["deploy_started"] = False
            _save_setup_state(state)
        except Exception:
            pass


# ====================================================================
# Cloud Sync v2 â€” è§„åˆ™é©±åŠ¨çš„çµæ´»åŒæ­¥å¼•æ“
# ====================================================================
RCLONE_CONF = Path.home() / ".config" / "rclone" / "rclone.conf"
SYNC_RULES_FILE = Path("/workspace/.sync_rules.json")
SYNC_PREFS_FILE = Path("/workspace/.sync_prefs.json")  # å‘åå…¼å®¹

# åŒæ­¥è§„åˆ™é¢„è®¾æ¨¡æ¿ (å‰ç«¯å¿«é€Ÿæ·»åŠ )
SYNC_RULE_TEMPLATES = [
    {"id": "tpl-pull-workflows",  "name": "â¬‡ï¸ ä¸‹æ‹‰å·¥ä½œæµ",        "direction": "pull", "remote_path": "comfyui-assets/workflow",    "local_path": "user/default/workflows", "method": "sync",  "trigger": "deploy"},
    {"id": "tpl-pull-loras",      "name": "â¬‡ï¸ ä¸‹æ‹‰ LoRA",         "direction": "pull", "remote_path": "comfyui-assets/loras",       "local_path": "models/loras",           "method": "sync",  "trigger": "deploy"},
    {"id": "tpl-pull-checkpoints","name": "â¬‡ï¸ ä¸‹æ‹‰ Checkpoints",  "direction": "pull", "remote_path": "comfyui-assets/checkpoints", "local_path": "models/checkpoints",     "method": "sync",  "trigger": "deploy"},
    {"id": "tpl-pull-controlnet", "name": "â¬‡ï¸ ä¸‹æ‹‰ ControlNet",   "direction": "pull", "remote_path": "comfyui-assets/controlnet",  "local_path": "models/controlnet",      "method": "sync",  "trigger": "deploy"},
    {"id": "tpl-pull-embeddings", "name": "â¬‡ï¸ ä¸‹æ‹‰ Embeddings",   "direction": "pull", "remote_path": "comfyui-assets/embeddings",  "local_path": "models/embeddings",      "method": "sync",  "trigger": "deploy"},
    {"id": "tpl-pull-vae",        "name": "â¬‡ï¸ ä¸‹æ‹‰ VAE",          "direction": "pull", "remote_path": "comfyui-assets/vae",         "local_path": "models/vae",             "method": "sync",  "trigger": "deploy"},
    {"id": "tpl-pull-upscale",    "name": "â¬‡ï¸ ä¸‹æ‹‰ Upscale",      "direction": "pull", "remote_path": "comfyui-assets/upscale",     "local_path": "models/upscale_models",  "method": "sync",  "trigger": "deploy"},
    {"id": "tpl-pull-wildcards",  "name": "â¬‡ï¸ ä¸‹æ‹‰ Wildcards",    "direction": "pull", "remote_path": "comfyui-assets/wildcards",   "local_path": "custom_nodes/comfyui-dynamicprompts/wildcards", "method": "sync", "trigger": "deploy"},
    {"id": "tpl-pull-input",      "name": "â¬‡ï¸ ä¸‹æ‹‰ Input ç´ æ",   "direction": "pull", "remote_path": "comfyui-assets/input",       "local_path": "input",                  "method": "sync",  "trigger": "deploy"},
    {"id": "tpl-push-output",     "name": "â¬†ï¸ ä¸Šä¼ è¾“å‡º (ç§»åŠ¨)",    "direction": "push", "remote_path": "ComfyUI_Output",             "local_path": "output",                 "method": "move",  "trigger": "watch", "watch_interval": 15, "filters": ["+ *.{png,jpg,jpeg,webp,gif,mp4,mov,webm}", "- .*/**", "- *"]},
    {"id": "tpl-push-output-copy","name": "â¬†ï¸ ä¸Šä¼ è¾“å‡º (ä¿ç•™æœ¬åœ°)","direction": "push", "remote_path": "ComfyUI_Output",             "local_path": "output",                 "method": "copy",  "trigger": "watch", "watch_interval": 15, "filters": ["+ *.{png,jpg,jpeg,webp,gif,mp4,mov,webm}", "- .*/**", "- *"]},
    {"id": "tpl-push-workflows",  "name": "â¬†ï¸ å¤‡ä»½å·¥ä½œæµ",        "direction": "push", "remote_path": "comfyui-assets/workflow",     "local_path": "user/default/workflows", "method": "sync",  "trigger": "manual"},
]

# Remote ç±»å‹è¡¨å•å®šä¹‰ (é OAuth)
REMOTE_TYPE_DEFS = {
    "s3": {
        "label": "S3 / Cloudflare R2",
        "icon": "â˜ï¸",
        "fields": [
            {"key": "provider", "label": "Provider", "type": "select", "options": ["Cloudflare", "AWS", "Minio", "DigitalOcean", "Wasabi", "Other"], "default": "Cloudflare"},
            {"key": "access_key_id", "label": "Access Key ID", "type": "text", "required": True},
            {"key": "secret_access_key", "label": "Secret Access Key", "type": "password", "required": True},
            {"key": "endpoint", "label": "Endpoint URL", "type": "text", "required": True, "placeholder": "https://<account_id>.r2.cloudflarestorage.com"},
            {"key": "acl", "label": "ACL", "type": "text", "default": "private"},
        ],
    },
    "sftp": {
        "label": "SFTP",
        "icon": "ğŸ–¥ï¸",
        "fields": [
            {"key": "host", "label": "Host", "type": "text", "required": True},
            {"key": "port", "label": "Port", "type": "text", "default": "22"},
            {"key": "user", "label": "ç”¨æˆ·å", "type": "text", "required": True},
            {"key": "pass", "label": "å¯†ç ", "type": "password"},
            {"key": "key_file", "label": "SSH Key è·¯å¾„", "type": "text", "placeholder": "~/.ssh/id_rsa"},
        ],
    },
    "webdav": {
        "label": "WebDAV",
        "icon": "ğŸŒ",
        "fields": [
            {"key": "url", "label": "WebDAV URL", "type": "text", "required": True},
            {"key": "user", "label": "ç”¨æˆ·å", "type": "text"},
            {"key": "pass", "label": "å¯†ç ", "type": "password"},
            {"key": "vendor", "label": "Vendor", "type": "select", "options": ["other", "nextcloud", "owncloud", "sharepoint"], "default": "other"},
        ],
    },
    "onedrive": {
        "label": "OneDrive",
        "icon": "ğŸ“",
        "oauth": True,
        "fields": [
            {"key": "token", "label": "OAuth Token", "type": "textarea", "required": True,
             "help": "åœ¨æœ¬åœ°æ‰§è¡Œ <code>rclone authorize \"onedrive\"</code> è·å– token JSON"},
        ],
    },
    "drive": {
        "label": "Google Drive",
        "icon": "ğŸ“‚",
        "oauth": True,
        "fields": [
            {"key": "token", "label": "OAuth Token", "type": "textarea", "required": True,
             "help": "åœ¨æœ¬åœ°æ‰§è¡Œ <code>rclone authorize \"drive\"</code> è·å– token JSON"},
        ],
    },
    "dropbox": {
        "label": "Dropbox",
        "icon": "ğŸ“¦",
        "oauth": True,
        "fields": [
            {"key": "token", "label": "OAuth Token", "type": "textarea", "required": True,
             "help": "åœ¨æœ¬åœ°æ‰§è¡Œ <code>rclone authorize \"dropbox\"</code> è·å– token JSON"},
        ],
    },
}


# â”€â”€ Sync Rules CRUD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _load_sync_rules():
    """åŠ è½½åŒæ­¥è§„åˆ™"""
    if SYNC_RULES_FILE.exists():
        try:
            return json.loads(SYNC_RULES_FILE.read_text(encoding="utf-8"))
        except Exception:
            pass
    return []


def _save_sync_rules(rules):
    """ä¿å­˜åŒæ­¥è§„åˆ™"""
    SYNC_RULES_FILE.write_text(json.dumps(rules, indent=2, ensure_ascii=False), encoding="utf-8")


def _parse_rclone_conf():
    """è§£æ rclone.conf è¿”å› remote åˆ—è¡¨"""
    remotes = []
    if not RCLONE_CONF.exists():
        return remotes
    current = None
    for line in RCLONE_CONF.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        m = re.match(r'^\[(.+)\]$', line)
        if m:
            if current:
                remotes.append(current)
            current = {"name": m.group(1), "type": "", "params": {},
                        "_has_token": False, "_has_keys": False}
        elif current and '=' in line:
            k, v = line.split('=', 1)
            k, v = k.strip(), v.strip()
            if k == "type":
                current["type"] = v
            if k == "token" and v:
                current["_has_token"] = True
            if k == "access_key_id" and v:
                current["_has_keys"] = True
            if k not in ("token", "access_key_id", "secret_access_key", "refresh_token"):
                current["params"][k] = v
    if current:
        remotes.append(current)
    return remotes


# â”€â”€ Sync Worker (Python åå°çº¿ç¨‹) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_sync_worker_thread = None
_sync_worker_stop = threading.Event()
_sync_log_buffer = []         # æœ€è¿‘ 300 è¡Œæ—¥å¿—
_sync_log_lock = threading.Lock()


def _sync_log(msg):
    """å†™æ—¥å¿—åˆ°å†…å­˜ buffer"""
    ts = time.strftime("%H:%M:%S")
    line = f"[{ts}] {msg}"
    with _sync_log_lock:
        _sync_log_buffer.append(line)
        if len(_sync_log_buffer) > 300:
            _sync_log_buffer[:] = _sync_log_buffer[-300:]
    app.logger.debug(f"[sync] {msg}")


def _run_sync_rule(rule):
    """æ‰§è¡Œå•æ¡åŒæ­¥è§„åˆ™ (rclone subprocess)"""
    remote = rule.get("remote", "")
    remote_path = rule.get("remote_path", "")
    local_rel = rule.get("local_path", "")
    method = rule.get("method", "sync")    # sync|copy|move
    direction = rule.get("direction", "pull")
    filters = rule.get("filters", [])
    name = rule.get("name", rule.get("id", "?"))

    local_abs = os.path.join(COMFYUI_DIR, local_rel)
    os.makedirs(local_abs, exist_ok=True)

    remote_spec = f"{remote}:{remote_path}"
    if direction == "pull":
        src, dst = remote_spec, local_abs
    else:
        src, dst = local_abs, remote_spec

    cmd = ["rclone", method, src, dst, "--transfers", "4", "-P"]
    for f in filters:
        cmd.extend(["--filter", f])

    _sync_log(f"{'â¬‡' if direction == 'pull' else 'â¬†'} {name}: {src} â†’ {dst} ({method})")
    try:
        proc = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
        # æå– rclone è¾“å‡ºæ‘˜è¦
        output = (proc.stdout + proc.stderr).strip()
        if output:
            for line in output.split('\n')[-3:]:
                line = line.strip()
                if line:
                    _sync_log(f"  {line}")
        if proc.returncode == 0:
            _sync_log(f"âœ… {name} å®Œæˆ")
        else:
            _sync_log(f"âŒ {name} å¤±è´¥ (code={proc.returncode})")
        return proc.returncode == 0
    except subprocess.TimeoutExpired:
        _sync_log(f"â° {name} è¶…æ—¶ (600s)")
        return False
    except Exception as e:
        _sync_log(f"âŒ {name} å¼‚å¸¸: {e}")
        return False


def _sync_worker_loop():
    """åå°çº¿ç¨‹: æŒç»­æ‰§è¡Œ watch ç±»å‹è§„åˆ™"""
    _sync_log("â˜ï¸ Sync Worker å·²å¯åŠ¨")
    while not _sync_worker_stop.is_set():
        rules = _load_sync_rules()
        watch_rules = [r for r in rules if r.get("trigger") == "watch" and r.get("enabled", True)]
        if not watch_rules:
            _sync_worker_stop.wait(30)
            continue
        for rule in watch_rules:
            if _sync_worker_stop.is_set():
                break
            _run_sync_rule(rule)
        # ç­‰å¾…æœ€çŸ­ intervalï¼Œé»˜è®¤ 15 ç§’
        intervals = [r.get("watch_interval", 15) for r in watch_rules]
        wait = max(min(intervals), 5) if intervals else 15
        _sync_worker_stop.wait(wait)
    _sync_log("ğŸ›‘ Sync Worker å·²åœæ­¢")


def _start_sync_worker():
    """å¯åŠ¨ sync worker åå°çº¿ç¨‹"""
    global _sync_worker_thread
    _stop_sync_worker()
    _sync_worker_stop.clear()
    _sync_worker_thread = threading.Thread(target=_sync_worker_loop, daemon=True, name="sync-worker")
    _sync_worker_thread.start()
    return True


def _stop_sync_worker():
    """åœæ­¢ sync worker"""
    global _sync_worker_thread
    _sync_worker_stop.set()
    if _sync_worker_thread and _sync_worker_thread.is_alive():
        _sync_worker_thread.join(timeout=5)
    _sync_worker_thread = None


# â”€â”€ API ç«¯ç‚¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.route("/api/sync/status")
def api_sync_status():
    """è·å– Sync Worker çŠ¶æ€å’Œæ—¥å¿—"""
    worker_running = _sync_worker_thread is not None and _sync_worker_thread.is_alive()

    # ä¹Ÿæ£€æŸ¥æ—§çš„ PM2 sync è¿›ç¨‹ (å‘åå…¼å®¹)
    pm2_status = "stopped"
    try:
        r = subprocess.run("pm2 jlist 2>/dev/null", shell=True, capture_output=True, text=True, timeout=5)
        if r.returncode == 0:
            for p in json.loads(r.stdout or "[]"):
                if p.get("name") == "sync":
                    pm2_status = p.get("pm2_env", {}).get("status", "unknown")
                    break
    except Exception:
        pass

    with _sync_log_lock:
        log_lines = list(_sync_log_buffer)

    rules = _load_sync_rules()
    return jsonify({
        "worker_running": worker_running,
        "pm2_status": pm2_status,
        "log_lines": log_lines,
        "rules": rules,
    })


@app.route("/api/sync/remotes")
def api_sync_remotes():
    """åˆ—å‡º rclone é…ç½®çš„ remote"""
    remotes = _parse_rclone_conf()
    for r in remotes:
        t = r["type"]
        type_def = REMOTE_TYPE_DEFS.get(t, {})
        r["display_name"] = type_def.get("label", t)
        r["icon"] = type_def.get("icon", "ğŸ’¾")
        r["has_auth"] = bool(r.get("_has_token") or r.get("_has_keys"))
    return jsonify({"remotes": remotes})


@app.route("/api/sync/remote/create", methods=["POST"])
def api_sync_remote_create():
    """åˆ›å»ºæ–°çš„ rclone remote"""
    data = request.get_json(force=True)
    name = data.get("name", "").strip()
    rtype = data.get("type", "").strip()
    params = data.get("params", {})

    if not name or not rtype:
        return jsonify({"error": "name å’Œ type å¿…å¡«"}), 400
    if not re.match(r'^[a-zA-Z0-9_-]+$', name):
        return jsonify({"error": "Remote åç§°åªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’ŒçŸ­æ¨ªçº¿"}), 400

    # å·²å­˜åœ¨æ£€æŸ¥
    existing = [r["name"] for r in _parse_rclone_conf()]
    if name in existing:
        return jsonify({"error": f"Remote '{name}' å·²å­˜åœ¨"}), 409

    # æ„å»º rclone config create å‘½ä»¤
    cmd = f'rclone config create "{name}" "{rtype}"'
    for k, v in params.items():
        if v:
            # å¯¹ token ç­‰å«ç‰¹æ®Šå­—ç¬¦çš„å€¼éœ€è¦å®‰å…¨ä¼ é€’
            cmd += f" {k}={shlex.quote(str(v))}"

    try:
        r = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=15)
        if r.returncode != 0:
            return jsonify({"error": f"åˆ›å»ºå¤±è´¥: {r.stderr.strip() or r.stdout.strip()}"}), 500
    except Exception as e:
        return jsonify({"error": str(e)}), 500

    return jsonify({"ok": True, "message": f"Remote '{name}' å·²åˆ›å»º"})


@app.route("/api/sync/remote/delete", methods=["POST"])
def api_sync_remote_delete():
    """åˆ é™¤ rclone remote"""
    data = request.get_json(force=True)
    name = data.get("name", "").strip()
    if not name:
        return jsonify({"error": "ç¼ºå°‘ remote åç§°"}), 400
    try:
        r = subprocess.run(f'rclone config delete "{name}"', shell=True, capture_output=True, text=True, timeout=10)
        if r.returncode != 0:
            return jsonify({"error": f"åˆ é™¤å¤±è´¥: {r.stderr.strip()}"}), 500
    except Exception as e:
        return jsonify({"error": str(e)}), 500
    return jsonify({"ok": True, "message": f"Remote '{name}' å·²åˆ é™¤"})


@app.route("/api/sync/remote/browse", methods=["POST"])
def api_sync_remote_browse():
    """æµè§ˆ remote è·¯å¾„ä¸‹çš„ç›®å½•"""
    data = request.get_json(force=True)
    remote = data.get("remote", "")
    path = data.get("path", "")
    try:
        cmd = f'rclone lsjson "{remote}:{path}" --dirs-only -R --max-depth 1 2>/dev/null'
        r = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)
        if r.returncode == 0:
            items = json.loads(r.stdout or "[]")
            dirs = [i["Path"] for i in items if i.get("IsDir")]
            return jsonify({"ok": True, "dirs": sorted(dirs)})
        return jsonify({"ok": True, "dirs": []})
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route("/api/sync/remote/types")
def api_sync_remote_types():
    """è¿”å›æ”¯æŒçš„ remote ç±»å‹å®šä¹‰ (å‰ç«¯è¡¨å•æ¸²æŸ“)"""
    return jsonify({"types": REMOTE_TYPE_DEFS})


@app.route("/api/sync/storage")
def api_sync_storage():
    """è·å–å„ remote çš„å®¹é‡ä¿¡æ¯"""
    remotes = _parse_rclone_conf()
    results = {}
    for r in remotes:
        name = r["name"]
        try:
            proc = subprocess.run(
                f'rclone about "{name}:" --json 2>/dev/null',
                shell=True, capture_output=True, text=True, timeout=30
            )
            if proc.returncode == 0:
                about = json.loads(proc.stdout)
                results[name] = {
                    "total": about.get("total"),
                    "used": about.get("used"),
                    "free": about.get("free"),
                    "trashed": about.get("trashed"),
                }
            else:
                results[name] = {"error": "ä¸æ”¯æŒå®¹é‡æŸ¥è¯¢"}
        except subprocess.TimeoutExpired:
            results[name] = {"error": "æŸ¥è¯¢è¶…æ—¶"}
        except Exception as e:
            results[name] = {"error": str(e)}
    return jsonify({"storage": results})


# â”€â”€ åŒæ­¥è§„åˆ™ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.route("/api/sync/rules")
def api_sync_rules():
    """è·å–æ‰€æœ‰åŒæ­¥è§„åˆ™"""
    return jsonify({"rules": _load_sync_rules(), "templates": SYNC_RULE_TEMPLATES})


@app.route("/api/sync/rules/save", methods=["POST"])
def api_sync_rules_save():
    """ä¿å­˜åŒæ­¥è§„åˆ™ (æ•´ä½“æ›¿æ¢)"""
    data = request.get_json(force=True)
    rules = data.get("rules", [])
    # æ ¡éªŒ
    for r in rules:
        if not r.get("id") or not r.get("remote") or not r.get("local_path"):
            return jsonify({"error": "æ¯æ¡è§„åˆ™å¿…é¡»æœ‰ id, remote, local_path"}), 400
    _save_sync_rules(rules)

    # å¦‚æœæœ‰ watch è§„åˆ™ä¸” worker æ²¡è¿è¡Œ, è‡ªåŠ¨å¯åŠ¨
    watch_rules = [r for r in rules if r.get("trigger") == "watch" and r.get("enabled", True)]
    if watch_rules and (not _sync_worker_thread or not _sync_worker_thread.is_alive()):
        _start_sync_worker()
    elif not watch_rules:
        _stop_sync_worker()

    return jsonify({"ok": True, "message": f"å·²ä¿å­˜ {len(rules)} æ¡è§„åˆ™"})


@app.route("/api/sync/rules/run", methods=["POST"])
def api_sync_rules_run():
    """æ‰‹åŠ¨æ‰§è¡ŒæŒ‡å®šè§„åˆ™ (æˆ–å…¨éƒ¨ deploy è§„åˆ™)"""
    data = request.get_json(force=True)
    rule_id = data.get("rule_id")  # ä¸ºç©ºåˆ™æ‰§è¡Œå…¨éƒ¨ deploy è§„åˆ™
    rules = _load_sync_rules()

    if rule_id:
        targets = [r for r in rules if r.get("id") == rule_id]
    else:
        targets = [r for r in rules if r.get("trigger") == "deploy" and r.get("enabled", True)]

    if not targets:
        return jsonify({"error": "æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è§„åˆ™"}), 404

    # åå°æ‰§è¡Œ (éé˜»å¡)
    def _run_targets():
        for r in targets:
            _run_sync_rule(r)

    threading.Thread(target=_run_targets, daemon=True).start()
    return jsonify({"ok": True, "message": f"å¼€å§‹æ‰§è¡Œ {len(targets)} æ¡è§„åˆ™"})


@app.route("/api/sync/worker/start", methods=["POST"])
def api_sync_worker_start():
    """å¯åŠ¨ Sync Worker"""
    _start_sync_worker()
    return jsonify({"ok": True, "message": "Sync Worker å·²å¯åŠ¨"})


@app.route("/api/sync/worker/stop", methods=["POST"])
def api_sync_worker_stop():
    """åœæ­¢ Sync Worker"""
    _stop_sync_worker()
    return jsonify({"ok": True, "message": "Sync Worker å·²åœæ­¢"})


# â”€â”€ Rclone é…ç½®æ–‡ä»¶ç›´æ¥ç¼–è¾‘ (é«˜çº§) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@app.route("/api/sync/rclone_config", methods=["GET"])
def api_get_rclone_config():
    """è·å– rclone.conf å®Œæ•´å†…å®¹"""
    if not RCLONE_CONF.exists():
        return jsonify({"config": "", "exists": False})
    raw = RCLONE_CONF.read_text(encoding="utf-8")
    return jsonify({"config": raw, "exists": True})


@app.route("/api/sync/rclone_config", methods=["POST"])
def api_save_rclone_config():
    """ä¿å­˜ rclone.conf"""
    data = request.get_json(force=True)
    config_text = data.get("config", "")
    if not config_text.strip():
        return jsonify({"error": "é…ç½®å†…å®¹ä¸èƒ½ä¸ºç©º"}), 400
    sections = re.findall(r'^\[.+\]', config_text, re.MULTILINE)
    if not sections:
        return jsonify({"error": "é…ç½®æ ¼å¼é”™è¯¯ï¼šè‡³å°‘éœ€è¦ä¸€ä¸ª [remote] æ®µ"}), 400
    if RCLONE_CONF.exists():
        RCLONE_CONF.with_suffix('.conf.bak').write_text(
            RCLONE_CONF.read_text(encoding="utf-8"), encoding="utf-8")
    RCLONE_CONF.parent.mkdir(parents=True, exist_ok=True)
    RCLONE_CONF.write_text(config_text, encoding="utf-8")
    RCLONE_CONF.chmod(0o600)
    try:
        r = subprocess.run("rclone listremotes 2>&1", shell=True, capture_output=True, text=True, timeout=5)
        remotes = [l.strip().rstrip(':') for l in r.stdout.strip().split('\n') if l.strip()]
    except Exception:
        remotes = []
    return jsonify({"ok": True, "message": f"é…ç½®å·²ä¿å­˜ï¼Œæ£€æµ‹åˆ° {len(remotes)} ä¸ª remote: {', '.join(remotes)}"})


@app.route("/api/sync/import_config", methods=["POST"])
def api_import_config():
    """ä» URL æˆ– base64 å¯¼å…¥ rclone.conf"""
    import base64
    data = request.get_json(force=True)
    import_type = data.get("type", "")
    value = data.get("value", "")
    config_text = ""
    if import_type == "url" and value:
        try:
            resp = requests.get(value, timeout=15)
            resp.raise_for_status()
            config_text = resp.text
        except Exception as e:
            return jsonify({"error": f"ä¸‹è½½å¤±è´¥: {e}"}), 400
    elif import_type == "base64" and value:
        try:
            config_text = base64.b64decode(value).decode("utf-8")
        except Exception as e:
            return jsonify({"error": f"Base64 è§£ç å¤±è´¥: {e}"}), 400
    else:
        return jsonify({"error": "è¯·æä¾› type (url/base64) å’Œ value"}), 400
    sections = re.findall(r'^\[.+\]', config_text, re.MULTILINE)
    if not sections:
        return jsonify({"error": "å¯¼å…¥çš„å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„ rclone é…ç½®"}), 400
    if RCLONE_CONF.exists():
        RCLONE_CONF.with_suffix('.conf.bak').write_text(
            RCLONE_CONF.read_text(encoding="utf-8"), encoding="utf-8")
    RCLONE_CONF.parent.mkdir(parents=True, exist_ok=True)
    RCLONE_CONF.write_text(config_text, encoding="utf-8")
    RCLONE_CONF.chmod(0o600)
    try:
        r = subprocess.run("rclone listremotes 2>&1", shell=True, capture_output=True, text=True, timeout=5)
        remotes = [l.strip().rstrip(':') for l in r.stdout.strip().split('\n') if l.strip()]
    except Exception:
        remotes = []
    return jsonify({"ok": True, "message": f"å¯¼å…¥æˆåŠŸï¼Œæ£€æµ‹åˆ° {len(remotes)} ä¸ª remote: {', '.join(remotes)}"})


# â”€â”€ å‘åå…¼å®¹: æ—§çš„ sync_prefs â†’ rules è¿ç§» â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _migrate_old_sync_prefs():
    """å¦‚æœå­˜åœ¨æ—§çš„ .sync_prefs.json ä¸”æ²¡æœ‰ rulesï¼Œè‡ªåŠ¨è¿ç§»"""
    if SYNC_RULES_FILE.exists():
        return  # å·²æœ‰æ–°è§„åˆ™
    if not SYNC_PREFS_FILE.exists():
        return
    try:
        prefs = json.loads(SYNC_PREFS_FILE.read_text(encoding="utf-8"))
    except Exception:
        return

    rules = []
    remotes = _parse_rclone_conf()
    remote_names = {r["type"]: r["name"] for r in remotes}

    # R2 ä¸‹æ‹‰è§„åˆ™
    r2_name = remote_names.get("s3", "")
    r2_prefs = prefs.get("r2", {})
    if r2_name and r2_prefs.get("enabled", True):
        if r2_prefs.get("sync_workflows", True):
            rules.append({"id": "migrated-pull-workflows", "name": "ä¸‹æ‹‰å·¥ä½œæµ", "direction": "pull",
                          "remote": r2_name, "remote_path": "comfyui-assets/workflow",
                          "local_path": "user/default/workflows", "method": "sync", "trigger": "deploy", "enabled": True})
        if r2_prefs.get("sync_loras", True):
            rules.append({"id": "migrated-pull-loras", "name": "ä¸‹æ‹‰ LoRA", "direction": "pull",
                          "remote": r2_name, "remote_path": "comfyui-assets/loras",
                          "local_path": "models/loras", "method": "sync", "trigger": "deploy", "enabled": True})
        if r2_prefs.get("sync_wildcards", True):
            rules.append({"id": "migrated-pull-wildcards", "name": "ä¸‹æ‹‰ Wildcards", "direction": "pull",
                          "remote": r2_name, "remote_path": "comfyui-assets/wildcards",
                          "local_path": "custom_nodes/comfyui-dynamicprompts/wildcards",
                          "method": "sync", "trigger": "deploy", "enabled": True})

    # OneDrive / GDrive è¾“å‡ºä¸Šä¼ è§„åˆ™
    od_name = remote_names.get("onedrive", "")
    od_prefs = prefs.get("onedrive", {})
    if od_name and od_prefs.get("enabled", False):
        rules.append({"id": "migrated-push-od", "name": "ä¸Šä¼ è¾“å‡ºåˆ° OneDrive", "direction": "push",
                      "remote": od_name, "remote_path": od_prefs.get("destination", "ComfyUI_Transfer"),
                      "local_path": "output", "method": "move", "trigger": "watch", "watch_interval": 15,
                      "filters": ["+ *.{png,jpg,jpeg,webp,gif,mp4,mov,webm}", "- .*/**", "- *"], "enabled": True})

    gd_name = remote_names.get("drive", "")
    gd_prefs = prefs.get("gdrive", {})
    if gd_name and gd_prefs.get("enabled", False):
        rules.append({"id": "migrated-push-gd", "name": "ä¸Šä¼ è¾“å‡ºåˆ° Google Drive", "direction": "push",
                      "remote": gd_name, "remote_path": gd_prefs.get("destination", "ComfyUI_Transfer"),
                      "local_path": "output", "method": "move", "trigger": "watch", "watch_interval": 15,
                      "filters": ["+ *.{png,jpg,jpeg,webp,gif,mp4,mov,webm}", "- .*/**", "- *"], "enabled": True})

    if rules:
        _save_sync_rules(rules)
        _sync_log(f"å·²ä»æ—§é…ç½®è¿ç§» {len(rules)} æ¡åŒæ­¥è§„åˆ™")


# ====================================================================
# å‰ç«¯é¡µé¢
# ====================================================================
@app.route("/")
def index():
    # å¦‚æœå‘å¯¼æœªå®Œæˆï¼Œæ˜¾ç¤ºå‘å¯¼é¡µé¢
    if not _is_setup_complete():
        wizard_path = Path(__file__).parent / "setup_wizard.html"
        if wizard_path.exists():
            resp = Response(wizard_path.read_text(encoding="utf-8"), mimetype="text/html")
            resp.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
            return resp
        return Response("<h1>setup_wizard.html not found</h1>", mimetype="text/html", status=404)
    html_path = Path(__file__).parent / "dashboard.html"
    if html_path.exists():
        resp = Response(html_path.read_text(encoding="utf-8"), mimetype="text/html")
        resp.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        return resp
    return Response("<h1>dashboard.html not found</h1>", mimetype="text/html", status=404)


@app.route("/dashboard.js")
def serve_js():
    js_path = Path(__file__).parent / "dashboard.js"
    if js_path.exists():
        resp = Response(js_path.read_text(encoding="utf-8"), mimetype="application/javascript")
        resp.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"
        return resp
    return "", 404


@app.route("/favicon.ico")
def serve_favicon():
    """Serve favicon"""
    ico = os.path.join(SCRIPT_DIR, "favicon.ico")
    if os.path.exists(ico):
        return send_file(ico, mimetype="image/x-icon")
    return "", 204

@app.route("/static/<path:filename>")
def serve_static(filename):
    """é€šç”¨é™æ€æ–‡ä»¶æœåŠ¡"""
    base_dir = Path(__file__).parent.resolve()
    safe_path = (base_dir / filename).resolve()
    if not str(safe_path).startswith(str(base_dir)):
        return "", 403
    if safe_path.exists() and safe_path.is_file():
        return send_file(str(safe_path))
    return "", 404


# ====================================================================
# å¯åŠ¨
# ====================================================================
if __name__ == "__main__":
    port = int(sys.argv[1]) if len(sys.argv) > 1 else MANAGER_PORT

    # ä»ç¯å¢ƒå˜é‡å¯¼å…¥ API Key
    if os.environ.get("CIVITAI_TOKEN") and not _get_api_key():
        CONFIG_FILE.write_text(json.dumps({"api_key": os.environ["CIVITAI_TOKEN"]}))
        print(f"  ğŸ“ å·²ä»ç¯å¢ƒå˜é‡ CIVITAI_TOKEN å¯¼å…¥ API Key")

    # è¿ç§»æ—§ sync_prefs â†’ rules å¹¶å¯åŠ¨ watch worker
    _migrate_old_sync_prefs()
    rules = _load_sync_rules()
    watch_rules = [r for r in rules if r.get("trigger") == "watch" and r.get("enabled", True)]
    if watch_rules:
        _start_sync_worker()
        print(f"  â˜ï¸  Sync Worker å·²å¯åŠ¨ ({len(watch_rules)} æ¡ç›‘æ§è§„åˆ™)")

    print(f"\n{'='*50}")
    print(f"  ğŸ–¥ï¸  ComfyCarry v2.4")
    print(f"  è®¿é—®åœ°å€: http://localhost:{port}")
    print(f"  ComfyUI:  {COMFYUI_DIR}")
    print(f"{'='*50}\n")
    app.run(host="0.0.0.0", port=port, debug=False)
